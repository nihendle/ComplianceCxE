{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"M365 Compliance One-Stop-Shop (OSS) \u2693\ufe0e S-C-M Customer Adoption Team (CAT) is a World Wide team, our charter is helping customers deploy M365 security and compliance products. We do this through understanding the benefits of the product, being the voice of the customer inside engineering, help prioritize bugs and features, and lastly shape the product which benefits the customer's use cases scenarios while protecting and governing their most sensitive data. We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis. General Information \u2693\ufe0e CxE Deployment Acceleration Guides (DAGs) Official M365 Compliance Documentation Security and Compliance Licensing Guidance What is a 'Dev Tenant' and why would you want one? Social Media and Forums \u2693\ufe0e MIP Yammer Channel MIPNews Twitter Upcoming Webinars \u2693\ufe0e The Compliance CxE team regularly hosts webinars to present what's changing and new with our products. Every webinar is always recorded and published here along with the PowerPoint Decks and Q&A. Webinar Topic Date & Time Registration Link MIG : What's New from Ignite regarding Information Governance & Records Mgmt. ( EMEA/NA ) May 19, 2021 16:00 GMT / 08:00 PST Register MIG : What's New from Ignite regarding Information Governance & Records Mgmt. ( APAC ) May 19, 2021 16:00 AEDT Register Past webinars... Learn more about... \u2693\ufe0e eDiscovery in Microsoft 365 Microsoft Information Governance in Microsoft 365 Microsoft Information Protection in Microsoft 365 Endpoint Data Loss Prevention in Microsoft 365 Insider Risk Management in Microsoft 365 Compliance Manager in Microsoft 365","title":"OSS"},{"location":"#m365-compliance-one-stop-shop-oss","text":"S-C-M Customer Adoption Team (CAT) is a World Wide team, our charter is helping customers deploy M365 security and compliance products. We do this through understanding the benefits of the product, being the voice of the customer inside engineering, help prioritize bugs and features, and lastly shape the product which benefits the customer's use cases scenarios while protecting and governing their most sensitive data. We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"M365 Compliance One-Stop-Shop (OSS)"},{"location":"#general-information","text":"CxE Deployment Acceleration Guides (DAGs) Official M365 Compliance Documentation Security and Compliance Licensing Guidance What is a 'Dev Tenant' and why would you want one?","title":"General Information"},{"location":"#social-media-and-forums","text":"MIP Yammer Channel MIPNews Twitter","title":"Social Media and Forums"},{"location":"#upcoming-webinars","text":"The Compliance CxE team regularly hosts webinars to present what's changing and new with our products. Every webinar is always recorded and published here along with the PowerPoint Decks and Q&A. Webinar Topic Date & Time Registration Link MIG : What's New from Ignite regarding Information Governance & Records Mgmt. ( EMEA/NA ) May 19, 2021 16:00 GMT / 08:00 PST Register MIG : What's New from Ignite regarding Information Governance & Records Mgmt. ( APAC ) May 19, 2021 16:00 AEDT Register Past webinars...","title":"Upcoming Webinars"},{"location":"#learn-more-about","text":"eDiscovery in Microsoft 365 Microsoft Information Governance in Microsoft 365 Microsoft Information Protection in Microsoft 365 Endpoint Data Loss Prevention in Microsoft 365 Insider Risk Management in Microsoft 365 Compliance Manager in Microsoft 365","title":"Learn more about..."},{"location":"dag/","text":"Deployment Acceleration Guides \u2693\ufe0e The deployment acceleration guides (DAGs) are written and updated by the global Compliance CxE team and are a resource designed to help with the following: One Compliance Story covering how each solution complements each other Best Practices based on the CxE team's experience with customer roadblocks Considerations to take and research before starting your deployment Help Resources links to additional readings and topics to gain a deeper understanding of the solution Appendix for additional information on licensing The guides can be used both independently, but we recommend using all the solutions together for your deployment needs. We are not recommending one solution be implemented before another but have included information in each guide to tie all the solutions together with features to consider during your implementation. The guide covers current released feature as of today and is continuously updated as additional features progress from beta, or private preview to general availability. How to use the Deployment Acceleration Guide \u2693\ufe0e Organizations of all types are moving to the cloud and adopting more solutions to meet data protection and compliance requirements from the Microsoft 365 (M365) suite of capabilities. Use this guide as a comprehensive source for the suite of solutions across information protection and compliance. Start by understanding best practices, key considerations and lessons learned from others who have gone before you. Use this cumulative knowledge and processes outlined in the following pages to drive alignment and consensus in your organization by taking the first steps toward a more secure, compliant posture for your organization in the cloud. Each of the sections in this guide can be leveraged as standalone guidance, or all together to define your overall compliance strategy. Many of the solutions covered in this guide will require participation from various teams and business groups within your organization. Customers who achieve successful roll outs of the capabilities typically prioritize by a use case scenario and create a working virtual team to manage the requirements validation, proof of concept testing in a pre-production environment, internal checkpoints, and approvals and finally deployment into the production environment. We recommend identifying your top 1-2 scenarios for deployment and tackling those first, with the right resources from your broader team engaged. Once those priorities are deployed, come back to this guide to identify the next two priorities for deployment and repeat the process of stakeholder alignment, testing and validation on the path to successful deployment. We believe our solutions from Microsoft 365 are the best of suite to help our customers know their data better, by protecting and governing data throughout its lifecycle in a heterogenous environment. This is often the key starting point for many of our customers in their modern compliance journey \u2013 knowing what sensitive data they have, creating flexible, end-user friendly policies for both security and compliance outcomes and using more automation and intelligence. Getting Started \u2693\ufe0e Before jumping into the various sections detailing the deployment, there are some planning and prerequisite items that should be addressed. These include general prerequisites, such as scheduling and recommended attendance of meetings, and support and communication planning. We will touch on these items and provide some general guidance based on what we have seen help customers succeed in deployments of Microsoft Information Protection & Compliance. While these tips are meant to help guide you on your deployment journey, please keep in mind that these items will vary widely depending on the size, regulatory requirements, and complexity of your organization. DAGs By Feature \u2693\ufe0e Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Advanced eDiscovery and Advanced Audit Insider Risk Management and Commmunication Compliance Microsoft Information Governance and Records Management Microsoft Information Protection and Data Loss Prevention","title":"Getting Started"},{"location":"dag/#deployment-acceleration-guides","text":"The deployment acceleration guides (DAGs) are written and updated by the global Compliance CxE team and are a resource designed to help with the following: One Compliance Story covering how each solution complements each other Best Practices based on the CxE team's experience with customer roadblocks Considerations to take and research before starting your deployment Help Resources links to additional readings and topics to gain a deeper understanding of the solution Appendix for additional information on licensing The guides can be used both independently, but we recommend using all the solutions together for your deployment needs. We are not recommending one solution be implemented before another but have included information in each guide to tie all the solutions together with features to consider during your implementation. The guide covers current released feature as of today and is continuously updated as additional features progress from beta, or private preview to general availability.","title":"Deployment Acceleration Guides"},{"location":"dag/#how-to-use-the-deployment-acceleration-guide","text":"Organizations of all types are moving to the cloud and adopting more solutions to meet data protection and compliance requirements from the Microsoft 365 (M365) suite of capabilities. Use this guide as a comprehensive source for the suite of solutions across information protection and compliance. Start by understanding best practices, key considerations and lessons learned from others who have gone before you. Use this cumulative knowledge and processes outlined in the following pages to drive alignment and consensus in your organization by taking the first steps toward a more secure, compliant posture for your organization in the cloud. Each of the sections in this guide can be leveraged as standalone guidance, or all together to define your overall compliance strategy. Many of the solutions covered in this guide will require participation from various teams and business groups within your organization. Customers who achieve successful roll outs of the capabilities typically prioritize by a use case scenario and create a working virtual team to manage the requirements validation, proof of concept testing in a pre-production environment, internal checkpoints, and approvals and finally deployment into the production environment. We recommend identifying your top 1-2 scenarios for deployment and tackling those first, with the right resources from your broader team engaged. Once those priorities are deployed, come back to this guide to identify the next two priorities for deployment and repeat the process of stakeholder alignment, testing and validation on the path to successful deployment. We believe our solutions from Microsoft 365 are the best of suite to help our customers know their data better, by protecting and governing data throughout its lifecycle in a heterogenous environment. This is often the key starting point for many of our customers in their modern compliance journey \u2013 knowing what sensitive data they have, creating flexible, end-user friendly policies for both security and compliance outcomes and using more automation and intelligence.","title":"How to use the Deployment Acceleration Guide"},{"location":"dag/#getting-started","text":"Before jumping into the various sections detailing the deployment, there are some planning and prerequisite items that should be addressed. These include general prerequisites, such as scheduling and recommended attendance of meetings, and support and communication planning. We will touch on these items and provide some general guidance based on what we have seen help customers succeed in deployments of Microsoft Information Protection & Compliance. While these tips are meant to help guide you on your deployment journey, please keep in mind that these items will vary widely depending on the size, regulatory requirements, and complexity of your organization.","title":"Getting Started"},{"location":"dag/#dags-by-feature","text":"Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Advanced eDiscovery and Advanced Audit Insider Risk Management and Commmunication Compliance Microsoft Information Governance and Records Management Microsoft Information Protection and Data Loss Prevention","title":"DAGs By Feature"},{"location":"how-to-contribute/","text":"The Compliance CxE team encourages collaboration of our content. This article describes how you can contribute. In this document \u2693\ufe0e Submitting an Issue Quick Editing a Page Submitting an Issue \u2693\ufe0e Notice something incorrect? Have a comment? Submit an issue or make a comment. Select the 'Submit Issue' link at the top right of the page. This will take you to GitHub, where you will fill out a new 'Issue', then click Submit new issue NOTE: You must be logged in to GitHub to submit an issue. Quick Editing a Page \u2693\ufe0e Want to just make quick changes yourself? Select the 'Edit Page' link at the top right of the page. In GitHub, select the pencil icon to the edit the article NOTE: You must be logged in to GitHub or the edit button will be greyed out Make changes in the web editor. Click the Preview changes tab to check formatting of your change. Once you have made your changes, scroll to the bottom of the page. Enter a title and description for your changes and click Propose file change Now that you've proposed your change, you need to ask the owners of the repository to \"pull\" your changes into their repository. This is done using something called a \"pull request\". When you select Propose file change , a new page similar to the following is displayed: Select Create pull request, enter a title, and optionally a description for the pull request, and then select Create pull request. If you are new to GitHub, see About Pull Requests for more information. That's it! Content team members will review and merge your PR when it's approved. You may get feedback requesting changes.","title":"How to Contribute"},{"location":"how-to-contribute/#in-this-document","text":"Submitting an Issue Quick Editing a Page","title":"In this document"},{"location":"how-to-contribute/#submitting-an-issue","text":"Notice something incorrect? Have a comment? Submit an issue or make a comment. Select the 'Submit Issue' link at the top right of the page. This will take you to GitHub, where you will fill out a new 'Issue', then click Submit new issue NOTE: You must be logged in to GitHub to submit an issue.","title":"Submitting an Issue"},{"location":"how-to-contribute/#quick-editing-a-page","text":"Want to just make quick changes yourself? Select the 'Edit Page' link at the top right of the page. In GitHub, select the pencil icon to the edit the article NOTE: You must be logged in to GitHub or the edit button will be greyed out Make changes in the web editor. Click the Preview changes tab to check formatting of your change. Once you have made your changes, scroll to the bottom of the page. Enter a title and description for your changes and click Propose file change Now that you've proposed your change, you need to ask the owners of the repository to \"pull\" your changes into their repository. This is done using something called a \"pull request\". When you select Propose file change , a new page similar to the following is displayed: Select Create pull request, enter a title, and optionally a description for the pull request, and then select Create pull request. If you are new to GitHub, see About Pull Requests for more information. That's it! Content team members will review and merge your PR when it's approved. You may get feedback requesting changes.","title":"Quick Editing a Page"},{"location":"playbooks/","text":"Coming soon! In the mean time, check out our playbooks at the links below: Data Loss Prevention \u2693\ufe0e Migrating from Exchange ETR to DLP Playbook Teams DLP Playbook","title":"Playbooks"},{"location":"playbooks/#data-loss-prevention","text":"Migrating from Exchange ETR to DLP Playbook Teams DLP Playbook","title":"Data Loss Prevention"},{"location":"previews/","text":"Coming soon! If you would like to sign up for our private preview programs, please fill out the form at https://aka.ms/MIPC/JoinPreviews . In the mean time, take a look at our Preview Programs blog post at https://aka.ms/MIPC/previews","title":"Previews"},{"location":"test/","text":"Customer Experience Engineering (CxE) is a World Wide team, our charter is helping customers deploy M365 security and compliance products. We do this through understanding the benefits of the product, being the voice of the customer inside engineering, help prioritize bugs and features, and lastly shape the product which benefits the customer's use cases scenarios while protecting and governing their most sensitive data. We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis. [!NOTE] Test Make sure to test this. General Information \u2693\ufe0e CxE Deployment Acceleration Guides (DAGs) Official M365 Compliance Documentation Security and Compliance Licensing Guidance What is a 'Dev Tenant' and why would you want one? Social Media and Forums \u2693\ufe0e MIP Yammer Channel MIPNews Twitter Upcoming Webinars \u2693\ufe0e The Compliance CxE team regularly hosts webinars to present what's changing and new with our products. Every webinar is always recorded and published here along with the PowerPoint Decks and Q&A. |Webinar Topic|Date & Time|Registration Link| |---|---|---|---| | MIG : What's New from Ignite regarding Information Governance & Records Mgmt. ( EMEA/NA )|May 19, 2021 16:00 GMT / 08:00 PST| Register | | MIG : What's New from Ignite regarding Information Governance & Records Mgmt. ( APAC )|May 19, 2021 16:00 AEDT| Register | Past webinars... Learn more about... \u2693\ufe0e eDiscovery in Microsoft 365 Microsoft Information Governance in Microsoft 365 Microsoft Information Protection in Microsoft 365 Endpoint Data Loss Prevention in Microsoft 365 Insider Risk Management in Microsoft 365 Compliance Manager in Microsoft 365","title":"OSS"},{"location":"test/#general-information","text":"CxE Deployment Acceleration Guides (DAGs) Official M365 Compliance Documentation Security and Compliance Licensing Guidance What is a 'Dev Tenant' and why would you want one?","title":"General Information"},{"location":"test/#social-media-and-forums","text":"MIP Yammer Channel MIPNews Twitter","title":"Social Media and Forums"},{"location":"test/#upcoming-webinars","text":"The Compliance CxE team regularly hosts webinars to present what's changing and new with our products. Every webinar is always recorded and published here along with the PowerPoint Decks and Q&A. |Webinar Topic|Date & Time|Registration Link| |---|---|---|---| | MIG : What's New from Ignite regarding Information Governance & Records Mgmt. ( EMEA/NA )|May 19, 2021 16:00 GMT / 08:00 PST| Register | | MIG : What's New from Ignite regarding Information Governance & Records Mgmt. ( APAC )|May 19, 2021 16:00 AEDT| Register | Past webinars...","title":"Upcoming Webinars"},{"location":"test/#learn-more-about","text":"eDiscovery in Microsoft 365 Microsoft Information Governance in Microsoft 365 Microsoft Information Protection in Microsoft 365 Endpoint Data Loss Prevention in Microsoft 365 Insider Risk Management in Microsoft 365 Compliance Manager in Microsoft 365","title":"Learn more about..."},{"location":"webinars/","text":"The Compliance CxE team regularly hosts webinars to present what's changing and new with our products. Every webinar is always recorded and published here along with the PowerPoint Decks and Q&A. For upcoming webinars, refer to the OSS . Discovery & Response \u2693\ufe0e Date Topic Recording Resources April 7, 2021 D&R : What's New with Advanced eDiscovery Spring 2021 YouTube Deck/FAQ Oct 19, 2020 D&R : New Announcements and Updates Video Deck/FAQ May 14, 2020 D&R : eDiscovery for Teams Video Deck/FAQ Apr. 7, 2020 D&R : Advanced Audit Video Deck/FAQ Compliance Manager \u2693\ufe0e Date Topic Recording Resources April 20, 2021 CM : What's New from Ignite regarding Compliance Manager YouTube Deck/FAQ Oct 01, 2020 CM : Compliance Manager Overview Video Deck/FAQ Apr. 15, 2020 CM : Compliance score how-to Video Deck/FAQ Insider Risk Management/Communication Compliance {#ircc} \u2693\ufe0e Date Topic Recording Resources March 24, 2021 IIRC : What's New from Ignite regarding Insider Risk Management YouTube Deck/FAQ Oct 29, 2020 IRCC : New Announcements and Updates Video Deck/FAQ Mar. 10, 2020 IRCC : Insider Risk Management & Communications Compliance Video Deck/FAQ Microsoft Information Governance \u2693\ufe0e Date Topic Recording Resources Oct 26, 2020 MIG : New Announcements and Updates Video Deck/FAQ May 26, 2020 MIG : Records Management Video Deck/FAQ Microsoft Information Protection \u2693\ufe0e Date Topic Recording Resources May 4, 2021 MIP : What's New from Ignite regarding Microsoft Information Protection YouTube Deck/FAQ Feb 19, 2021 MIP : Office Channels Video Deck/FAQ Feb 10, 2021 MIP : Extending MIP with high-value third-party solutions Video Deck/FAQ Oct 13, 2020 MIP : New Announcements and Updates Video Deck/FAQ Sep 30, 2020 MIP : Protection for on-premises data Video Deck Jul 14, 2020 MIP : Feature Improvements for Sensitivity Labels for Containers Video Deck/FAQ Jun. 2, 2020 MIP : Power BI and MIP Integration Video Deck May 28, 2020 MIP : Moving to unified labeling Video Deck/FAQ Apr. 22, 2020 MIP : Exact Data Match (EDM) classification Video Deck/FAQ Mar. 17, 2020 MIP : Trainable classifiers Video Deck/FAQ Mar. 5, 2020 MIP : Using Sensitivity labels with Microsoft Teams, O365 Groups and SharePoint Online sites Video Deck/FAQ Feb. 11, 2020 MIP : Know your data Video Deck/FAQ Jan. 22, 2020 MIP : Introduction to SharePoint & OneDrive Auto-labeling Video N/A Jan. 15, 2020 MIP : Moving to unified labeling YouTube Deck/FAQ Data Loss Prevention \u2693\ufe0e Date Topic Recording Resources March 17, 2021 DLP : Unified DLP YouTube Deck/FAQ Jan 26, 2021 DLP : Remote Workers DLP YouTube Deck/FAQ Nov 04, 2020 DLP : On-Premises DLP Video Deck/FAQ Sep 9, 2020 DLP : Microsoft Endpoint DLP Video Deck/FAQ Other \u2693\ufe0e Date Topic Recording Resources Apr. 27, 2020 Working remotely during challenging times Video Deck/FAQ","title":"Webinars"},{"location":"webinars/#discovery-response","text":"Date Topic Recording Resources April 7, 2021 D&R : What's New with Advanced eDiscovery Spring 2021 YouTube Deck/FAQ Oct 19, 2020 D&R : New Announcements and Updates Video Deck/FAQ May 14, 2020 D&R : eDiscovery for Teams Video Deck/FAQ Apr. 7, 2020 D&R : Advanced Audit Video Deck/FAQ","title":"Discovery &amp; Response"},{"location":"webinars/#compliance-manager","text":"Date Topic Recording Resources April 20, 2021 CM : What's New from Ignite regarding Compliance Manager YouTube Deck/FAQ Oct 01, 2020 CM : Compliance Manager Overview Video Deck/FAQ Apr. 15, 2020 CM : Compliance score how-to Video Deck/FAQ","title":"Compliance Manager"},{"location":"webinars/#insider-risk-managementcommunication-compliance-ircc","text":"Date Topic Recording Resources March 24, 2021 IIRC : What's New from Ignite regarding Insider Risk Management YouTube Deck/FAQ Oct 29, 2020 IRCC : New Announcements and Updates Video Deck/FAQ Mar. 10, 2020 IRCC : Insider Risk Management & Communications Compliance Video Deck/FAQ","title":"Insider Risk Management/Communication Compliance {#ircc}"},{"location":"webinars/#microsoft-information-governance","text":"Date Topic Recording Resources Oct 26, 2020 MIG : New Announcements and Updates Video Deck/FAQ May 26, 2020 MIG : Records Management Video Deck/FAQ","title":"Microsoft Information Governance"},{"location":"webinars/#microsoft-information-protection","text":"Date Topic Recording Resources May 4, 2021 MIP : What's New from Ignite regarding Microsoft Information Protection YouTube Deck/FAQ Feb 19, 2021 MIP : Office Channels Video Deck/FAQ Feb 10, 2021 MIP : Extending MIP with high-value third-party solutions Video Deck/FAQ Oct 13, 2020 MIP : New Announcements and Updates Video Deck/FAQ Sep 30, 2020 MIP : Protection for on-premises data Video Deck Jul 14, 2020 MIP : Feature Improvements for Sensitivity Labels for Containers Video Deck/FAQ Jun. 2, 2020 MIP : Power BI and MIP Integration Video Deck May 28, 2020 MIP : Moving to unified labeling Video Deck/FAQ Apr. 22, 2020 MIP : Exact Data Match (EDM) classification Video Deck/FAQ Mar. 17, 2020 MIP : Trainable classifiers Video Deck/FAQ Mar. 5, 2020 MIP : Using Sensitivity labels with Microsoft Teams, O365 Groups and SharePoint Online sites Video Deck/FAQ Feb. 11, 2020 MIP : Know your data Video Deck/FAQ Jan. 22, 2020 MIP : Introduction to SharePoint & OneDrive Auto-labeling Video N/A Jan. 15, 2020 MIP : Moving to unified labeling YouTube Deck/FAQ","title":"Microsoft Information Protection"},{"location":"webinars/#data-loss-prevention","text":"Date Topic Recording Resources March 17, 2021 DLP : Unified DLP YouTube Deck/FAQ Jan 26, 2021 DLP : Remote Workers DLP YouTube Deck/FAQ Nov 04, 2020 DLP : On-Premises DLP Video Deck/FAQ Sep 9, 2020 DLP : Microsoft Endpoint DLP Video Deck/FAQ","title":"Data Loss Prevention"},{"location":"webinars/#other","text":"Date Topic Recording Resources Apr. 27, 2020 Working remotely during challenging times Video Deck/FAQ","title":"Other"},{"location":"dag/aed-audit/","text":"Last updated: 05/11/2021 How can Advanced eDiscovery and Advanced Audit support your organization in responding to legal, regulatory, and compliance obligations? It starts with discovering the data that is relevant without the need to export this data out of Microsoft 365. The ability to natively search for data in Teams, Yammer, SharePoint Online, OneDrive for Business, Exchange Online leveraging conversations reconstruction, along with support other file types using 3rd party connectors, enhances your collection prowess. Advanced eDiscovery allows you to manage the workflows in solution reducing the amount of data intelligently through the use of ML mapping unique and share data resources of custodians, and reporting or using analytics prior to data collection before your review. Advanced Audit supports your organizations requirements in assessing the scope of compromise during a data breach or to give you an efficient way to go back to historical data without holding large volumes of data. Using forensic investigations and responding to legal requests leverages the audit logs to define the scope of a data breach and determine the length of an investigation. Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Advanced eDiscovery Advanced Audit The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while providing workflows that respond to needs of investigations in an efficient, repeatable, and defensible manner. Advanced eDiscovery \u2693\ufe0e The Advanced eDiscovery solution provides customers with the ability to identify, preserve, collect, process, analyze, review and product content that's responsive to your organization's internal and external investigations. Discovering and managing data is challenging. To help solve these challenges, we provide customers with tools that enable them to do more in-place eDiscovery in Microsoft 365, thereby reducing risks associated with either creating multiple copies or exporting content outside of your security and compliance boundaries. Using Advanced eDiscovery, you can reduce the content in-place and only export matter relevant content. Best Practices \u2693\ufe0e To help frame the Advanced eDiscovery solution, it is important to note that our capabilities align with the eDiscovery Reference Model (EDRM) workflow as shown in figure 1. Within Advanced eDiscovery, we have enhanced identification, preservation, and collection from core eDiscovery with things like custodian management and advanced indexing. On top of this, to further cull and reduce data intelligently, in Advanced eDiscovery, provides capabilities to process, review and analyze your data so that what you export is minimized. See figure 2 below for a suggested linear workflow. Workflows \u2693\ufe0e In the suggested workflows below you have the ability to hit the ground running in implementing Advanced eDiscovery in your tenant. Basic Workflow \u2693\ufe0e Create a case in Advanced eDiscovery. Identify your custodial and non-custodial source locations and add to case for advanced indexing. Create a search on identified source locations Add your results to a Review Set Further reduce content in your review set using the Analytics to find near duplicates and thread messages Export out of AeD Advanced Workflow \u2693\ufe0e Create a case in Advanced eDiscovery. Identify your custodial and non-custodial source locations and add to case for advanced indexing. Remediate any processing errors Create and send legal hold notifications to custodians Create and run a search on identified source locations Add your results to a review set. Select the options to include modern attachments as well as contextual conversation review. Further reduce using Analyze to group together near duplicates and email threads, and identify content that is potentially privileged . Review the content within your review set for responsiveness using tags. Annotate and Redact documents Export out only case relevant content Next Steps Workflow \u2693\ufe0e Set up attorney-client privilege Custodian Audit Activity Themes Case Management \u2693\ufe0e When navigating to the compliance center, you will see an overview of all cases in Advanced eDiscovery. Think of a case as the container for your legal matter. The case will include all searches, holds, hold notifications, reviews, and exports. Note that the name of your case cannot be changed later, careful thought should be used in creating a naming convention that allows all in your organization to follow and understand. If connecting to a matter management tool, please ensure that you use the same naming convention. When creating a new case, you have the opportunity to adjust your analytics settings, enable OCR, adjust your settings for Themes, configure Ignore text, and add any additional members to the case. As mentioned below in considerations, the similarity threshold is set to 65% by default. This means that when running the analytics job, the application will group together items that are within 65% similar to another document. You can enhance it if you need. The Themes functionality analyzes documents with text in a review set to parse out common clusters or themes that appear across all the documents in the review set. Consider selecting Adjust Maximum Number Of Themes Dynamically to ensure that you can still take advantage of the feature even if there are not enough documents to create the desired number of themes. There are situations where certain text will diminish the quality of analytics, such as lengthy disclaimers that get added to email messages regardless of the content of the email. If you know of text that should be ignored, you can exclude it from analytics by specifying the text string and the analytics functionality (Near-duplicates, Email threading, Themes, and Relevance) that the text should be excluded for. Using regular expressions (RegEx) as ignored text is also supported. OCR processing will be run on image files when sources are added to a case during the advanced indexing job. This means that text in image files that matches the search criteria will be returned in a collection search. Source Location Management \u2693\ufe0e A user is so much more than their mailbox and their OneDrive site. They are able to collaborate in Teams, Yammer and Sharepoint. They use third party tools like Bloomberg, Facebook and more. When using Advanced eDiscovery, you can associate other data locations to a custodian beyond their mailbox and OneDrive site alone. Once your legal team has identified a custodian, you can use the Data Sources tab in Advanced eDiscovery to manage the following: User mailbox User OneDrive site Any Teams that they are currently a member of Any Yammer networks (in native mode) Sharepoint sites a custodian may have accessed or contributed to Custodians and source locations can be added on-by-one in the user interface using the picker or they can be added in bulk using the Import Custodian feature. If your legal team has given you a list of custodians, consider using the custodian template to import your custodial locations. For tips on how to populate the .csv, please follow our guidance found here . The Data Sources tab within an Advanced eDiscovery case contains a list of all custodians that have been added to the case. After you add custodians to a case, details about each custodian are automatically collected from Azure Active Directory and are viewable in Advanced eDiscovery. You may have additional data locations located within Microsoft 365 that do not need to be associated with a custodian. These locations are typically group mailboxes or SharePoint sites. You can still add these non-custodial data sources to your case in order to take advantage of the advanced indexing, search, preservation, analytics and review. Not all documents that you need to analyze in Advanced eDiscovery are located within Microsoft 365. You can also upload items that are not located in Microsoft 365 later in the workflow directly into a review set. This would be content like on-premises exchange data or local files. Keep in mind that custodians must be added to the case before you can upload and associate non-Microsoft 365 data to them. Non-Microsoft 365 data must be a file type that is supported by Advanced eDiscovery. For more information, see Supported file types in Advanced eDiscovery . Processing \u2693\ufe0e Once a source location has been added to a case, any content that is partially indexed will be processed. Content can be partially indexed for a number of reasons including the existence of images, unsupported file types or when indexing file size limits are encountered. All items (including the content and metadata) are reindexed so that all data in the review set is fully searchable during the review of the case data. Reindexing the data results in thorough and fast searches when you search the data in the review set during the case investigation. After the indexing job is complete, you can see a report of the effectiveness of the job. The graph will give you the number of items that were added to the hybrid index where Advanced eDiscovery stores the reprocessed content. You will also have the opportunity to remediate any errors including decryption of content that was encrypted using third party encryption tools. Preservation \u2693\ufe0e Using the Advanced eDiscovery hold capabilities, you can place a hold on custodial data including their collaborative data sources. When you place content locations on hold, content is held until you release the custodian, remove a specific data location, or delete the hold policy entirely. Custodian hold policies are managed when adding locations as a source in your case. When adding a custodial data source, you will have the opportunity to decide whether you would like the locations placed on hold. As mentioned in the Helpful Resources section below, Channel conversations that are part of a Microsoft Teams channel are stored in the mailbox that is associated with the Team. Similarly, files that team members share in a channel are stored on the team's SharePoint site. Therefore, you have to place the Microsoft Team mailbox and SharePoint site on hold to retain conversations and files in a channel. Conversations that are part of the Chat list in Microsoft Teams are stored in the mailbox of the users who participate in the chat. Files that a user shares in Chat conversations are stored in the OneDrive for Business site of the user who shares the file. Therefore, you have to place the individual user mailboxes and OneDrive for Business sites on hold to retain conversations and files in the Chat list. If you the need to place a Microsoft 365 Group or Microsoft Team on hold for a specific custodian, consider mapping the group site and group mailbox to the custodian. If the Microsoft 365 Group or Microsoft Team is not attributable to a single custodian, consider adding the source to a non-custodial hold. Hold Notifications \u2693\ufe0e Once a custodian is added to a case in Advanced eDiscovery, your legal team can create and customize their legal hold notification workflow. The custodian communications tool lets legal teams configure the following notices and workflows: Issuance notice: A legal hold notice is issued (or initiated) by a notification from the legal department to custodians who may have relevant information about the case matter. This notice instructs the custodians to preserve any information that may be needed for discovery. Re-Issuance notice: During a case, custodians may be required to preserve additional content (or less content) than was previously requested. For this scenario, you can update the existing hold notice and re-issue it to custodians. Release notice: Once a matter is resolved and the custodian is no longer subject to a preservation requirement, the custodian can be released from the case. Additionally, you can notify the custodian that they are no longer required to preserve content and provide instructions about how to resume their normal work activity with regard to their data. Reminders and escalations: In some instances, just issuing a notice is not enough to satisfy legal discovery requirements. With each notification, legal teams can schedule a set of reminder and escalation workflows to automatically follow up with unresponsive custodians. Reminders: After a legal hold notice has been issued or re-issued to a set of custodians, an organization can set up reminders to alert unresponsive custodians. Escalations: In some cases, if a custodian remains unresponsive even after a set of reminders over a period of time, the legal team can set up an escalation workflow to notify unresponsive custodians and their manager. After you've defined the contents of the hold notice, you can set up the workflows around sending and managing the notification process . Notifications are email messages that are sent to notify and follow up with custodians. Every custodian added to the communication will receive the same notification. To set up and send a hold notice, you must include Issuance, Re-Issuance, and Release notifications. Collection \u2693\ufe0e Using Searches in Advanced eDiscovery, you can collect case data from your Microsoft 365 data source locations. This includes the source content that was previously processed in the above step or any additional content source locations. When creating a search, you will define the source location as well as your query. Consider reducing the amount of data you collect by using the available query conditions . Once your search is complete, you will need to add the results to a review set. This job copies the data from its source location to a static Azure Blob storage container so that you can review the content from within your data boundaries. Upon initiating this job, you will need to name your review set and decide which additional settings are required for this specific review: Include All Document Versions From SharePoint: This setting will ingest all versions of the item from SharePoint or OneDrive. Only select this if there is a specific requirement to review all versions of a specific item. Contextual conversation review : Teams chats and conversations are stored as individual messages in the associated user or group mailbox. When selecting the option to include contextual conversation review, the Advanced eDiscovery solution will thread the messages together into a conversation format to provide full context. Enable Retrieval For Modern Attachments: With modern attachments, you can check a box to auto collect all cloud attachments to your users Teams, Yammer and Exchange conversations. This is familiar to your current process for reviewing regular attachments as families or email sets. If there are downstream processes that rely on these relationships, we ensure that we are able to preserve these relationships in the load file Analysis \u2693\ufe0e Using the analytics and machine learning capabilities in Advanced eDiscovery, you can reduce the amount of data to review. Analyze \u2693\ufe0e The first step you will take after your search results are added to your review set will be to run the analytics job . Analyze allows for the identification and grouping of exact and near-duplicate files. It also identifies and organizes emails into hierarchically structured groups of email Threads , based on the progressive inclusiveness of the emails. Sets of near duplicates (ND) documents are grouped together in an ND Set. For a document to join an ND Set, there must be at least one document in the ND Set with a level of resemblance exceeding the similarity. Themes \u2693\ufe0e Themes is a content-analytics application that identifies themes and thematic relationships across file collections. The application to identify interdependencies between themes allows users to browse associatively across the collection, navigating intuitively from theme to related theme. By generating meaningful labels for each thematic group, Themes provides an immediate snapshot of a file collection. In early case assessment and investigations, Themes enables litigators and analysts to intuitively acquire an informed and rapid overview of the data set. Keep in mind that increasing the \u201cNumber of themes\u201d can affect the ability of a theme to generalize. The higher the number of themes, the more granular they are. For example, if a set of 50 themes produces themes such as \u201cBasketball, Spurs, Clippers, Lakers\u201d, a set of 300 themes may include separate themes such as \u201cSpurs\u201d, \u201cClippers\u201d, \u201cLakers\u201d. If the user had no awareness of the theme \u201cBasketball\u201d and uses this feature for Early Case Assessment (ECA), seeing the theme \u201cBasketball\u201d could be useful. If the clustering is too granular (too many themes), the user may never see the word \u201cBasketball\u201d and may not know that Spurs and Clippers are good Basketball themes to review rather than items that go on boots and are used for hair. Attorney-Client Privledge \u2693\ufe0e When attorney-client privilege detection is enabled, all documents in a review set will be processed by the attorney-client privilege detection model when you analyze the data in the review set. The model uses machine learning to determine the likelihood that a document contains content that is legal in nature. When setting up attorney-client privilege detection, you will need to submit a list of attorneys for your organization. The model will compare the participants of the document with the attorney list to determine if any attorneys are participants. Relevance \u2693\ufe0e The relevance module identifies and ranks files by relevance, which assists with early case assessment, document culling and review. Once the trained sample of files are reviewed and tagged by a human expert as Relevant or Not Relevant, the model will rank the relevance of all files in your case. There will be more information on the Relevance module in next version of this document. Review \u2693\ufe0e The review portion of the eDiscovery process can be the most time consuming and costly step. Using Advanced eDiscovery, you can cull the data in order to only produce the relevant data. A review set is simply a static set of documents that you can analyze, query, tag, and export. Review set \u2693\ufe0e Advanced eDiscovery allows you to further query and filter data within a review set so that you can focus on a subset of documents. You can build a query by using a combination of keywords, properties, and conditions in the Keywords condition. You can also group conditions as a block (called a condition group) to build a more complex query. For a list and description of metadata properties that you can search, see Document metadata fields in Advanced eDiscovery . Once you are ready to review the case data, Advanced eDiscovery displays content via several viewers each with different purposes. The various viewers can be used by clicking on any document within a review set. Above the content viewing pane, you will be able to view metadata for each document within your review set. The Native viewer displays the richest view of a document. It supports hundreds of file types and is meant to display the truest to native experience possible. The Text viewer provides a view of the extracted text of a file. It ignores any embedded images and formatting but is very effective if you are trying to understand the content quickly. The Annotate view provides features that allow users to apply markup on a document. When reviewing documents, you can annotate and redact documents to hide confidential information. You can preserve these markings during the export process. During review, you may want to further tag documents based on criteria like responsive vs non-responsive. Tags are customizable to meet the needs of your review process. You can also use the annotation tool to annotate and redact content in documents. Content with redactions and annotations will be exported in PDF form. Custodian Audit Activity \u2693\ufe0e Need to find if a user viewed a specific document or purged an item from their mailbox? Advanced eDiscovery is now integrated with the existing audit log search tool in the M365 compliance center. Using this embedded experience, you can use the Advanced eDiscovery custodian management tool to facilitate your investigation by easily accessing and searching the activity for custodians within your case. Audit has access to a broad and rich set of information around user activities across 30 Microsoft services send user and admin activity to Audit. This can help answer questions during a legal investigation like: What SharePoint files did this custodian view or share? Did the custodian read this message? While we cover Advanced Audit in more depth below, there is great benefit in understanding how a custodian interacts with data in the context of a legal investigation. Production \u2693\ufe0e Once your review is complete, you can export content from your Advanced eDiscovery case. You will need to consider where the data goes after exported out of Microsoft 365 to determine the export options that fit your needs. Currently, you can export files out in two formats: Loose files and PSTs (email is added to PSTs when possible) - Files are exported in a format that resembles the original directory structure seen by users in their native applications. For more information, see the Loose files and PST export structure section. Native files within the condensed directory structure - Files are exported in their native format along with a load file containing mapping and metadata for each file. Consider whether you require conversations to be exported as Conversation Files. These messages will be threaded together and exported in PDF format. Once export is complete, you will need to use AzCopy to download the results. While if you implement all the recommendations above you are set for a successful deployment of AeD, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on steps that allow you to learn the end-to-end process with minimal disruptions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Considerations \u2693\ufe0e The M365 compliance center provides two out-of-box role groups, eDiscovery Manager and eDiscovery Administrator, that include the required roles to complete eDiscovery tasks. An eDiscovery Manager will only have access to cases that they create or are assigned to. An eDiscovery Administrator can access all eDiscovery cases. You can create and define custom role groups in order to manage a subset of eDiscovery tasks. Assign eDiscovery permissions in the Security & Compliance Center - Microsoft 365 Compliance Consider using Compliance Boundaries to control the content locations (such as mailboxes, OneDrive locations or SharePoint sites) that your eDiscovery Manager is able to search. They can also be used to control access to eDiscovery cases used to manage the legal, HR or other investigations within your organization. The need for compliance boundaries is often necessary for multi-national corporations that have to respect geographical boarders and regulations and for governments, which are often divided into different agencies. The analytics similarity threshold is set to 65% by default. When creating your case, discuss the expected similarity threshold with your legal team to ensure the value is correct. This setting cannot be changed once Analytics are run on the case data. When applying a hold to a custodian, an in-place hold is placed on their mailbox. This differs from a Litigation Hold in that it can be query based. There is also no limit to the number of in-place holds that can be applied to a mailbox or site. The holds within Advanced eDiscovery should be used for legal preservation and not for overall governance in your organization . If you require additional governance policies, please use the Microsoft 365 Retention policies. When attorney-client privilege detection is enabled, all documents in a review set will be processed by the attorney-client privilege detection model when you analyze the data in the review set. The model uses machine leaning to determine the likelihood that the content is legal in nature. It will also compare the participants of the document against the pre-submitted list of attorneys for your organization. To leverage the export option to produce the redacted PDFs instead of files in their native format, you must first use the action to convert all redacted files to PDF within your review set When uploading non-Microsoft 365 data into your review set, all custodians that you will be associating the data with still require the appropriate license. Microsoft 365 eDiscovery tools now incorporate decryption of encrypted files that are attached to email messages and sent in Exchange Online. Additionally, encrypted documents stored in SharePoint Online and OneDrive for Business are decrypted in Advanced eDiscovery. You can review and query the decrypted file in the review set. For more information, see Decryption in Microsoft 365 eDiscovery tools . Advanced eDiscovery supports double-byte character set languages (these include Simplified Chinese, Traditional Chinese, Japanese, and Korean, which are collectively known as CJK languages) when querying the data within a review set, tagging the data within a review set and when analyzing the data. At the current time, we do not support OCR of CJK characters from image files. Query based holds and the relevance module do not support CJK languages. The goal of the APIs is to reduce some of the risk with repetitive processes that can be error prone. At the current time, four out of the eight eDiscovery APIs are available in Beta. The APIs are set up to deliver on 2 scenarios. Automating common processes and task by taking jobs that are repeatable and creating an application. Consider things like kicking off an email once the review set creation job is complete or automatically searching all Teams that a custodian is currently a member of. Integration with existing systems, whether they be custom or a common industry tool. Helpful Resources \u2693\ufe0e Understanding how and what types of content is stored in a mailbox is key to a successful eDiscovery posture. An exchange mailbox stores so much more than just email messages. Your calendar items, tasks, Skype messages, Teams messages, Voicemails, Forms, Sway, To-Do, Yammer conversations and so much more are stored in either user or group mailboxes. An understanding of where content is stored in Sharepoint based on the type of hold can be key during an investigation. Consider reading this blog that covers the lifecycle of an item in Sharepoint. Teams 1:1 and 1:N chats are stored in the user mailbox. Teams conversations are stored in the Team Group mailbox. Items that are uploaded to chats are stored in the user OneDrive location. Items that are uploaded to conversations are stored in the Team Sharepoint site. eDiscovery of messages and files in private channels works differently than in standard channels. To learn more, see eDiscovery of private channels . Teams chat content that is associated with a guest user is stored in a cloud-based storage location and can be searched for using eDiscovery. This includes searching for content in 1:1 and 1:N chat conversations in which a guest user is a participant with other users in your organization. You can also search for private channel messages in which a guest user is a participant and search for content in guest:guest chat conversations where the only participants are guest users. You can add inactive mailboxes, Microsoft Teams, Yammer Groups, Office 365 Groups, and distribution groups to the list of mailboxes to search. Dynamic distribution groups are not supported. If you add Microsoft Teams, Yammer Groups, or Office 365 Groups, the group or team mailbox is searched; the mailboxes of the group members are not searched. Cloud links or modern attachments are items attached to messages in either Teams or Exchange. Cloud links differ from legacy attachments in that a copy of the item is not stored along with the message. Cloud attachments are a pointer to the location (in either OneDrive or Sharepoint) that the item is stored. Contextual conversation review enables you to review a single message that matches your query within the context of the conversation. At the current time, 4/8 of the eDiscovery APIs in Microsoft Graph are available in beta. The APIs can be used to automate or customize your workflow to reduce redundant tasks. For instance, you can create a PowerBI Dashboard that will give you real time case statistics or custodian reports. One compliance story with Microsoft 365 Advanced eDiscovery \u2693\ufe0e Insider risk management is a compliance solution in Microsoft 365 that helps minimize internal risks by enabling you to detect, investigate, and act on malicious and inadvertent activities in your organization. Insider risk policies allow you to define the types of risks to identify and detect in your organization, including acting on cases and escalating cases to Microsoft Advanced eDiscovery if needed. The content identified for escalation from IRM is automatically added to a review set in a case within Advanced eDiscovery. For the IRM or CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to be a member of the eDiscovery Manager role group in the Security and Compliance center. Communication compliance is an insider risk solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and act on inappropriate messages in your organization. Should you need to further investigate messages identified by your communication compliance policy, you can use the Escalate for Investigation control to create a new Advanced eDiscovery case. You will provide a name and notes for the new case, and user who sent the message matching the policy is automatically assigned as the case custodian. The content identified for escalation from CC is automatically added to a review set within a case in Advanced eDiscovery. For CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to be a member of the eDiscovery Manager role group in the Security and Compliance center. Having a strong information governance and records management posture ensures that content that needs to be retained is retained in-place and content that does not need to be retained is deleted. The downstream effects of a strong information governance and records management posture should be considered for your eDiscovery strategy. Less data means less risk and lower litigation costs. Microsoft eDiscovery tools support items encrypted with Microsoft encryption technologies. These technologies include Office Message Encryption, Azure Rights Management, and Microsoft Information Protection (specifically sensitivity labels). If a file that is encrypted with a Microsoft encryption technology is attached to an email message or located on a SharePoint or OneDrive account, those encrypted items are decrypted when the search results are prepared for preview, added to a review set in Advanced eDiscovery, and exported. This allows eDiscovery managers to view the content of encrypted email attachments and site documents when previewing search results, and review them after they have been added to a review set in Advanced eDiscovery. Advanced Audit \u2693\ufe0e Advanced Audit aims to expand on the capabilities of the Microsoft 365 unified auditing capabilities by offering additional features. The retention of audit logs for Exchange, SharePoint, and Azure Active Directory activities for each licensed user can be extended from 90 days to 1 year, by default. You can now create custom audit log retention policies for the services mentioned, allowing you to target records generated in the other services that are not covered by the default retention policy for periods up to 1 year. There are additional Exchange Online and SharePoint Online events captured which are crucial for conducting forensic and compliance investigations. These new events help investigators understand if mail items were accessed through the mail sync and mail bind operation. This is extremely helpful to organizations with regulatory obligations that require breach notifications because now they have the ability to scope mail items that may have been compromised to reduce fines and penalties. Customers will receive additional bandwidth when accessing audit data through the Office 365 Management Activity API based on the new tenant-level bandwidth quota. When you are conducting an investigation, it is not just about the content. You may need to investigate an individual user\u2019s behavior and activity more deeply. These activities can be reviewed through the unified audit log. Best Practices \u2693\ufe0e While the advanced audit features are going to be key for many of our customers to address their compliance requirements, it is also important for all customers to start with a basic understanding of the unified audit log. Many organizations consider the information contained in the audit logs to be sensitive in nature. As such, formulate a plan and execute how you will manage access to view those logs. That access is granted through the View-Only Audit Logs or Audit Logs roles in Exchange Online. These roles are managed in the Exchange admin center (EAC) and not in the M365 compliance center. Before you start, please check that the audit log is enabled by navigating to the Audit solution in the M365 compliance center. If you see a banner stating that auditing needs to be turned on, see link . Make sure your staff knows how to search and export the audit logs using the UI. There are reference links in the appendix to point them to resources that can help guide them. Follow the steps in the Helpful Resources section below to enable mailbox audit logging for all users. Once you have the basics down, it is time to plan how you will implement the advanced audit features. If your organization has decided not to license all your users with one of the E5 licenses that enable the advanced features, you will need to identify the population that warrants the additional oversight and longer-term retention of their activities to assign them E5 licenses. Decide if the default advanced retention policy works for you. By default, the audit records for Exchange, SharePoint, and Azure Active Directory are kept for one year. You may require that those records be kept for a shorter or longer period of time. Decide on the length of your audit retention for the activities in the other services not covered by the default policy mentioned above. Create a retention policy to retain your data for the appropriate amount of time. You can use an audit log retention policy to modify the default retention policy, or keep other data for longer than 90 days, up to 1 year. Additionally, an Audit add-on license for 10-year retention can allow records to be stored for long-term retention. Conduct forensic and compliance investigations by providing access to crucial events such as when mail items were accessed, when mail items were replied to and forwarded, and when and what a user searched for in Exchange Online and SharePoint Online. If you have a need to export data or integrate with a Security Information Event Management (SIEM) solution, you will need staff that are familiar with APIs or work with a partner. If you have a need to automate some of your audit search activities or need to perform very large searches, we recommend having resources that are comfortable using PowerShell cmdlets in Exchange Online and M365 compliance center. Considerations \u2693\ufe0e To manage audit log retention policies, you will need to be assigned the Organization Configuration role in the M365 compliance center. You can have a maximum of 50 audit log retention policies in your organization. To benefit from user-level Advanced Audit capabilities, a user needs to be assigned an E5 license. The higher bandwidth access to the API does not change the standard documented latencies for activities. When performing a search in the Audit solution that spans a timeframe longer than 90 days, you will receive a warning indicating that only users that have the proper licensing applied will return activities beyond the 90 day window. While not directly related to Advanced Audit, it is important to note that audit logging for Power BI isn't enabled by default. To search for Power BI activities in the audit log, you must enable auditing in the Power BI admin portal. Helpful Resources \u2693\ufe0e A list of the additional events included with Advanced Audit as well as an explanation of each can be found here . For details on creating and managing your audit retention policies, please use this link . For more information on the high-bandwidth access to the Office 365 Management Activity API you can read about it here . For instructions on how to enable Power BI logs see the \"Audit logs\" section in Power BI admin portal . This article includes a table indicating the time it takes for corresponding records to be returned for the different services in Office 365. Follow the steps outlined here to enable mailbox audit logging for user without an E5 licenses. Appendix - Additional Resources \u2693\ufe0e This section contains links to the information regarding license requirements and provides additional links to additional information related to Advanced eDiscovery. Advanced eDiscovery License Requirements \u2693\ufe0e Before you get started with Advanced eDiscovery, you should confirm your Microsoft 365 subscriptions and any add-ons. To access and use Advanced eDiscovery, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 eDiscovery & Audit add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Discovery & Audit add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Discovery & Audit add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions) Advanced Audit License Requirements \u2693\ufe0e Before you get started with Advanced Audit, you should confirm your Microsoft 365 subscription and any add-ons. To access and use Advanced Audit, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 eDiscovery & Audit add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Discovery & Audit add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Discovery & Audit add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Adanced eDiscovery and Advanced Audit"},{"location":"dag/aed-audit/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Advanced eDiscovery Advanced Audit The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while providing workflows that respond to needs of investigations in an efficient, repeatable, and defensible manner.","title":"Your Deployment Plan"},{"location":"dag/aed-audit/#advanced-ediscovery","text":"The Advanced eDiscovery solution provides customers with the ability to identify, preserve, collect, process, analyze, review and product content that's responsive to your organization's internal and external investigations. Discovering and managing data is challenging. To help solve these challenges, we provide customers with tools that enable them to do more in-place eDiscovery in Microsoft 365, thereby reducing risks associated with either creating multiple copies or exporting content outside of your security and compliance boundaries. Using Advanced eDiscovery, you can reduce the content in-place and only export matter relevant content.","title":"Advanced eDiscovery"},{"location":"dag/aed-audit/#best-practices","text":"To help frame the Advanced eDiscovery solution, it is important to note that our capabilities align with the eDiscovery Reference Model (EDRM) workflow as shown in figure 1. Within Advanced eDiscovery, we have enhanced identification, preservation, and collection from core eDiscovery with things like custodian management and advanced indexing. On top of this, to further cull and reduce data intelligently, in Advanced eDiscovery, provides capabilities to process, review and analyze your data so that what you export is minimized. See figure 2 below for a suggested linear workflow.","title":"Best Practices"},{"location":"dag/aed-audit/#workflows","text":"In the suggested workflows below you have the ability to hit the ground running in implementing Advanced eDiscovery in your tenant.","title":"Workflows"},{"location":"dag/aed-audit/#basic-workflow","text":"Create a case in Advanced eDiscovery. Identify your custodial and non-custodial source locations and add to case for advanced indexing. Create a search on identified source locations Add your results to a Review Set Further reduce content in your review set using the Analytics to find near duplicates and thread messages Export out of AeD","title":"Basic Workflow"},{"location":"dag/aed-audit/#advanced-workflow","text":"Create a case in Advanced eDiscovery. Identify your custodial and non-custodial source locations and add to case for advanced indexing. Remediate any processing errors Create and send legal hold notifications to custodians Create and run a search on identified source locations Add your results to a review set. Select the options to include modern attachments as well as contextual conversation review. Further reduce using Analyze to group together near duplicates and email threads, and identify content that is potentially privileged . Review the content within your review set for responsiveness using tags. Annotate and Redact documents Export out only case relevant content","title":"Advanced Workflow"},{"location":"dag/aed-audit/#next-steps-workflow","text":"Set up attorney-client privilege Custodian Audit Activity Themes","title":"Next Steps Workflow"},{"location":"dag/aed-audit/#case-management","text":"When navigating to the compliance center, you will see an overview of all cases in Advanced eDiscovery. Think of a case as the container for your legal matter. The case will include all searches, holds, hold notifications, reviews, and exports. Note that the name of your case cannot be changed later, careful thought should be used in creating a naming convention that allows all in your organization to follow and understand. If connecting to a matter management tool, please ensure that you use the same naming convention. When creating a new case, you have the opportunity to adjust your analytics settings, enable OCR, adjust your settings for Themes, configure Ignore text, and add any additional members to the case. As mentioned below in considerations, the similarity threshold is set to 65% by default. This means that when running the analytics job, the application will group together items that are within 65% similar to another document. You can enhance it if you need. The Themes functionality analyzes documents with text in a review set to parse out common clusters or themes that appear across all the documents in the review set. Consider selecting Adjust Maximum Number Of Themes Dynamically to ensure that you can still take advantage of the feature even if there are not enough documents to create the desired number of themes. There are situations where certain text will diminish the quality of analytics, such as lengthy disclaimers that get added to email messages regardless of the content of the email. If you know of text that should be ignored, you can exclude it from analytics by specifying the text string and the analytics functionality (Near-duplicates, Email threading, Themes, and Relevance) that the text should be excluded for. Using regular expressions (RegEx) as ignored text is also supported. OCR processing will be run on image files when sources are added to a case during the advanced indexing job. This means that text in image files that matches the search criteria will be returned in a collection search.","title":"Case Management"},{"location":"dag/aed-audit/#source-location-management","text":"A user is so much more than their mailbox and their OneDrive site. They are able to collaborate in Teams, Yammer and Sharepoint. They use third party tools like Bloomberg, Facebook and more. When using Advanced eDiscovery, you can associate other data locations to a custodian beyond their mailbox and OneDrive site alone. Once your legal team has identified a custodian, you can use the Data Sources tab in Advanced eDiscovery to manage the following: User mailbox User OneDrive site Any Teams that they are currently a member of Any Yammer networks (in native mode) Sharepoint sites a custodian may have accessed or contributed to Custodians and source locations can be added on-by-one in the user interface using the picker or they can be added in bulk using the Import Custodian feature. If your legal team has given you a list of custodians, consider using the custodian template to import your custodial locations. For tips on how to populate the .csv, please follow our guidance found here . The Data Sources tab within an Advanced eDiscovery case contains a list of all custodians that have been added to the case. After you add custodians to a case, details about each custodian are automatically collected from Azure Active Directory and are viewable in Advanced eDiscovery. You may have additional data locations located within Microsoft 365 that do not need to be associated with a custodian. These locations are typically group mailboxes or SharePoint sites. You can still add these non-custodial data sources to your case in order to take advantage of the advanced indexing, search, preservation, analytics and review. Not all documents that you need to analyze in Advanced eDiscovery are located within Microsoft 365. You can also upload items that are not located in Microsoft 365 later in the workflow directly into a review set. This would be content like on-premises exchange data or local files. Keep in mind that custodians must be added to the case before you can upload and associate non-Microsoft 365 data to them. Non-Microsoft 365 data must be a file type that is supported by Advanced eDiscovery. For more information, see Supported file types in Advanced eDiscovery .","title":"Source Location Management"},{"location":"dag/aed-audit/#processing","text":"Once a source location has been added to a case, any content that is partially indexed will be processed. Content can be partially indexed for a number of reasons including the existence of images, unsupported file types or when indexing file size limits are encountered. All items (including the content and metadata) are reindexed so that all data in the review set is fully searchable during the review of the case data. Reindexing the data results in thorough and fast searches when you search the data in the review set during the case investigation. After the indexing job is complete, you can see a report of the effectiveness of the job. The graph will give you the number of items that were added to the hybrid index where Advanced eDiscovery stores the reprocessed content. You will also have the opportunity to remediate any errors including decryption of content that was encrypted using third party encryption tools.","title":"Processing"},{"location":"dag/aed-audit/#preservation","text":"Using the Advanced eDiscovery hold capabilities, you can place a hold on custodial data including their collaborative data sources. When you place content locations on hold, content is held until you release the custodian, remove a specific data location, or delete the hold policy entirely. Custodian hold policies are managed when adding locations as a source in your case. When adding a custodial data source, you will have the opportunity to decide whether you would like the locations placed on hold. As mentioned in the Helpful Resources section below, Channel conversations that are part of a Microsoft Teams channel are stored in the mailbox that is associated with the Team. Similarly, files that team members share in a channel are stored on the team's SharePoint site. Therefore, you have to place the Microsoft Team mailbox and SharePoint site on hold to retain conversations and files in a channel. Conversations that are part of the Chat list in Microsoft Teams are stored in the mailbox of the users who participate in the chat. Files that a user shares in Chat conversations are stored in the OneDrive for Business site of the user who shares the file. Therefore, you have to place the individual user mailboxes and OneDrive for Business sites on hold to retain conversations and files in the Chat list. If you the need to place a Microsoft 365 Group or Microsoft Team on hold for a specific custodian, consider mapping the group site and group mailbox to the custodian. If the Microsoft 365 Group or Microsoft Team is not attributable to a single custodian, consider adding the source to a non-custodial hold.","title":"Preservation"},{"location":"dag/aed-audit/#hold-notifications","text":"Once a custodian is added to a case in Advanced eDiscovery, your legal team can create and customize their legal hold notification workflow. The custodian communications tool lets legal teams configure the following notices and workflows: Issuance notice: A legal hold notice is issued (or initiated) by a notification from the legal department to custodians who may have relevant information about the case matter. This notice instructs the custodians to preserve any information that may be needed for discovery. Re-Issuance notice: During a case, custodians may be required to preserve additional content (or less content) than was previously requested. For this scenario, you can update the existing hold notice and re-issue it to custodians. Release notice: Once a matter is resolved and the custodian is no longer subject to a preservation requirement, the custodian can be released from the case. Additionally, you can notify the custodian that they are no longer required to preserve content and provide instructions about how to resume their normal work activity with regard to their data. Reminders and escalations: In some instances, just issuing a notice is not enough to satisfy legal discovery requirements. With each notification, legal teams can schedule a set of reminder and escalation workflows to automatically follow up with unresponsive custodians. Reminders: After a legal hold notice has been issued or re-issued to a set of custodians, an organization can set up reminders to alert unresponsive custodians. Escalations: In some cases, if a custodian remains unresponsive even after a set of reminders over a period of time, the legal team can set up an escalation workflow to notify unresponsive custodians and their manager. After you've defined the contents of the hold notice, you can set up the workflows around sending and managing the notification process . Notifications are email messages that are sent to notify and follow up with custodians. Every custodian added to the communication will receive the same notification. To set up and send a hold notice, you must include Issuance, Re-Issuance, and Release notifications.","title":"Hold Notifications"},{"location":"dag/aed-audit/#collection","text":"Using Searches in Advanced eDiscovery, you can collect case data from your Microsoft 365 data source locations. This includes the source content that was previously processed in the above step or any additional content source locations. When creating a search, you will define the source location as well as your query. Consider reducing the amount of data you collect by using the available query conditions . Once your search is complete, you will need to add the results to a review set. This job copies the data from its source location to a static Azure Blob storage container so that you can review the content from within your data boundaries. Upon initiating this job, you will need to name your review set and decide which additional settings are required for this specific review: Include All Document Versions From SharePoint: This setting will ingest all versions of the item from SharePoint or OneDrive. Only select this if there is a specific requirement to review all versions of a specific item. Contextual conversation review : Teams chats and conversations are stored as individual messages in the associated user or group mailbox. When selecting the option to include contextual conversation review, the Advanced eDiscovery solution will thread the messages together into a conversation format to provide full context. Enable Retrieval For Modern Attachments: With modern attachments, you can check a box to auto collect all cloud attachments to your users Teams, Yammer and Exchange conversations. This is familiar to your current process for reviewing regular attachments as families or email sets. If there are downstream processes that rely on these relationships, we ensure that we are able to preserve these relationships in the load file","title":"Collection"},{"location":"dag/aed-audit/#analysis","text":"Using the analytics and machine learning capabilities in Advanced eDiscovery, you can reduce the amount of data to review.","title":"Analysis"},{"location":"dag/aed-audit/#analyze","text":"The first step you will take after your search results are added to your review set will be to run the analytics job . Analyze allows for the identification and grouping of exact and near-duplicate files. It also identifies and organizes emails into hierarchically structured groups of email Threads , based on the progressive inclusiveness of the emails. Sets of near duplicates (ND) documents are grouped together in an ND Set. For a document to join an ND Set, there must be at least one document in the ND Set with a level of resemblance exceeding the similarity.","title":"Analyze"},{"location":"dag/aed-audit/#themes","text":"Themes is a content-analytics application that identifies themes and thematic relationships across file collections. The application to identify interdependencies between themes allows users to browse associatively across the collection, navigating intuitively from theme to related theme. By generating meaningful labels for each thematic group, Themes provides an immediate snapshot of a file collection. In early case assessment and investigations, Themes enables litigators and analysts to intuitively acquire an informed and rapid overview of the data set. Keep in mind that increasing the \u201cNumber of themes\u201d can affect the ability of a theme to generalize. The higher the number of themes, the more granular they are. For example, if a set of 50 themes produces themes such as \u201cBasketball, Spurs, Clippers, Lakers\u201d, a set of 300 themes may include separate themes such as \u201cSpurs\u201d, \u201cClippers\u201d, \u201cLakers\u201d. If the user had no awareness of the theme \u201cBasketball\u201d and uses this feature for Early Case Assessment (ECA), seeing the theme \u201cBasketball\u201d could be useful. If the clustering is too granular (too many themes), the user may never see the word \u201cBasketball\u201d and may not know that Spurs and Clippers are good Basketball themes to review rather than items that go on boots and are used for hair.","title":"Themes"},{"location":"dag/aed-audit/#attorney-client-privledge","text":"When attorney-client privilege detection is enabled, all documents in a review set will be processed by the attorney-client privilege detection model when you analyze the data in the review set. The model uses machine learning to determine the likelihood that a document contains content that is legal in nature. When setting up attorney-client privilege detection, you will need to submit a list of attorneys for your organization. The model will compare the participants of the document with the attorney list to determine if any attorneys are participants.","title":"Attorney-Client Privledge"},{"location":"dag/aed-audit/#relevance","text":"The relevance module identifies and ranks files by relevance, which assists with early case assessment, document culling and review. Once the trained sample of files are reviewed and tagged by a human expert as Relevant or Not Relevant, the model will rank the relevance of all files in your case. There will be more information on the Relevance module in next version of this document.","title":"Relevance"},{"location":"dag/aed-audit/#review","text":"The review portion of the eDiscovery process can be the most time consuming and costly step. Using Advanced eDiscovery, you can cull the data in order to only produce the relevant data. A review set is simply a static set of documents that you can analyze, query, tag, and export.","title":"Review"},{"location":"dag/aed-audit/#review-set","text":"Advanced eDiscovery allows you to further query and filter data within a review set so that you can focus on a subset of documents. You can build a query by using a combination of keywords, properties, and conditions in the Keywords condition. You can also group conditions as a block (called a condition group) to build a more complex query. For a list and description of metadata properties that you can search, see Document metadata fields in Advanced eDiscovery . Once you are ready to review the case data, Advanced eDiscovery displays content via several viewers each with different purposes. The various viewers can be used by clicking on any document within a review set. Above the content viewing pane, you will be able to view metadata for each document within your review set. The Native viewer displays the richest view of a document. It supports hundreds of file types and is meant to display the truest to native experience possible. The Text viewer provides a view of the extracted text of a file. It ignores any embedded images and formatting but is very effective if you are trying to understand the content quickly. The Annotate view provides features that allow users to apply markup on a document. When reviewing documents, you can annotate and redact documents to hide confidential information. You can preserve these markings during the export process. During review, you may want to further tag documents based on criteria like responsive vs non-responsive. Tags are customizable to meet the needs of your review process. You can also use the annotation tool to annotate and redact content in documents. Content with redactions and annotations will be exported in PDF form.","title":"Review set"},{"location":"dag/aed-audit/#custodian-audit-activity","text":"Need to find if a user viewed a specific document or purged an item from their mailbox? Advanced eDiscovery is now integrated with the existing audit log search tool in the M365 compliance center. Using this embedded experience, you can use the Advanced eDiscovery custodian management tool to facilitate your investigation by easily accessing and searching the activity for custodians within your case. Audit has access to a broad and rich set of information around user activities across 30 Microsoft services send user and admin activity to Audit. This can help answer questions during a legal investigation like: What SharePoint files did this custodian view or share? Did the custodian read this message? While we cover Advanced Audit in more depth below, there is great benefit in understanding how a custodian interacts with data in the context of a legal investigation.","title":"Custodian Audit Activity"},{"location":"dag/aed-audit/#production","text":"Once your review is complete, you can export content from your Advanced eDiscovery case. You will need to consider where the data goes after exported out of Microsoft 365 to determine the export options that fit your needs. Currently, you can export files out in two formats: Loose files and PSTs (email is added to PSTs when possible) - Files are exported in a format that resembles the original directory structure seen by users in their native applications. For more information, see the Loose files and PST export structure section. Native files within the condensed directory structure - Files are exported in their native format along with a load file containing mapping and metadata for each file. Consider whether you require conversations to be exported as Conversation Files. These messages will be threaded together and exported in PDF format. Once export is complete, you will need to use AzCopy to download the results. While if you implement all the recommendations above you are set for a successful deployment of AeD, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on steps that allow you to learn the end-to-end process with minimal disruptions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact.","title":"Production"},{"location":"dag/aed-audit/#considerations","text":"The M365 compliance center provides two out-of-box role groups, eDiscovery Manager and eDiscovery Administrator, that include the required roles to complete eDiscovery tasks. An eDiscovery Manager will only have access to cases that they create or are assigned to. An eDiscovery Administrator can access all eDiscovery cases. You can create and define custom role groups in order to manage a subset of eDiscovery tasks. Assign eDiscovery permissions in the Security & Compliance Center - Microsoft 365 Compliance Consider using Compliance Boundaries to control the content locations (such as mailboxes, OneDrive locations or SharePoint sites) that your eDiscovery Manager is able to search. They can also be used to control access to eDiscovery cases used to manage the legal, HR or other investigations within your organization. The need for compliance boundaries is often necessary for multi-national corporations that have to respect geographical boarders and regulations and for governments, which are often divided into different agencies. The analytics similarity threshold is set to 65% by default. When creating your case, discuss the expected similarity threshold with your legal team to ensure the value is correct. This setting cannot be changed once Analytics are run on the case data. When applying a hold to a custodian, an in-place hold is placed on their mailbox. This differs from a Litigation Hold in that it can be query based. There is also no limit to the number of in-place holds that can be applied to a mailbox or site. The holds within Advanced eDiscovery should be used for legal preservation and not for overall governance in your organization . If you require additional governance policies, please use the Microsoft 365 Retention policies. When attorney-client privilege detection is enabled, all documents in a review set will be processed by the attorney-client privilege detection model when you analyze the data in the review set. The model uses machine leaning to determine the likelihood that the content is legal in nature. It will also compare the participants of the document against the pre-submitted list of attorneys for your organization. To leverage the export option to produce the redacted PDFs instead of files in their native format, you must first use the action to convert all redacted files to PDF within your review set When uploading non-Microsoft 365 data into your review set, all custodians that you will be associating the data with still require the appropriate license. Microsoft 365 eDiscovery tools now incorporate decryption of encrypted files that are attached to email messages and sent in Exchange Online. Additionally, encrypted documents stored in SharePoint Online and OneDrive for Business are decrypted in Advanced eDiscovery. You can review and query the decrypted file in the review set. For more information, see Decryption in Microsoft 365 eDiscovery tools . Advanced eDiscovery supports double-byte character set languages (these include Simplified Chinese, Traditional Chinese, Japanese, and Korean, which are collectively known as CJK languages) when querying the data within a review set, tagging the data within a review set and when analyzing the data. At the current time, we do not support OCR of CJK characters from image files. Query based holds and the relevance module do not support CJK languages. The goal of the APIs is to reduce some of the risk with repetitive processes that can be error prone. At the current time, four out of the eight eDiscovery APIs are available in Beta. The APIs are set up to deliver on 2 scenarios. Automating common processes and task by taking jobs that are repeatable and creating an application. Consider things like kicking off an email once the review set creation job is complete or automatically searching all Teams that a custodian is currently a member of. Integration with existing systems, whether they be custom or a common industry tool.","title":"Considerations"},{"location":"dag/aed-audit/#helpful-resources","text":"Understanding how and what types of content is stored in a mailbox is key to a successful eDiscovery posture. An exchange mailbox stores so much more than just email messages. Your calendar items, tasks, Skype messages, Teams messages, Voicemails, Forms, Sway, To-Do, Yammer conversations and so much more are stored in either user or group mailboxes. An understanding of where content is stored in Sharepoint based on the type of hold can be key during an investigation. Consider reading this blog that covers the lifecycle of an item in Sharepoint. Teams 1:1 and 1:N chats are stored in the user mailbox. Teams conversations are stored in the Team Group mailbox. Items that are uploaded to chats are stored in the user OneDrive location. Items that are uploaded to conversations are stored in the Team Sharepoint site. eDiscovery of messages and files in private channels works differently than in standard channels. To learn more, see eDiscovery of private channels . Teams chat content that is associated with a guest user is stored in a cloud-based storage location and can be searched for using eDiscovery. This includes searching for content in 1:1 and 1:N chat conversations in which a guest user is a participant with other users in your organization. You can also search for private channel messages in which a guest user is a participant and search for content in guest:guest chat conversations where the only participants are guest users. You can add inactive mailboxes, Microsoft Teams, Yammer Groups, Office 365 Groups, and distribution groups to the list of mailboxes to search. Dynamic distribution groups are not supported. If you add Microsoft Teams, Yammer Groups, or Office 365 Groups, the group or team mailbox is searched; the mailboxes of the group members are not searched. Cloud links or modern attachments are items attached to messages in either Teams or Exchange. Cloud links differ from legacy attachments in that a copy of the item is not stored along with the message. Cloud attachments are a pointer to the location (in either OneDrive or Sharepoint) that the item is stored. Contextual conversation review enables you to review a single message that matches your query within the context of the conversation. At the current time, 4/8 of the eDiscovery APIs in Microsoft Graph are available in beta. The APIs can be used to automate or customize your workflow to reduce redundant tasks. For instance, you can create a PowerBI Dashboard that will give you real time case statistics or custodian reports.","title":"Helpful Resources"},{"location":"dag/aed-audit/#one-compliance-story-with-microsoft-365-advanced-ediscovery","text":"Insider risk management is a compliance solution in Microsoft 365 that helps minimize internal risks by enabling you to detect, investigate, and act on malicious and inadvertent activities in your organization. Insider risk policies allow you to define the types of risks to identify and detect in your organization, including acting on cases and escalating cases to Microsoft Advanced eDiscovery if needed. The content identified for escalation from IRM is automatically added to a review set in a case within Advanced eDiscovery. For the IRM or CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to be a member of the eDiscovery Manager role group in the Security and Compliance center. Communication compliance is an insider risk solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and act on inappropriate messages in your organization. Should you need to further investigate messages identified by your communication compliance policy, you can use the Escalate for Investigation control to create a new Advanced eDiscovery case. You will provide a name and notes for the new case, and user who sent the message matching the policy is automatically assigned as the case custodian. The content identified for escalation from CC is automatically added to a review set within a case in Advanced eDiscovery. For CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to be a member of the eDiscovery Manager role group in the Security and Compliance center. Having a strong information governance and records management posture ensures that content that needs to be retained is retained in-place and content that does not need to be retained is deleted. The downstream effects of a strong information governance and records management posture should be considered for your eDiscovery strategy. Less data means less risk and lower litigation costs. Microsoft eDiscovery tools support items encrypted with Microsoft encryption technologies. These technologies include Office Message Encryption, Azure Rights Management, and Microsoft Information Protection (specifically sensitivity labels). If a file that is encrypted with a Microsoft encryption technology is attached to an email message or located on a SharePoint or OneDrive account, those encrypted items are decrypted when the search results are prepared for preview, added to a review set in Advanced eDiscovery, and exported. This allows eDiscovery managers to view the content of encrypted email attachments and site documents when previewing search results, and review them after they have been added to a review set in Advanced eDiscovery.","title":"One compliance story with Microsoft 365 Advanced eDiscovery"},{"location":"dag/aed-audit/#advanced-audit","text":"Advanced Audit aims to expand on the capabilities of the Microsoft 365 unified auditing capabilities by offering additional features. The retention of audit logs for Exchange, SharePoint, and Azure Active Directory activities for each licensed user can be extended from 90 days to 1 year, by default. You can now create custom audit log retention policies for the services mentioned, allowing you to target records generated in the other services that are not covered by the default retention policy for periods up to 1 year. There are additional Exchange Online and SharePoint Online events captured which are crucial for conducting forensic and compliance investigations. These new events help investigators understand if mail items were accessed through the mail sync and mail bind operation. This is extremely helpful to organizations with regulatory obligations that require breach notifications because now they have the ability to scope mail items that may have been compromised to reduce fines and penalties. Customers will receive additional bandwidth when accessing audit data through the Office 365 Management Activity API based on the new tenant-level bandwidth quota. When you are conducting an investigation, it is not just about the content. You may need to investigate an individual user\u2019s behavior and activity more deeply. These activities can be reviewed through the unified audit log.","title":"Advanced Audit"},{"location":"dag/aed-audit/#best-practices_1","text":"While the advanced audit features are going to be key for many of our customers to address their compliance requirements, it is also important for all customers to start with a basic understanding of the unified audit log. Many organizations consider the information contained in the audit logs to be sensitive in nature. As such, formulate a plan and execute how you will manage access to view those logs. That access is granted through the View-Only Audit Logs or Audit Logs roles in Exchange Online. These roles are managed in the Exchange admin center (EAC) and not in the M365 compliance center. Before you start, please check that the audit log is enabled by navigating to the Audit solution in the M365 compliance center. If you see a banner stating that auditing needs to be turned on, see link . Make sure your staff knows how to search and export the audit logs using the UI. There are reference links in the appendix to point them to resources that can help guide them. Follow the steps in the Helpful Resources section below to enable mailbox audit logging for all users. Once you have the basics down, it is time to plan how you will implement the advanced audit features. If your organization has decided not to license all your users with one of the E5 licenses that enable the advanced features, you will need to identify the population that warrants the additional oversight and longer-term retention of their activities to assign them E5 licenses. Decide if the default advanced retention policy works for you. By default, the audit records for Exchange, SharePoint, and Azure Active Directory are kept for one year. You may require that those records be kept for a shorter or longer period of time. Decide on the length of your audit retention for the activities in the other services not covered by the default policy mentioned above. Create a retention policy to retain your data for the appropriate amount of time. You can use an audit log retention policy to modify the default retention policy, or keep other data for longer than 90 days, up to 1 year. Additionally, an Audit add-on license for 10-year retention can allow records to be stored for long-term retention. Conduct forensic and compliance investigations by providing access to crucial events such as when mail items were accessed, when mail items were replied to and forwarded, and when and what a user searched for in Exchange Online and SharePoint Online. If you have a need to export data or integrate with a Security Information Event Management (SIEM) solution, you will need staff that are familiar with APIs or work with a partner. If you have a need to automate some of your audit search activities or need to perform very large searches, we recommend having resources that are comfortable using PowerShell cmdlets in Exchange Online and M365 compliance center.","title":"Best Practices"},{"location":"dag/aed-audit/#considerations_1","text":"To manage audit log retention policies, you will need to be assigned the Organization Configuration role in the M365 compliance center. You can have a maximum of 50 audit log retention policies in your organization. To benefit from user-level Advanced Audit capabilities, a user needs to be assigned an E5 license. The higher bandwidth access to the API does not change the standard documented latencies for activities. When performing a search in the Audit solution that spans a timeframe longer than 90 days, you will receive a warning indicating that only users that have the proper licensing applied will return activities beyond the 90 day window. While not directly related to Advanced Audit, it is important to note that audit logging for Power BI isn't enabled by default. To search for Power BI activities in the audit log, you must enable auditing in the Power BI admin portal.","title":"Considerations"},{"location":"dag/aed-audit/#helpful-resources_1","text":"A list of the additional events included with Advanced Audit as well as an explanation of each can be found here . For details on creating and managing your audit retention policies, please use this link . For more information on the high-bandwidth access to the Office 365 Management Activity API you can read about it here . For instructions on how to enable Power BI logs see the \"Audit logs\" section in Power BI admin portal . This article includes a table indicating the time it takes for corresponding records to be returned for the different services in Office 365. Follow the steps outlined here to enable mailbox audit logging for user without an E5 licenses.","title":"Helpful Resources"},{"location":"dag/aed-audit/#appendix-additional-resources","text":"This section contains links to the information regarding license requirements and provides additional links to additional information related to Advanced eDiscovery.","title":"Appendix - Additional Resources"},{"location":"dag/aed-audit/#advanced-ediscovery-license-requirements","text":"Before you get started with Advanced eDiscovery, you should confirm your Microsoft 365 subscriptions and any add-ons. To access and use Advanced eDiscovery, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 eDiscovery & Audit add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Discovery & Audit add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Discovery & Audit add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Advanced eDiscovery License Requirements"},{"location":"dag/aed-audit/#advanced-audit-license-requirements","text":"Before you get started with Advanced Audit, you should confirm your Microsoft 365 subscription and any add-ons. To access and use Advanced Audit, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 eDiscovery & Audit add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Discovery & Audit add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Discovery & Audit add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Advanced Audit License Requirements"},{"location":"dag/cm/","text":"Last updated: 05/07/2021 Compliance Manger is an end to end information compliance management solution in the Microsoft 365 compliance center that helps you understand your organization's compliance posture. Compliance Manager uses the inventory of data protection risk allowing you to manage the complexities of controls, adhering to regulations and certifications long with reporting needed for auditors. Overview \u2693\ufe0e Using Compliance Manager allows your organization to simplify compliance and start reducing the risk by completing the pre-built assessments targeting industries, standards, regulations or leveraging a custom assessment created by you. In addition to the assessments in the dashboard, this tool provides step-by-step guidance on open actions and by displaying a score for measuring compliance posture. The tool focuses on identifying gaps and controls needing updated and directs you how to improve these items drawing elements from NIST CSF (National Institute of Standards and Technology Cybersecurity Framework) and ISO (International Organization for Standardization), as well as from FedRAMP (Federal Risk and Authorization Management Program) and GDPR (General Data Protection Regulation of the European Union). With Compliance Manager you can: You can get and run Pre-built assessments for common industry and regional standards and regulations, or custom assessments to meet your unique compliance needs. Compliance Manager provides you built in workflow capabilities to help you efficiently complete your risk assessments through a single tool. Issues flagged provide you detailed step-by-step guidance on suggested improvement actions to help you comply with the standards and regulations that are most relevant for your organization. Compliance Manager Provides you an overall risk-based compliance score to help you understand your compliance posture by measuring your progress in completing improvement actions. Best Practices \u2693\ufe0e Updates to an action propagate tenant wide. Our recommendation is to accept the updates to have the latest guidance and improvement actions to meet a requirement. Global administrator will need to setup permission to use Compliance Manager. Roles are based on RBAC which grant the rights needed for different actions. Only users that are global admins or Compliance Manager Admins can create and modify an assessment. The person holding the global admin role for your organization can set user permissions in the Microsoft 365 compliance center, as well as in Azure Active Directory (Azure AD). Customers in US Government Community (GCC) High environments can only set user permissions and roles for Compliance Manager in Azure AD Using Compliance Manger is not a check mark or a guarantee if the recommendations are followed your organization is compliant. Use correctly formatted Excel files when working with Compliance Manager to prevent errors with the import process. Export any existing assessment before deleting it in case you need to add it back through the import process again. If you reassign an action that has a pending update, the direct link to the action in the reassignment email will break if the update is accepted after reassignment. You can fix this by re-assigning the action to the user after the update is accepted. Considerations \u2693\ufe0e Compliance Manager leverages key elements in its management of activities. We recommend understanding of controls, risk assessments, grouping the controls into an assessment, deploying the built-in assessments or modify to create a custom assessment along with how to monitor the progress of the each. Use the Compliance Manager quickstart to follow guidance on what items to do first while directing through steps to use the tool to its fullest. Compliance Manager auto scans the environment to update technical action status with the dashboard updating every 24hours. If you implement a control for example, you see the update the following day. Helpful Resources \u2693\ufe0e When you open Compliance Manager for the first time you will see a baseline score for your organization. For further details on your score, review how your compliance score is calculated. Review the FAQ for Compliance Manager answer a question you might have about using Compliance Score in the past and how it is part of Compliance Manager solution.","title":"Compliance Manager"},{"location":"dag/cm/#overview","text":"Using Compliance Manager allows your organization to simplify compliance and start reducing the risk by completing the pre-built assessments targeting industries, standards, regulations or leveraging a custom assessment created by you. In addition to the assessments in the dashboard, this tool provides step-by-step guidance on open actions and by displaying a score for measuring compliance posture. The tool focuses on identifying gaps and controls needing updated and directs you how to improve these items drawing elements from NIST CSF (National Institute of Standards and Technology Cybersecurity Framework) and ISO (International Organization for Standardization), as well as from FedRAMP (Federal Risk and Authorization Management Program) and GDPR (General Data Protection Regulation of the European Union). With Compliance Manager you can: You can get and run Pre-built assessments for common industry and regional standards and regulations, or custom assessments to meet your unique compliance needs. Compliance Manager provides you built in workflow capabilities to help you efficiently complete your risk assessments through a single tool. Issues flagged provide you detailed step-by-step guidance on suggested improvement actions to help you comply with the standards and regulations that are most relevant for your organization. Compliance Manager Provides you an overall risk-based compliance score to help you understand your compliance posture by measuring your progress in completing improvement actions.","title":"Overview"},{"location":"dag/cm/#best-practices","text":"Updates to an action propagate tenant wide. Our recommendation is to accept the updates to have the latest guidance and improvement actions to meet a requirement. Global administrator will need to setup permission to use Compliance Manager. Roles are based on RBAC which grant the rights needed for different actions. Only users that are global admins or Compliance Manager Admins can create and modify an assessment. The person holding the global admin role for your organization can set user permissions in the Microsoft 365 compliance center, as well as in Azure Active Directory (Azure AD). Customers in US Government Community (GCC) High environments can only set user permissions and roles for Compliance Manager in Azure AD Using Compliance Manger is not a check mark or a guarantee if the recommendations are followed your organization is compliant. Use correctly formatted Excel files when working with Compliance Manager to prevent errors with the import process. Export any existing assessment before deleting it in case you need to add it back through the import process again. If you reassign an action that has a pending update, the direct link to the action in the reassignment email will break if the update is accepted after reassignment. You can fix this by re-assigning the action to the user after the update is accepted.","title":"Best Practices"},{"location":"dag/cm/#considerations","text":"Compliance Manager leverages key elements in its management of activities. We recommend understanding of controls, risk assessments, grouping the controls into an assessment, deploying the built-in assessments or modify to create a custom assessment along with how to monitor the progress of the each. Use the Compliance Manager quickstart to follow guidance on what items to do first while directing through steps to use the tool to its fullest. Compliance Manager auto scans the environment to update technical action status with the dashboard updating every 24hours. If you implement a control for example, you see the update the following day.","title":"Considerations"},{"location":"dag/cm/#helpful-resources","text":"When you open Compliance Manager for the first time you will see a baseline score for your organization. For further details on your score, review how your compliance score is calculated. Review the FAQ for Compliance Manager answer a question you might have about using Compliance Score in the past and how it is part of Compliance Manager solution.","title":"Helpful Resources"},{"location":"dag/dag-resources/","text":"Last updated: 05/10/2021 One Compliance Story \u2693\ufe0e Our Data Classification solution will play an important role in not only your information protection strategy but also your information governance and records management deployment. Content Explorer will allow you to scan your content before you create any policies with zero change management. You will be able to see what sensitive information types (SITs) exist in your environment and create your own. These SITs can be leveraged to auto-apply retention, record, and sensitivity labels as well as trigger DLP policies. Activity Explorer provides the ability to monitor what\u2019s being done with your labeled content which will allow you to see the impact that the retention and records labels are having in your environment to help assess your protection and governance policy needs. Having a strong information governance and records management posture ensures that content that needs to be retained is retained in-place and content that does not need to be retained is deleted. The downstream effects of a strong information governance and records management posture should be considered for your governance strategy. Less data means less risk and lower litigation costs. Microsoft eDiscovery tools support items encrypted with Microsoft encryption technologies. These technologies include Office Message Encryption, Azure Rights Management, and sensitivity labels. If a file that is encrypted with a Microsoft encryption technology is attached to an email message or located on a SharePoint or OneDrive account, those encrypted items are decrypted when the search results are prepared for preview, added to a review set in Advanced eDiscovery, and exported. Should you need to further investigate messages identified by your communication compliance policy, you can use the Escalate for Investigation control to create a new Advanced eDiscovery case. You will provide a name and notes for the new case, and user who sent the message matching the policy is automatically assigned as the case custodian. Things to note for both Insider Risk Management and Communication Compliance integration with Advanced eDiscovery: - The underlying content of the escalation from IRM/CC is automatically added to a review set in the case in Advanced eDiscovery. You can put data sources on hold or run further searches on the custodians and locations that you deem relevant and add results as per relevance to the same or different review sets. - For the IRM or CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to have the eDiscovery Manager/Administrator privilege. With information in many locations organization need an easy way to be able to audit then activities across many different services in Microsoft 365. Advanced Audit helps organizations to conduct forensic and compliance investigations by increasing audit log retention required to conduct an investigation, providing access to crucial events that help determine scope of compromise, and faster access to Office 365 Management Activity API. Useful Links \u2693\ufe0e Ready to get started with Microsoft E5 Compliance? https://techcommunity.microsoft.com/t5/security-privacy-and-compliance/ready-to-get-started-with-microsoft-365-e5-compliance-adopt-with/ba-p/989785 Microsoft 365 Roadmap Website - has public details about when new features are in development and when the features are targeted to launch or are available. To see details about a particular product, filter the check boxes to select what product/s you are interested in. https://www.microsoft.com/en-us/microsoft-365/roadmap Microsoft 365 Compliance Documentation https://docs.microsoft.com/en-us/microsoft-365/compliance/ Knowledgebase from Customer Experience Engineering Team \u2693\ufe0e Ready to become the hero of your organization? Learn more about deploying Microsoft Information Protection & Compliance features with the resources below: Get started today! Join our Preview Program: https://aka.ms/MIPC/JoinPreviews & https://aka.ms/MIPC/Previews Visit all Community Resources Learn from our webinar series and YouTube video series: https://aka.ms/MIPC/Webinars & http://aka.ms/MIPC/YouTube Read up on our latest blog posts \u2013 https://aka.ms/MIPblog & https://aka.ms/CompBlog Train End Users for adoption of labels \u2013 http://aka.ms/MIPC/Blog-EnduserTraining_Sensitivity & http//aka.ms/MIPC/Blog-EndUserTraining_Retention Ask us on Yammer Follow us on Twitter using the tag #MicrosoftIP Email us \u2013 mipsccxe@microsoft.com NOTE: We encourage contacting the CxE team with any suggestions directly related to products, webinars, blogs, or ideas for additional training. All support issues should be directed through the appropriate channels of support or community forums.","title":"Resources"},{"location":"dag/dag-resources/#one-compliance-story","text":"Our Data Classification solution will play an important role in not only your information protection strategy but also your information governance and records management deployment. Content Explorer will allow you to scan your content before you create any policies with zero change management. You will be able to see what sensitive information types (SITs) exist in your environment and create your own. These SITs can be leveraged to auto-apply retention, record, and sensitivity labels as well as trigger DLP policies. Activity Explorer provides the ability to monitor what\u2019s being done with your labeled content which will allow you to see the impact that the retention and records labels are having in your environment to help assess your protection and governance policy needs. Having a strong information governance and records management posture ensures that content that needs to be retained is retained in-place and content that does not need to be retained is deleted. The downstream effects of a strong information governance and records management posture should be considered for your governance strategy. Less data means less risk and lower litigation costs. Microsoft eDiscovery tools support items encrypted with Microsoft encryption technologies. These technologies include Office Message Encryption, Azure Rights Management, and sensitivity labels. If a file that is encrypted with a Microsoft encryption technology is attached to an email message or located on a SharePoint or OneDrive account, those encrypted items are decrypted when the search results are prepared for preview, added to a review set in Advanced eDiscovery, and exported. Should you need to further investigate messages identified by your communication compliance policy, you can use the Escalate for Investigation control to create a new Advanced eDiscovery case. You will provide a name and notes for the new case, and user who sent the message matching the policy is automatically assigned as the case custodian. Things to note for both Insider Risk Management and Communication Compliance integration with Advanced eDiscovery: - The underlying content of the escalation from IRM/CC is automatically added to a review set in the case in Advanced eDiscovery. You can put data sources on hold or run further searches on the custodians and locations that you deem relevant and add results as per relevance to the same or different review sets. - For the IRM or CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to have the eDiscovery Manager/Administrator privilege. With information in many locations organization need an easy way to be able to audit then activities across many different services in Microsoft 365. Advanced Audit helps organizations to conduct forensic and compliance investigations by increasing audit log retention required to conduct an investigation, providing access to crucial events that help determine scope of compromise, and faster access to Office 365 Management Activity API.","title":"One Compliance Story"},{"location":"dag/dag-resources/#useful-links","text":"Ready to get started with Microsoft E5 Compliance? https://techcommunity.microsoft.com/t5/security-privacy-and-compliance/ready-to-get-started-with-microsoft-365-e5-compliance-adopt-with/ba-p/989785 Microsoft 365 Roadmap Website - has public details about when new features are in development and when the features are targeted to launch or are available. To see details about a particular product, filter the check boxes to select what product/s you are interested in. https://www.microsoft.com/en-us/microsoft-365/roadmap Microsoft 365 Compliance Documentation https://docs.microsoft.com/en-us/microsoft-365/compliance/","title":"Useful Links"},{"location":"dag/dag-resources/#knowledgebase-from-customer-experience-engineering-team","text":"Ready to become the hero of your organization? Learn more about deploying Microsoft Information Protection & Compliance features with the resources below: Get started today! Join our Preview Program: https://aka.ms/MIPC/JoinPreviews & https://aka.ms/MIPC/Previews Visit all Community Resources Learn from our webinar series and YouTube video series: https://aka.ms/MIPC/Webinars & http://aka.ms/MIPC/YouTube Read up on our latest blog posts \u2013 https://aka.ms/MIPblog & https://aka.ms/CompBlog Train End Users for adoption of labels \u2013 http://aka.ms/MIPC/Blog-EnduserTraining_Sensitivity & http//aka.ms/MIPC/Blog-EndUserTraining_Retention Ask us on Yammer Follow us on Twitter using the tag #MicrosoftIP Email us \u2013 mipsccxe@microsoft.com NOTE: We encourage contacting the CxE team with any suggestions directly related to products, webinars, blogs, or ideas for additional training. All support issues should be directed through the appropriate channels of support or community forums.","title":"Knowledgebase from Customer Experience Engineering Team"},{"location":"dag/ir-cc/","text":"Last updated: 05/10/2021 In today\u2019s climate one of the top concerns for security and compliance are the data leakage from insider risks. Studies point to insider risk from specific user events and activities; protecting your organization may seem impossible if one does not have insight or a way to identify the risk but worse if you cannot mitigate the risk you do not know about. With this in mind, let\u2019s get started with Microsoft 365 Insider Risk Management (IRM) and Communication Compliance (CC) solutions. Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: \u2022 Compliance Manager \u2022 Microsoft Compliance Configuration Analyzer (MCCA) \u2022 Communication Compliance \u2022 Insider Risk Management The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while protecting your intellectual property, stopping fraud or insider trading, plugging the sensitive data leaks, along with making the workplace safe. Communication Compliance \u2693\ufe0e Communication compliance is part of the new insider risk solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and take remediation actions for inappropriate messages in your organization. Pre-defined and custom policies allow you to scan internal and external communications for policy matches so they can be examined by designated reviewers. Reviewers can investigate communications in your organization that do not meet your standards, as identified through configurable rules, and take appropriate remediation actions to make sure that they are compliant with your organization's message standards. Communication compliance supports several company communications channels including those part of the Microsoft 365 solution such as Exchange email, Microsoft Teams, Yammer or Skype for Business, as well as a large number of third-party communication platforms integrated through available connectors such as Twitter, Facebook, and Bloomberg instant messages. More details on third-party connectors can be found here . Communication compliance policies in Microsoft 365 help you overcome many modern challenges associated with compliance and internal and external communications, including: Scanning increasing numbers of communication channels The increasing communication volumes Regulatory enforcement & the risk of fines Best Practices \u2693\ufe0e Let\u2019s establish some of the preparation that goes into start of execution of using communication compliance to help plan your deployment. Policy Definition \u2693\ufe0e While the usage of communication compliance is distinct to each organization and their business and regulatory requirements and the policies you define will need to be designed accordingly, the following criteria can be used to guide the initial creation of policies at most organizations. Decide whether your organization\u2019s use cases for the solution revolve around regulatory compliance, enforcing a code of conduct, preventing self-harm or harm to others, or monitoring external communications by specific employees (or more than one of these or other scenarios), and define policies based on this decision according to the following rules. For code of conduct policies: It is generally advised that you create policies that cover all employees. While code of conduct violations by employees in some roles may be more problematic than in other roles, a minimum set of rules must be met by all employees, so start with a single policy that is scoped to all employees. Code of conduct policies typically utilize the built-in classifiers for offensive language. Create a policy utilizing the classifiers for profanity, harassment, targeted harassment, adult images, gory images, and racy images (it is alternatively possible to create separate policies for some of these if you think they should be monitored by different auditors or the response time needed for different types of offenses may vary significantly). While it is possible to create your own trainable classifiers for handling specific offensive or non-compliant terms, it is generally easier to start with the built-in classifiers and only train or retrain your own classifiers if needed. In some organizations, it may not be necessary to detect all offenses, and configuring the policy to only create alerts to a given percentage of offensive language use may be effective enough, since if employees know their communications are being regularly monitoring that may be enough incentive for them to follow the rules. In other organizations where no exceptions can be allowed a 100% review percentage may be needed. It is possible to create overlapping rules for specific roles such as executives, people working with customers or people in special, external-facing roles, or policies targeting specific communication channels that can have higher exposure such as social media. Such roles can be more aggressive in their rules and have higher review percentages than rules for the general population. In most cases, for code of conduct policies you will want to monitor both internal and outbound communications. Monitoring inbound communications can also be useful for detecting potential sources of stress to your employees. For policies related to monitoring self-harm or threats to others, similar practices to the ones for offensive language apply, but it is generally advised to create a policy that is separate from offensive language, since this type of policy usually requires a quicker reaction time in order to avoid actual harm and you may want to monitor such alerts more diligently. You will also likely want to configure a 100% review for such policies. For meeting regulatory compliance requirements, you will typically create a custom policy with rules that are dictated by your regulatory requirements. Typically, you will create a policy starting with the regulatory compliance policy template and configure it with rules that utilize \u201cmessage (or attachment) contains any of these words\u201d and provide words or phrases frequently used in language that represents the type of risks you want to identify. For example, for detecting situations such as improper gifts you can define phrases like \u201ccomplimentary\u201d, \u201cgift\u201d, \u201cat no cost to you\u201d and \u201cour treat\u201d. For more complex requirements, you can create custom Sensitive Information Types (SIT) and use them in your policies. A custom SIT can use large dictionaries that are easier to maintain, combinations of different lists of words, complex conditions including operators (and/or/not) and near relationships between terms and more. Go to Data Classification page in M365 SCC, navigate to Sensitive Info Types tab. Click Create Info Type and use your dictionary to create a custom SIT. For more details, check this How to setup a keyword dictionary Go to Policies tab in Communication Compliance admin portal and click Create Policy. Choose Custom Policy from the drop-down menu and use custom create SIT in the Conditions And Percentages page of the New Policy Wizard along with other details as required. This method can require more effort to implement than a simple keyword list or a trainable classifier, so it is recommended that you start with the simpler option and assess your accuracy before committing to more complex policies based on sensitive info types. In most cases, regulatory compliance policies can be scoped to specific communications, in particular including only external communications or communications to/from specific organizations can significantly reduce the volume of alerts to review while keeping the relevant messages in scope. Communication compliance can also be used for monitoring communications through official channels (such as official communications by executives and PR people such as on Twitter feeds). While it is rare that an employee would intentionally commit policy violations in such channels, it is not as rare that an employee mixes up their personal account with the official one and send improper messages that way. Using Communication compliance to monitor such media can help rapidly detect potential offenses and delete the offending messages. In most cases you may want to utilize the built-in classifiers for offensive language, harassment, and the classifiers for gory, racy and adult images for these policies. If your organization is multi-national or have employees that communicate in multiple languages, contact Microsoft for access to the Offensive Language classifiers in different languages, currently in preview. If you do so, unless you know that all your auditors are fluent in all the languages in question, it is often recommended that you create separate policies for each of these languages, so you can assign in each policy reviewers that can read the language in question and properly assess the offenses. Since Communication compliance will attempt to detect the language in which a message is written and will use the right classifiers accordingly, it is generally not required to assign policies in specific languages to known speakers of those languages. Still, doing so can reduce false positives due to the fact that certain non-offensive words in some languages can be identical to offensive words in other languages, so if you have large known populations that communicate in specific languages (such as to people in specific countries where that language is the primary language in use) you can target such language-specific policies to those populations to make the solution more accurate. At this moment, Communication compliance gathers and analyzes messages on a 24-hour cycle, which starts at the moment a policy is enabled for the first time. You may want to plan the creation of policies that relate to time-sensitive matters (such as threats) so it completes at the same time when you expect your analysts to check daily for alerts, in order to minimize the delay in reviewing messages. For other types of policies some organizations prefer to align their creation with the end of the productive day for most employees so policies can be reviewed before the next day. While compliance alerts are often monitored by individuals specifically assigned to the role, assessment of noncompliance often requires escalation to other roles in the organization. It is recommended that before putting your policies in production you identify the appropriate stakeholders and personas in your organization to collaborate for remediation actions and alerts triaging in communication compliance. Some recommended personas to include in the end-to-end investigation workflow are human resources, compliance/privacy and legal. You may also want to involve people that are fluent in specific languages or that are familiar with the culture of specific regions since there may be local nuances that change the meaning of some phrases. It is often useful to create groups in Office 365 or channels in Teams including these persons to make obtaining feedback about these types of situations more efficient (though for obvious reasons assessment of offensive language or images is typically better handled 1:1). Also, in order to allow these persons to have direct access to the Communication compliance console, assign the required role groups to these groups or individuals. Before enabling the solution broadly in your production environment, you may consider testing the policies with a small set of production users or in a test environment while waiting for the necessary privacy and legal reviews in your organization. Bear in mind that evaluating it in a test environment will require that you generate simulated user content to create alerts that can be triaged and processed, so testing with a small group of users in a production environment is usually preferred. Use the anonymization feature in settings to pseudonymize display names for risky users to maintain privacy and prevent bias when reviewing alerts and taking appropriate actions within the tool. After creating a new policy, expect alerts to start arriving in 24 hours, though there may be additional delay in some cases. Investigating Alerts \u2693\ufe0e The first step to investigate issues detected by your policies is to review generated alerts in the Microsoft 365 compliance center. There are several areas in the compliance center to help you to quickly investigate alerts, depending on how you prefer to view alert grouping: Communication compliance home page : Here you will see: Alerts needing review listed from high to low severity. Select an alert to launch the alert details page and to start remediation actions. Recent policy matches listed by policy name. Resolved items listed by policy name. Escalations listed by policy name. Users with the most policy matches, listed from the most to the least number of matches. Alerts tab: Display alerts grouped by matched communication compliance policy. This view allows you to quickly see which communication compliance policies are generating the most alerts ordered by severity. Policies tab: Each policy listed includes the count of alerts that need review. Selecting a policy displays all the pending alerts for matches to the policy, select a specific alert to launch the policy details page and to start remediation actions. Considerations \u2693\ufe0e To make communication compliance available as a menu option in Microsoft 365 compliance center, you must be assigned the Supervisory Review Administrator role. You must create a new role group for reviewers with the Supervisory Review Administrator, Case Management, Compliance Administrator, and Review roles to investigate and remediate messages with policy matches. For communication compliance to be able to monitor user activity, you have to enable the Audit log in Office 365 . Helpful Resources \u2693\ufe0e For step-by-step instructions to begin setup of communication compliance, please follow guidance: Get started with communication compliance Stay up to date with the new announcements and features in communication compliance by following our latest blog posts: Foster a culture of inclusion and safety with Microsoft Teams and Communication Compliance Manage a broad range of communication risks efficiently Insider Risk Management \u2693\ufe0e Internal risks are often what keeps business leaders up at night \u2013 regardless of whether negligent or malicious, identifying and being able to take action on internal risks are critical. The ability to quickly identify and manage risks from insiders (employees or contractors with corporate access) and minimize the negative impact on corporate compliance, competitive business position and brand reputation is a priority for organizations worldwide. Insider risk management is a solution in Microsoft 365 that helps minimize internal risks by enabling you to detect, investigate, and take action on risky activities in your organization using signals from user activity, human resources (HR) systems and other sources that can provide rich context to enable accurate identification of potential threats. Custom policies allow you to detect and act on malicious and inadvertent risk activities in your organization, including escalating cases to Microsoft Advanced eDiscovery if needed. Risk analysts in your organization can quickly take appropriate actions to make sure users are compliant with your organization's compliance standards. Best Practices \u2693\ufe0e Let\u2019s establish some of the preparation that goes into start of execution of using insider risk to help plan your deployment. Prior to Deployment Plan \u2693\ufe0e Identify the appropriate stakeholders and personas in your organization to collaborate for remediation actions on insider risks. Some recommended personas to include in the end-to-end investigation workflow are compliance/privacy, security, HR, and legal. Insider risk management has role-based access control. You must be added or add users within your organization to the Insider Risk Management role group. Insider risk management uses audit logs for user insights and activities, it is a prerequisite to enable the Audit Log in Office 365. Deployment Test Plan \u2693\ufe0e Before enabling the solution broadly in your production environment, you may consider testing the policies with a small set of production users or in a test environment while waiting for the necessary privacy and legal reviews in your organization. Bear in mind that evaluating in a test environment will require that you generate simulated user actions and other signals in order to create alerts that can be triaged and processed, so testing with a small group of users in a production environment is usually preferred. When you set up a policy in insider risk management, the type of the policy defines the type of action that will act as a trigger to put a user under observation. For example, in the Departing Employee Data Theft policy, the trigger that causes the system to start analyzing the user\u2019s behavior is a record indicating the departure date of an employee coming into the system through the HR connector, while for a Data Leak policy the analysis is triggered by a data loss prevention (DLP) alert being raised for the high severity DLP policy you designated during configuration. While you are testing the solution, you can monitor its progress in the evaluation of user activity by looking at the Users tab. When a user performs an action that matches the trigger conditions for a policy (e.g., announces their departure which is informed to the system through the HR connector) you will see the name of the user and the policy being triggered in the Users list. When you click on the user, you will see on the User Activity tab the list of all detected actions for the user along with their risk score. This will give you a view on what activity was detected and how it was quantified. There are multiple insider risk management policy templates available. For the Departing Employee Data Theft policy, you must setup the HR connector to leverage HR notice and termination dates as a signal to alert you of any user activity related to data theft among departing employees. Step-by-step instructions to setup the HR connector can be found here. The Data Leak policy will leverage a DLP policy configured for High severity alerts to alert you of any user activity related to a data leak of sensitive information. Production Deployment \u2693\ufe0e Use the anonymization feature in settings to pseudonymize display names for risky users to maintain privacy and prevent bias when reviewing alerts and taking appropriate actions within the tool. Select dedicated Insider Risk analysts to monitor and review the alerts on a regular cadence in the Microsoft 365 compliance center. After creating a new policy, do not expect to see alerts coming up immediately. Insider risk is not a solution where you should see a lot of activity. In fact, most organizations see alerts being generated at a rate of a few per week or less, since the alerts should be highly relevant and represent in most cases actual instances of malicious behavior or an employee putting the organization at risk. Once the event that triggers analysis occurs, the user\u2019s activities are put under observation while the user\u2019s past and future activities are evaluated to determine if the user\u2019s behavior represents a risk, and if so, an alert is raised. Upon seeing an alert being raised, our recommendation is that there are dedicated analysts reviewing the alerts and can make decisions based on the information provided (e, g. if it needs to be turned into a case for investigation, escalated, or whether actions need to be taken.) While if you implement all the recommendations above you are set for a successful deployment of IRM, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Considerations \u2693\ufe0e Insider risk management focuses on the user instead of the individual actions and will raise alerts for users that its analysis indicates represent a risk to the organization. The risks are analyzed based on well-known patterns of behavior that are frequently observed in many organizations, such as employees taking sensitive data with them when they leave the company. This enables the solution to detect most instances of the risks being monitored while producing little or no noise. You may need to consider the regional privacy laws to monitor insider risk activities within your organization. We recommend privacy reviews with privacy and/or legal stakeholders to ensure you are complying with company policies and privacy standards. Helpful Resources \u2693\ufe0e To get started with insider risk management, please follow the step-by-step instructions here . You may find this Insider Risk Management evaluation guide useful for setting up and troubleshooting guidance. Stay up to date with the new announcements and features in Insider Risk Management by following our latest blog posts: Effectively managing insider risks with integrated collaboration solutions including Microsoft Teams Protecting against insider risks in an uncertain environment Appendix \u2693\ufe0e This section contains links to the information regarding license requirements and provides additional links to additional information related to Microsoft Information Protection & Compliance. License Requirements \u2693\ufe0e Below contains the necessary licenses for specific solutions outlined in the Deployment Acceleration Guide. While this information is current as of the writing of this document, refer to Microsoft 365 Licensing Guidance for Security & Compliance for the latest information as it may change. Communication Compliance (CC) \u2693\ufe0e Before you get started with communication compliance, you should confirm your Microsoft 365 subscription and any add-ons. To access and use communication compliance, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 Insider risk management add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Insider risk management add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Insider risk management add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions) Insider Risk Management (IRM) \u2693\ufe0e Before you get started with insider risk management policies, you should confirm your Microsoft 365 subscription and any add-ons. To access and use insider risk management policies, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 Insider risk management add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Insider risk management add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Insider risk management add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Insider Risk Management and Communication Compliance"},{"location":"dag/ir-cc/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: \u2022 Compliance Manager \u2022 Microsoft Compliance Configuration Analyzer (MCCA) \u2022 Communication Compliance \u2022 Insider Risk Management The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while protecting your intellectual property, stopping fraud or insider trading, plugging the sensitive data leaks, along with making the workplace safe.","title":"Your Deployment Plan"},{"location":"dag/ir-cc/#communication-compliance","text":"Communication compliance is part of the new insider risk solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and take remediation actions for inappropriate messages in your organization. Pre-defined and custom policies allow you to scan internal and external communications for policy matches so they can be examined by designated reviewers. Reviewers can investigate communications in your organization that do not meet your standards, as identified through configurable rules, and take appropriate remediation actions to make sure that they are compliant with your organization's message standards. Communication compliance supports several company communications channels including those part of the Microsoft 365 solution such as Exchange email, Microsoft Teams, Yammer or Skype for Business, as well as a large number of third-party communication platforms integrated through available connectors such as Twitter, Facebook, and Bloomberg instant messages. More details on third-party connectors can be found here . Communication compliance policies in Microsoft 365 help you overcome many modern challenges associated with compliance and internal and external communications, including: Scanning increasing numbers of communication channels The increasing communication volumes Regulatory enforcement & the risk of fines","title":"Communication Compliance"},{"location":"dag/ir-cc/#best-practices","text":"Let\u2019s establish some of the preparation that goes into start of execution of using communication compliance to help plan your deployment.","title":"Best Practices"},{"location":"dag/ir-cc/#policy-definition","text":"While the usage of communication compliance is distinct to each organization and their business and regulatory requirements and the policies you define will need to be designed accordingly, the following criteria can be used to guide the initial creation of policies at most organizations. Decide whether your organization\u2019s use cases for the solution revolve around regulatory compliance, enforcing a code of conduct, preventing self-harm or harm to others, or monitoring external communications by specific employees (or more than one of these or other scenarios), and define policies based on this decision according to the following rules. For code of conduct policies: It is generally advised that you create policies that cover all employees. While code of conduct violations by employees in some roles may be more problematic than in other roles, a minimum set of rules must be met by all employees, so start with a single policy that is scoped to all employees. Code of conduct policies typically utilize the built-in classifiers for offensive language. Create a policy utilizing the classifiers for profanity, harassment, targeted harassment, adult images, gory images, and racy images (it is alternatively possible to create separate policies for some of these if you think they should be monitored by different auditors or the response time needed for different types of offenses may vary significantly). While it is possible to create your own trainable classifiers for handling specific offensive or non-compliant terms, it is generally easier to start with the built-in classifiers and only train or retrain your own classifiers if needed. In some organizations, it may not be necessary to detect all offenses, and configuring the policy to only create alerts to a given percentage of offensive language use may be effective enough, since if employees know their communications are being regularly monitoring that may be enough incentive for them to follow the rules. In other organizations where no exceptions can be allowed a 100% review percentage may be needed. It is possible to create overlapping rules for specific roles such as executives, people working with customers or people in special, external-facing roles, or policies targeting specific communication channels that can have higher exposure such as social media. Such roles can be more aggressive in their rules and have higher review percentages than rules for the general population. In most cases, for code of conduct policies you will want to monitor both internal and outbound communications. Monitoring inbound communications can also be useful for detecting potential sources of stress to your employees. For policies related to monitoring self-harm or threats to others, similar practices to the ones for offensive language apply, but it is generally advised to create a policy that is separate from offensive language, since this type of policy usually requires a quicker reaction time in order to avoid actual harm and you may want to monitor such alerts more diligently. You will also likely want to configure a 100% review for such policies. For meeting regulatory compliance requirements, you will typically create a custom policy with rules that are dictated by your regulatory requirements. Typically, you will create a policy starting with the regulatory compliance policy template and configure it with rules that utilize \u201cmessage (or attachment) contains any of these words\u201d and provide words or phrases frequently used in language that represents the type of risks you want to identify. For example, for detecting situations such as improper gifts you can define phrases like \u201ccomplimentary\u201d, \u201cgift\u201d, \u201cat no cost to you\u201d and \u201cour treat\u201d. For more complex requirements, you can create custom Sensitive Information Types (SIT) and use them in your policies. A custom SIT can use large dictionaries that are easier to maintain, combinations of different lists of words, complex conditions including operators (and/or/not) and near relationships between terms and more. Go to Data Classification page in M365 SCC, navigate to Sensitive Info Types tab. Click Create Info Type and use your dictionary to create a custom SIT. For more details, check this How to setup a keyword dictionary Go to Policies tab in Communication Compliance admin portal and click Create Policy. Choose Custom Policy from the drop-down menu and use custom create SIT in the Conditions And Percentages page of the New Policy Wizard along with other details as required. This method can require more effort to implement than a simple keyword list or a trainable classifier, so it is recommended that you start with the simpler option and assess your accuracy before committing to more complex policies based on sensitive info types. In most cases, regulatory compliance policies can be scoped to specific communications, in particular including only external communications or communications to/from specific organizations can significantly reduce the volume of alerts to review while keeping the relevant messages in scope. Communication compliance can also be used for monitoring communications through official channels (such as official communications by executives and PR people such as on Twitter feeds). While it is rare that an employee would intentionally commit policy violations in such channels, it is not as rare that an employee mixes up their personal account with the official one and send improper messages that way. Using Communication compliance to monitor such media can help rapidly detect potential offenses and delete the offending messages. In most cases you may want to utilize the built-in classifiers for offensive language, harassment, and the classifiers for gory, racy and adult images for these policies. If your organization is multi-national or have employees that communicate in multiple languages, contact Microsoft for access to the Offensive Language classifiers in different languages, currently in preview. If you do so, unless you know that all your auditors are fluent in all the languages in question, it is often recommended that you create separate policies for each of these languages, so you can assign in each policy reviewers that can read the language in question and properly assess the offenses. Since Communication compliance will attempt to detect the language in which a message is written and will use the right classifiers accordingly, it is generally not required to assign policies in specific languages to known speakers of those languages. Still, doing so can reduce false positives due to the fact that certain non-offensive words in some languages can be identical to offensive words in other languages, so if you have large known populations that communicate in specific languages (such as to people in specific countries where that language is the primary language in use) you can target such language-specific policies to those populations to make the solution more accurate. At this moment, Communication compliance gathers and analyzes messages on a 24-hour cycle, which starts at the moment a policy is enabled for the first time. You may want to plan the creation of policies that relate to time-sensitive matters (such as threats) so it completes at the same time when you expect your analysts to check daily for alerts, in order to minimize the delay in reviewing messages. For other types of policies some organizations prefer to align their creation with the end of the productive day for most employees so policies can be reviewed before the next day. While compliance alerts are often monitored by individuals specifically assigned to the role, assessment of noncompliance often requires escalation to other roles in the organization. It is recommended that before putting your policies in production you identify the appropriate stakeholders and personas in your organization to collaborate for remediation actions and alerts triaging in communication compliance. Some recommended personas to include in the end-to-end investigation workflow are human resources, compliance/privacy and legal. You may also want to involve people that are fluent in specific languages or that are familiar with the culture of specific regions since there may be local nuances that change the meaning of some phrases. It is often useful to create groups in Office 365 or channels in Teams including these persons to make obtaining feedback about these types of situations more efficient (though for obvious reasons assessment of offensive language or images is typically better handled 1:1). Also, in order to allow these persons to have direct access to the Communication compliance console, assign the required role groups to these groups or individuals. Before enabling the solution broadly in your production environment, you may consider testing the policies with a small set of production users or in a test environment while waiting for the necessary privacy and legal reviews in your organization. Bear in mind that evaluating it in a test environment will require that you generate simulated user content to create alerts that can be triaged and processed, so testing with a small group of users in a production environment is usually preferred. Use the anonymization feature in settings to pseudonymize display names for risky users to maintain privacy and prevent bias when reviewing alerts and taking appropriate actions within the tool. After creating a new policy, expect alerts to start arriving in 24 hours, though there may be additional delay in some cases.","title":"Policy Definition"},{"location":"dag/ir-cc/#investigating-alerts","text":"The first step to investigate issues detected by your policies is to review generated alerts in the Microsoft 365 compliance center. There are several areas in the compliance center to help you to quickly investigate alerts, depending on how you prefer to view alert grouping: Communication compliance home page : Here you will see: Alerts needing review listed from high to low severity. Select an alert to launch the alert details page and to start remediation actions. Recent policy matches listed by policy name. Resolved items listed by policy name. Escalations listed by policy name. Users with the most policy matches, listed from the most to the least number of matches. Alerts tab: Display alerts grouped by matched communication compliance policy. This view allows you to quickly see which communication compliance policies are generating the most alerts ordered by severity. Policies tab: Each policy listed includes the count of alerts that need review. Selecting a policy displays all the pending alerts for matches to the policy, select a specific alert to launch the policy details page and to start remediation actions.","title":"Investigating Alerts"},{"location":"dag/ir-cc/#considerations","text":"To make communication compliance available as a menu option in Microsoft 365 compliance center, you must be assigned the Supervisory Review Administrator role. You must create a new role group for reviewers with the Supervisory Review Administrator, Case Management, Compliance Administrator, and Review roles to investigate and remediate messages with policy matches. For communication compliance to be able to monitor user activity, you have to enable the Audit log in Office 365 .","title":"Considerations"},{"location":"dag/ir-cc/#helpful-resources","text":"For step-by-step instructions to begin setup of communication compliance, please follow guidance: Get started with communication compliance Stay up to date with the new announcements and features in communication compliance by following our latest blog posts: Foster a culture of inclusion and safety with Microsoft Teams and Communication Compliance Manage a broad range of communication risks efficiently","title":"Helpful Resources"},{"location":"dag/ir-cc/#insider-risk-management","text":"Internal risks are often what keeps business leaders up at night \u2013 regardless of whether negligent or malicious, identifying and being able to take action on internal risks are critical. The ability to quickly identify and manage risks from insiders (employees or contractors with corporate access) and minimize the negative impact on corporate compliance, competitive business position and brand reputation is a priority for organizations worldwide. Insider risk management is a solution in Microsoft 365 that helps minimize internal risks by enabling you to detect, investigate, and take action on risky activities in your organization using signals from user activity, human resources (HR) systems and other sources that can provide rich context to enable accurate identification of potential threats. Custom policies allow you to detect and act on malicious and inadvertent risk activities in your organization, including escalating cases to Microsoft Advanced eDiscovery if needed. Risk analysts in your organization can quickly take appropriate actions to make sure users are compliant with your organization's compliance standards.","title":"Insider Risk Management"},{"location":"dag/ir-cc/#best-practices_1","text":"Let\u2019s establish some of the preparation that goes into start of execution of using insider risk to help plan your deployment.","title":"Best Practices"},{"location":"dag/ir-cc/#prior-to-deployment-plan","text":"Identify the appropriate stakeholders and personas in your organization to collaborate for remediation actions on insider risks. Some recommended personas to include in the end-to-end investigation workflow are compliance/privacy, security, HR, and legal. Insider risk management has role-based access control. You must be added or add users within your organization to the Insider Risk Management role group. Insider risk management uses audit logs for user insights and activities, it is a prerequisite to enable the Audit Log in Office 365.","title":"Prior to Deployment Plan"},{"location":"dag/ir-cc/#deployment-test-plan","text":"Before enabling the solution broadly in your production environment, you may consider testing the policies with a small set of production users or in a test environment while waiting for the necessary privacy and legal reviews in your organization. Bear in mind that evaluating in a test environment will require that you generate simulated user actions and other signals in order to create alerts that can be triaged and processed, so testing with a small group of users in a production environment is usually preferred. When you set up a policy in insider risk management, the type of the policy defines the type of action that will act as a trigger to put a user under observation. For example, in the Departing Employee Data Theft policy, the trigger that causes the system to start analyzing the user\u2019s behavior is a record indicating the departure date of an employee coming into the system through the HR connector, while for a Data Leak policy the analysis is triggered by a data loss prevention (DLP) alert being raised for the high severity DLP policy you designated during configuration. While you are testing the solution, you can monitor its progress in the evaluation of user activity by looking at the Users tab. When a user performs an action that matches the trigger conditions for a policy (e.g., announces their departure which is informed to the system through the HR connector) you will see the name of the user and the policy being triggered in the Users list. When you click on the user, you will see on the User Activity tab the list of all detected actions for the user along with their risk score. This will give you a view on what activity was detected and how it was quantified. There are multiple insider risk management policy templates available. For the Departing Employee Data Theft policy, you must setup the HR connector to leverage HR notice and termination dates as a signal to alert you of any user activity related to data theft among departing employees. Step-by-step instructions to setup the HR connector can be found here. The Data Leak policy will leverage a DLP policy configured for High severity alerts to alert you of any user activity related to a data leak of sensitive information.","title":"Deployment Test Plan"},{"location":"dag/ir-cc/#production-deployment","text":"Use the anonymization feature in settings to pseudonymize display names for risky users to maintain privacy and prevent bias when reviewing alerts and taking appropriate actions within the tool. Select dedicated Insider Risk analysts to monitor and review the alerts on a regular cadence in the Microsoft 365 compliance center. After creating a new policy, do not expect to see alerts coming up immediately. Insider risk is not a solution where you should see a lot of activity. In fact, most organizations see alerts being generated at a rate of a few per week or less, since the alerts should be highly relevant and represent in most cases actual instances of malicious behavior or an employee putting the organization at risk. Once the event that triggers analysis occurs, the user\u2019s activities are put under observation while the user\u2019s past and future activities are evaluated to determine if the user\u2019s behavior represents a risk, and if so, an alert is raised. Upon seeing an alert being raised, our recommendation is that there are dedicated analysts reviewing the alerts and can make decisions based on the information provided (e, g. if it needs to be turned into a case for investigation, escalated, or whether actions need to be taken.) While if you implement all the recommendations above you are set for a successful deployment of IRM, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact.","title":"Production Deployment"},{"location":"dag/ir-cc/#considerations_1","text":"Insider risk management focuses on the user instead of the individual actions and will raise alerts for users that its analysis indicates represent a risk to the organization. The risks are analyzed based on well-known patterns of behavior that are frequently observed in many organizations, such as employees taking sensitive data with them when they leave the company. This enables the solution to detect most instances of the risks being monitored while producing little or no noise. You may need to consider the regional privacy laws to monitor insider risk activities within your organization. We recommend privacy reviews with privacy and/or legal stakeholders to ensure you are complying with company policies and privacy standards.","title":"Considerations"},{"location":"dag/ir-cc/#helpful-resources_1","text":"To get started with insider risk management, please follow the step-by-step instructions here . You may find this Insider Risk Management evaluation guide useful for setting up and troubleshooting guidance. Stay up to date with the new announcements and features in Insider Risk Management by following our latest blog posts: Effectively managing insider risks with integrated collaboration solutions including Microsoft Teams Protecting against insider risks in an uncertain environment","title":"Helpful Resources"},{"location":"dag/ir-cc/#appendix","text":"This section contains links to the information regarding license requirements and provides additional links to additional information related to Microsoft Information Protection & Compliance.","title":"Appendix"},{"location":"dag/ir-cc/#license-requirements","text":"Below contains the necessary licenses for specific solutions outlined in the Deployment Acceleration Guide. While this information is current as of the writing of this document, refer to Microsoft 365 Licensing Guidance for Security & Compliance for the latest information as it may change.","title":"License Requirements"},{"location":"dag/ir-cc/#communication-compliance-cc","text":"Before you get started with communication compliance, you should confirm your Microsoft 365 subscription and any add-ons. To access and use communication compliance, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 Insider risk management add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Insider risk management add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Insider risk management add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Communication Compliance (CC)"},{"location":"dag/ir-cc/#insider-risk-management-irm","text":"Before you get started with insider risk management policies, you should confirm your Microsoft 365 subscription and any add-ons. To access and use insider risk management policies, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 Insider risk management add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Insider risk management add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Insider risk management add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Insider Risk Management (IRM)"},{"location":"dag/mcca/","text":"Last updated: 05/07/2021 Where does one start today with regards to being compliant with various standards and assessments? There are often multiple steps you need to take to safeguard your compliance posture. Often, you want to know if there is a starting point or recommended best practices as you get started on your journey of managing compliance requirements. Questions you may ask yourself are: \u2018How do I diagnose my compliance posture or ensure that I have the right configurations in place to protect my environment completely. These are largely manual processes which tend to be time consuming & allow for human error. Furthermore, with the evolving compliance landscape the risk of blind spots also increases along with compliance requirements needing to be changed or updated; the latest information will be included with MCCA tool without the need to update manually. Microsoft Compliance Configuration Analyzer (MCCA) is a diagnostic tool (seen in Figure 1 above) which generates a report to help M365 customers understand their current consumption of E5 compliance offerings. It surfaces improvement areas in a tenant\u2019s compliance configurations in achieving data protection guidelines and recommends best practices to follow. This tool can help you quickly see which improvement actions in Compliance Manger apply to your current Microsoft 365 environment. It is a PowerShell-based utility that will fetch your tenant\u2019s current configurations & validate these configurations against Microsoft 365 recommended best practices. These best practices are based on a set of controls that include key regulations and standards for data protection and general data governance. MCCA was built with the goals of helping you extract maximum value out of compliance offerings part of your M365 E5 licenses by creating awareness to your consumption of M365 compliance offerings. Today, MCCA will provide you recommendations for 8 Compliance solutions. We will keep adding more solutions & richer recommendations in future versions of this tool. Microsoft Information Protection Data Loss Prevention Microsoft Information Governance Records Management Insider Risk Management Communication Compliance Advanced Audit Advanced eDiscovery Use the GitHub link to download the tool and follow instructions for how to install, run and configure the tool for the about eight solutions. Also, you can download and install the PowerShell module for MCCA from the PowerShell Gallery . With MCCA you can: Quickly and automatically fetch your tenant\u2019s current configurations & validate these configurations against Microsoft 365 recommended best practices. Quickly diagnose your compliance posture & ensure that they have the right configurations in place to protect their environment completely. Reports allow you to focus efforts more on making the right configurations. Best Practices \u2693\ufe0e The reporting is based on the geolocations in your tenant as it accesses the SITs for each location to generate a report. We suggest running it for all geolocations and then using the correct input parameter to change location if need be. Our recommendation is to download via PowerShell Gallery because it has less steps and is hassle-free. Using the GitHub repo will need to be cloned & the module needs to load into PowerShell. We suggest this method for more advanced users and/or contributors who know have deeper experience with PowerShell. Considerations \u2693\ufe0e The MCCA report can be generated in its entirety by users with Global Admin or Global Reader privileges. Other roles within the organisation may not be able to run the tool or they may be able to run the tool with limited information in the final report. Helpful Resources \u2693\ufe0e Review the FAQ section for MCCA tool to answer a question you might have about making changes, reviewing reports, or what status indicates for each solution.","title":"Microsoft Compliance Configuration Analyzer (MCCA)"},{"location":"dag/mcca/#best-practices","text":"The reporting is based on the geolocations in your tenant as it accesses the SITs for each location to generate a report. We suggest running it for all geolocations and then using the correct input parameter to change location if need be. Our recommendation is to download via PowerShell Gallery because it has less steps and is hassle-free. Using the GitHub repo will need to be cloned & the module needs to load into PowerShell. We suggest this method for more advanced users and/or contributors who know have deeper experience with PowerShell.","title":"Best Practices"},{"location":"dag/mcca/#considerations","text":"The MCCA report can be generated in its entirety by users with Global Admin or Global Reader privileges. Other roles within the organisation may not be able to run the tool or they may be able to run the tool with limited information in the final report.","title":"Considerations"},{"location":"dag/mcca/#helpful-resources","text":"Review the FAQ section for MCCA tool to answer a question you might have about making changes, reviewing reports, or what status indicates for each solution.","title":"Helpful Resources"},{"location":"dag/mig-rm/","text":"Last updated: 05/10/2021 What is information governance and why should you worry about governing your data? The technical definition that you can find on the web is usually one that a records manager or compliance risk officer may read and say sure, but for some of us we still leave wanting a level 100 explanation. At a basic level, the goal is to balance the risk holding onto information presents with the value the information provides to the organization. You also need to consider which decisions are within your control as a company and which are driven by regulatory or industry requirements. It is important to remember that this is a strategy across all your information. That strategy should define who has the authority to make information related decisions. These individuals will be heavily involved in your retention policy, label taxonomy and file plan discussions. It also needs to account for how you will handle change management for your policies governing information as well as communication of your plan and training your users. Your information governance strategy should also establish the \u201cwhat\u201d, the requirements or how long, before actions need to be taken to retain or delete information, the \u201chow\u201d, by the technologies that will be used. In our case, the retention polices, and labels deployed through Microsoft Information Governance and Records Management . Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Data Loss Prevention (DLP) Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Azure Information Protection (AIP) Scanner Microsoft Cloud App Security (MCAS) Microsoft Information Protection (MIP) Microsoft Information Governance (MIG) and Records Management (RM) Communication Compliance Insider Risk Management Advanced eDiscovery Advanced Audit The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while governing your data by deciding what to keep, what to delete, what is a regulatory requirement, and using a workflow to manage the lifecycle. Microsoft Information Governance and Records Management \u2693\ufe0e Microsoft Information Governance (MIG) provides capabilities to manage the lifecycle of your content and govern your data for compliance or regulatory requirements. Records management (RM) manages high-value content for legal, business, or regulatory obligations, and adds advanced capabilities such as disposition review and file plans. Some organizations may have simple retention and deletion requirements were applying broad policies using the MIG features will meet your needs. Other organizations may have strict recordkeeping requirements including a formal file plan, disposition, or retention trigged by events which can be accomplished using the RM features. Best Practices \u2693\ufe0e The information governance needs from one organization to the next can differ greatly. While one organization has one simple retention policy that emails must be kept for 3 years, another can exist in a highly regulated industry and therefore have multiple requirements they need to meet based on different types of data. The approach below aims to provide guidance on how to approach deployment of the features available through information governance and records management, whether you have those basic needs or the more complex capabilities we offer. Let\u2019s establish some of the preparation that goes into being ready to start the execution of deploying retention policies, labels, and using your file plan to manage your records. Make sure that you understand the functions available in MIG and RM and what your requirements are so they may be aligned to drive the configuration during deployment. That should drive the plan whether it is a formal File Plan to be used in RM or simply a retention schedule that will categorize your information into retention and deletion periods. That plan will drive the number of labels you may need and their settings as well as the retention and publishing policies. Below are some questions to drive the conversation during this planning period. Will the built-in role groups covered in the considerations section align to your access governance or will you need to create custom role groups? If granular control is needed you can use the Security and Compliance center to create your custom role groups. Do you need to apply retention and deletion to broad buckets, such as all Teams chats and conversations or all Exchange email mailboxes? This is a good use case for retention policies. Do you store documents that may have different retention requirements in the same location such as a document library in SharePoint? This is a good use case for retention labels because they can be applied at the item level. Do you require a disposition review process at the end of the retention period? There is an option to require disposition of content when creating a label from the File Plan in RM. Do you need to trigger retention or deletion based on an event, such as the end of a fiscal year or employment end date or the end of a contract? When creating a label from the File Plan in RM you can choose one of the built-in event types or choose to create your own. If you need to manage content as formal records or have even stricter requirements for immutability, look at the information about declaring records with retention labels . Develop a solid test plan that defines what your scenarios and successful test outcomes will be. We recommend testing in a lower environment first to validate outcomes with shorter time periods for both the basic and more advanced configurations. Determine how long it will take to test all your scenarios and what approvals are needed and the timing of those to work backwards to set a deployment timeline and what your milestones will be. Such as deploying a simple retention policy to all of Exchange or having your file plan ready for import into Records Management. Now that we have touched on the preparation for deployment, below we outline the deployment and configurations when creating retention policies, creating and publishing retention labels, as well as creating labels through the file plan in records management to require stricter controls and reviews. Retention Policies \u2693\ufe0e Retention policies are best suited when targeting a location or container of information. Those locations can be one of the following in the list below, however Teams and Yammer locations need their own policies and cannot be combined with the other locations. Exchange email SharePoint site OneDrive accounts Microsoft 365 groups Skype for Business Exchange public folders Teams channel messages Teams chats Yammer community messages Yammer private messages Creation and management of policies will require that you log into the compliance center with an account that has the necessary Retention Management permissions which we discussed in the considerations section earlier. It is a good idea to start with the basic scenarios before moving on to the more advanced ones to gain a comfort level with the process and ensure you get the desired outcomes. In each example there are 3 consistent steps of the policy creation outlined below. With the common steps established we will focus how each example differs during the creation of the policy. You will need to give your policy a name and description that is meaningful for your organization. Note this name cannot be changed. You will need to choose if you want to retain content, delete it, or both and whether that should be based on created or modified date. The last step is to review your settings and create the policy. Once your policy is created after service completes the mechanisms policy engine in the various environments (Exchange Online, SharePoint Online, OneDrive, Yammer, Teams, etc..) it will take affect without any additional steps. Our experience is this completes in 7 days or sooner. Start Simple \u2693\ufe0e Deployment of a basic policy that sets the same retention settings to apply to the entire location(s). This approach is very straightforward. After the steps to name your policy and set retention settings above, you will choose the locations you want this policy to apply to. A basic policy will usually target an entire location and does not have inclusions or exclusions set. You will ensure that the location is toggle On and set to All. Remember that Teams and Yammer cannot be combined with the other locations. Next Steps \u2693\ufe0e Next, we cover deploying a policy that has inclusions or exclusions based on a need to apply different retention periods to content in the same location types such as different mailbox users, or SharePoint sites as an example. Choose the locations you want this policy to apply to. In this scenario you will ensure the status of the location is toggled On and then use the links to select specific recipients, sites, etc. to include or exclude in this policy. You will be required to know and enter the full path for SharePoint or OneDrive locations. Refer to the considerations section for policy limitations in this scenario. Advanced \u2693\ufe0e An advanced retention policy configuration is more suited for those that have a need to apply it based on what is in the content to target specific documents, such as sensitive information. Choose to Use Advanced Retention Settings. You can now either apply to content based on sensitive information present in the item using one of the built-in or custom sensitive information types (SITs), or you can apply to content that contains specific words or phrases. The choice to use the advanced settings above is going to limit the locations that you have as options to Exchange, SharePoint, and OneDrive. It will also default the Exchange location to include All. This cannot be changed. Retention, Record, and Regulatory labels and policies \u2693\ufe0e When you have a need to retain and delete content at the item level, use a retention label. Retention labels also provide some other capabilities that retention policies do not. Retention labels travel with the content as it moves within your tenant. They allow you to start the retention based on when the item is labeled. You can start the retention based on when an event occurs. An item can be automatically labeled based on a trainable classifier. An item can be labeled automatically if it matches a keyword query you create. You can set a default label on SharePoint lists and libraries. A disposition review can be required before something is permanently deleted. Labels allow you to mark content as a record or regulatory record. As you can see retention labels provide greater flexibility for when the retention period starts, what happens when the retention period ends, how that label is applied, and what can be done with the content once it has been labeled. These options allow for both a basic deployment strategy and a more advanced one. Many of the more advanced options also require the use of the File Plan feature in RM to create the labels. We will start with the label and policy creation from within the MIG solution, and then move to those that require using RM and the File Plan feature to create the more advanced labels and policies. Information Governance \u2693\ufe0e Creating labels and policies in Information Governance will require that you log into the compliance center with an account that has the necessary Retention Management permissions which we discussed in the considerations section earlier. In each example below we will be referring to the same steps to create a label that applies the retention period based on when an item is labeled. Label creation steps: * You will give your label a name based on your taxonomy and enter descriptions for both admins and your users that is meaningful for your organization. Remember this name cannot be changed. Toggle the Retention on and then choose whether you want to retain content, delete it, or both. In this example unique to labels, we will choose to take those actions based on When The Content Is Labeled. You are free to choose when created or modified as well. Review your settings and create the label. The label will now need a policy to publish the label to be manually applied by users, or to automatically apply it to content. When creating a policy to publish or apply the label, you should start with a simple approach and then add complexity. All policy creation has common steps to name the policy and review your settings. Each example will differ based on the locations we publish the label to or how that label is applied to content. Policy name and review steps: Give the policy a name and description that is meaningful. Remember, this name cannot be changed. Review your settings and either click publish labels or auto-apply to save your settings depending on the scenario. It can take up to 1 day for labels to appear and only for those mailboxes that have 10MB of data or more as noted above in the considerations. Start Simple \u2693\ufe0e In the basic example we will be publishing our label to all users and locations for them to apply manually. This publishing policy is very straightforward. Simply choose the default to publish this policy to all locations in the Choose Locations page within the Publish to users and groups step. Next Steps \u2693\ufe0e You may also have a need to create a label that needs to be published to a specific set of users or locations due to a department\u2019s unique requirements. When we create the policy to publish the label, we will be specifying inclusions or exclusions. In this scenario instead of all in the Choose Locations page, you will choose specific locations by ensuring the Status of the location is toggled On and then use the links to select specific recipients, sites, etc. to include or exclude in the policy. Refer to the considerations section for policy limitations in this scenario. During preparation you identify that you have a need to proactively address content that may have sensitive information in it. To avoid relying on your users to consistently label this content with a publish policy, you can choose to Auto-apply A Label instead based on SITs which are contained in the same list of templates as when you create a data loss prevention (DLP) policy. Make sure Apply Label To Content That Contains Sensitive Info is selected and pick one of the built-in templates or choose custom to either specify individual (SITs) or your own custom SIT. The SITs will have default instance count and match accuracy settings. If you would like to view them to confirm or modify, you will need to use the Edit button. You can also choose whether you want this policy to apply to All locations or specific locations. Using specific inclusions or exclusions here will also have the same policy limitation considerations mentioned above. Advanced \u2693\ufe0e If your organization has a mature information architecture in SharePoint online, you may want to leverage that data to use the condition Apply Label To Content That Contains Specific Words Or Phrases, Or Properties. The query-based auto-apply policies use the same search index as eDiscovery content search which means you can use any of the pre-defined SharePoint online managed properties as your criteria which are documented in the helpful resources section. You may want to start with out of the box properties first such as filetype or modifiedby before targeting your custom properties that have been mapped to a managed property. Once you have your criteria take care to enter it into the Keyword Query Editor correctly as it will not tell you if your query has bad syntax or is invalid. We also recommend always including the (AND, OR) operators to ensure that your query is interpreted correctly if you are combing more than one condition. During your planning for deployment of not only the MIG or RM solutions, but also Microsoft Information Protection (MIP) and Communications Compliance (CC), you may have decided that our trainable classifiers capability adds a lot of value based on your data estate. If that is the case, then you can create a policy with the condition Apply Label To Content That Matches A Trainable Classifier. You can find more information on trainable classifiers in the creating one compliance story section. Even if you have not built your own custom trainable classifier you can choose a built-in one from the list such as Source Code or Resumes. Trainable classifiers can label new and modified items and existing items from the last six months. Records Management \u2693\ufe0e Some may consider the concept of records management intimidating. The thought of having to categorize all your data and get agreement from the business on how long each category of information needs to be retained or how soon it needs to go can be daunting. We believe that both those already well down the path of the records management journey and those just getting started can take advantage of the features we offer in our solution. Unlike the information governance examples above where the progression of basic to advanced configurations usually involve how the label is applied, in records management the real power is in the information the label can have and what happens when the label is applied. This next section will touch on those configuration examples by starting with using File plan tool and the options we have when creating a label. When following the guidance below make sure that you log into the compliance center with an account that has the necessary Records Management permissions which we discussed in the considerations section earlier. Start Simple (File Plan) \u2693\ufe0e During planning you should determine if you have an existing retention schedule. Even if you do not have an existing retention schedule or a file plan, you can start to build one by creating your labels from within File Plan. The creation of the label using File Plan is similar to the steps from Information Governance. However, using File Plan provides the ability to add descriptors to your label. Start by adding your descriptors to provide additional information about each label, such as the business department the label is for, or the provision or citation that drives the configuration settings of the label. As you build your labels out you will be able to export this list to a .csv file which will contain the settings as well as those descriptors. You can pick from a list of values or create your own. If you create your own make sure the spelling and format is correct as you will not be able to modify or remove it once you save your changes. Next Steps (File Plan) \u2693\ufe0e You can also use the File Plan import option or the Export mentioned above to create your labels from the .csv file. This could be an empty template before any labels are created, or after some initial labels have been created to provide examples. This file can be used for planning and execution. We find this is extremely helpful for customers who prefer to fill the template out and then create their labels in bulk to save time. This method can also be used to bulk-modify existing labels. Advanced (File Plan) \u2693\ufe0e Your organization may already have retention schedule in place which includes a formal file plan. If so, the File Plan import can be used to download a blank template to import that plan and create your labels. You will need to map your current file plan to the fields available in the template. Each field can only have 64 characters. There is a validation during the import and if there are errors it will provide the line and row numbers that are causing issues. Keep in mind this import will create the labels only and those labels will have no impact until you create a policy to publish or automatically apply those labels. When creating your labels from File Plan you will notice there are some differences in the experiences as you step through each of the screens. While the retention settings are the same as in Information governance, the way they are presented may differ. All the examples below drive what settings are chosen from the Define Retention Settings screen. For label creation instructions please follow the steps here . Start Simple (Label Deployment) \u2693\ufe0e We mentioned above with records management, the power is in the label, one example of that is the option to require disposition when creating your label. You may identify certain information that may have a similar duration of retention as other material, but you need someone to formally review those items before they are removed. This is where disposition comes into play. We are covering this under records management because that solution contains the Disposition tab where the reviewers will go to evaluate the content that has reached its retention end date. Disposition can be required by selecting Trigger A Disposition Review under the At The End Of The Retention Period section. When choosing this option, you will need to select the users that you want to perform the review of the content. We recommend selecting more than one user. Mail-enabled security groups are supported. Microsoft 365 groups are not. Specifying a user here will not add them to the Disposition Management role, which is the minimum permissions needed. Content in Exchange, SharePoint, OneDrive, and Microsoft 365 groups is only deleted after a reviewer chooses to permanently delete the content. There is no undo button in the disposition workflow once that selection is made. Disposition for Exchange content requires that the target mailbox has at least 10MB of data. A reviewer can only use the link in the location column to view the content if they have permissions to that location and the content. If you have a need for the owners of the content to participate in the disposition process you can export the list of items needing review to a .csv file. Next Steps (Label Deployment) \u2693\ufe0e Disposition of content is a common requirement when declaring an item as a record. If your organization has identified certain types of information that are considered a record, you can apply the additional protections by choosing Mark Items As A Record during label creation. When this option is selected and the label is applied to emails, users will not be able to edit or delete those emails. Versioning is still possible by unlocking a record. The previous version is still considered a record and cannot be modified or deleted. When content labeled as a record in a SharePoint site or OneDrive is unlocked, a special Records folder is created in the Preservation Hold Library (PHL). Site Collection Administrators can still remove a record label from an item. Take that into consideration when evaluating who has those rights on your SharePoint site collections. The removal of a label as well as the lock and unlocking of a record are all activities that you can search for and view in the Audit solution. If an item was marked as a record and required disposition you will be able to provide a proof of records deletion. Advanced (Label Deployment) \u2693\ufe0e A common scenario we see is that organizations have a need to consider certain artifacts a record, but only after a certain event occurs such as the end of a customer engagement. Other organizations do not necessarily have the record requirement but have a need to keep certain information for a specific amount of time only after an event, like when an employee leaves the company. This can be accomplished by selecting one of the built-in event types or creating your own under the Start The Retention Period Based On option. Using this approach does take some planning. It requires that the items that have this label applied have the AssetID (SharePoint and OneDrive) populated by the user when they apply the label, or in the case of Exchange, have a consistent set of Keywords present in the email. Your organization may have other unique properties that you already apply to the documents related to your event type. For example, you may have an engagement number or contract number required for these documents. This can be used in place of the ComplianceAssetID property as long as it is entered in property:value pair format in the AssetID area when you create an event. Content search can be used to find the content that meets these criteria to validate which items will have their retention triggered. Because the labels are associated with event types, and the events you create are what trigger the retention, it is important to understand that the keywords and Asset ID values specified are what uniquely identify which set of labeled items the system should trigger the retention period on. It is important to understand that if you do not specify an asset ID or keywords for an event, all content with a retention label of that event type will have its retention period triggered by the event. If you plan to use labels that will trigger based on events, we highly recommend you consider automating this process. For more information on event types and how to automate this process please read Start retention when an event occurs . There are certain regulations that require strict immutability when it come to the content. While our existing Record capabilities satisfy most of our customer\u2019s needs, we did heard feedback from our highly regulated customers that we need to provide even stricter controls. In response, we have recently introduced a new option under Define Retention Settings when creating a label in Records Management to Mark Items As A Regulatory Record. The restrictions put in place once applied block any modification to the content. Careful thought and consideration need to go into determining if this is truly needed. Once applied the only actions that are allowed are read, copy, and move within container. Reference this table for a full breakdown. Once a regulatory record is applied to content, not even a global administrator, can remove the label. Because of these restrictions and irreversible actions, the option to Mark Items as a regulatory record is not available by default. You will first have to run the commands outline in Declare records by using retention labels . Once available you will also receive a warning when selecting this option. A label that marks content as a regulatory record cannot be applied automatically to content. We also recommend a strong education campaign for those users you publish these labels to. While if you implement all the recommendations above you are set for a successful deployment of MIG and RM, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption initially. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Now that we have covered the different basic to advanced deployment scenarios and best practices, take a minute to make sure you read the rest of this guide to understand how retention and records management integrate with the other compliance solutions and how they complement each other. We also provide you with some important considerations to keep in mind when it comes to your environment and how they may affect your deployment. There are some helpful resources as well thatwill point you to other articles, blog posts, or videos that provide important context or supplement the documentation for MIG and RM. Considerations \u2693\ufe0e To manage retention policies and labels, you will need to be added to the Compliance Administrator role group or for more targeted permissions, a new or existing role group can be assigned the Retention Management role. You can also grant read-only rights through the View-Only Retention Management role which can be added to a new or existing role group. Those responsible for records management in the organization should be added to the Records Management role group or for a read-only role, add the View-Only Record Management role to a new or existing role group. Important, when creating retention policies and labels, ensure that you are confident in your naming taxonomy. Once you create a policy or label it cannot be renamed. Only one retention label can be applied to content at any given time. If an item already has a label applied, automated labeling policies will not replace the existing label on the item. When creating a retention label or policy, be aware there is not a test mode or simulation mode as there is when creating a new MIP sensitivity label. Retention labels will only be available for users in Outlook client and Outlook web if their mailboxes have at least 10MB of data in them. Retention policies do not support list items, if you have a need to apply retention to items within lists you must use retention labels. Retention policies with specific inclusions or exclusions are subject to limits which you should be aware of. If you configure a retention policy with specific includes and then remove the last one, the configuration reverts to All for the location. Make sure this is the configuration that you intend before you save the policy. When considering applying retention or deletion policies to Teams channel messages, it is important to remember that private channel conversations are not included. Reactions to Teams messages are also not included. To retain content associated with a Team created from a Microsoft 365 group that is stored in the respective SharePoint site, a separate policy must also be applied to the related Microsoft 365 Group location. To retain email messages for Yammer you will also need a retention policy that applies to the Microsoft 365 groups location. You will also need a policy that targets the related SharePoint site or users OneDrive locations to retain the files shared in Yammer messages. When using retention policies for SharePoint sites, the settings do not apply to organization structures, system lists, or other items used to manage the system. Yammer items are retained and deleted for community messages and private messages but not reaction emoticons. Data Connectors can allow for the archival of third-party data which is stored in a users\u2019 Exchange Online mailbox and can have retention and records management applied to that data. (more here) Helpful Resources \u2693\ufe0e This list of retention policy and retention label capabilities can help you determine whether to use a retention policy or retention label to meet your requirements. It is important to understand the content that can be stored in an Exchange Online mailbox and the impact a retention policy applied to a mailbox may have on that data. It is also important to note that not all data will be preserved when a policy is applied at the mailbox level, such as Teams or Skype data. Those require their own policy specific to that workload. When content in an Exchange Online (EXO) mailbox is modified in some way and there is a retention policy targeting that mailbox or a label applied to the email, the original item is stored in a special location called the Recoverable Items folder for the mailbox. Where it is goes depends on the action taken and that is why we encourage you to have a good understanding of how the Recoverable items folder in Exchange Online works. This list of Third-party data connectors provides a table which indicates which third-party data can have retention and records management applied to it. SharePoint Online also has a special location to store items subject to retention called the Preservation Hold Library. There are also a 1st stage and 2nd stage recycle bin that come into play. To learn more about what happens to an item that someone deletes or reaches the end of its retention or deletion period, read Lifecycle of an item in SharePoint: Where does it go ? In the scenario where more than one retention policy and label may be applied to content, it is important to understand the principles of retention to gain insight into the outcome. Read U se retention labels to manage document lifecycles to understand how to leverage SharePoint information architecture to automatically apply retention labels to content. When targeting SharePoint locations for auto-apply labels, only the pre-defined managed properties are supported in the KQL query. See the list of crawled and managed properties in SharePoint server . Now that you can Use OneDrive for Business and SharePoint for Teams meeting recordings we have added support for you to use our automatic labeling capabilities to apply retention periods or immutability to those files. Read our online documentation for instructions regarding those recordings. You can use the steps for import retention labels into your file plan to guide you on how to map your existing retention schedule to the template to import into our Records Management solution. For a deeper understanding of the new Regulatory Record label for records management you can check out this video . While this guide focuses on the administrator activities for deployment, it is important to also train your end users to drive adoption. Use End User Training for Retention Labels in M365 as a good starting point.","title":"Microsoft Information Governance and Records Management"},{"location":"dag/mig-rm/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Data Loss Prevention (DLP) Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Azure Information Protection (AIP) Scanner Microsoft Cloud App Security (MCAS) Microsoft Information Protection (MIP) Microsoft Information Governance (MIG) and Records Management (RM) Communication Compliance Insider Risk Management Advanced eDiscovery Advanced Audit The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while governing your data by deciding what to keep, what to delete, what is a regulatory requirement, and using a workflow to manage the lifecycle.","title":"Your Deployment Plan"},{"location":"dag/mig-rm/#microsoft-information-governance-and-records-management","text":"Microsoft Information Governance (MIG) provides capabilities to manage the lifecycle of your content and govern your data for compliance or regulatory requirements. Records management (RM) manages high-value content for legal, business, or regulatory obligations, and adds advanced capabilities such as disposition review and file plans. Some organizations may have simple retention and deletion requirements were applying broad policies using the MIG features will meet your needs. Other organizations may have strict recordkeeping requirements including a formal file plan, disposition, or retention trigged by events which can be accomplished using the RM features.","title":"Microsoft Information Governance and Records Management"},{"location":"dag/mig-rm/#best-practices","text":"The information governance needs from one organization to the next can differ greatly. While one organization has one simple retention policy that emails must be kept for 3 years, another can exist in a highly regulated industry and therefore have multiple requirements they need to meet based on different types of data. The approach below aims to provide guidance on how to approach deployment of the features available through information governance and records management, whether you have those basic needs or the more complex capabilities we offer. Let\u2019s establish some of the preparation that goes into being ready to start the execution of deploying retention policies, labels, and using your file plan to manage your records. Make sure that you understand the functions available in MIG and RM and what your requirements are so they may be aligned to drive the configuration during deployment. That should drive the plan whether it is a formal File Plan to be used in RM or simply a retention schedule that will categorize your information into retention and deletion periods. That plan will drive the number of labels you may need and their settings as well as the retention and publishing policies. Below are some questions to drive the conversation during this planning period. Will the built-in role groups covered in the considerations section align to your access governance or will you need to create custom role groups? If granular control is needed you can use the Security and Compliance center to create your custom role groups. Do you need to apply retention and deletion to broad buckets, such as all Teams chats and conversations or all Exchange email mailboxes? This is a good use case for retention policies. Do you store documents that may have different retention requirements in the same location such as a document library in SharePoint? This is a good use case for retention labels because they can be applied at the item level. Do you require a disposition review process at the end of the retention period? There is an option to require disposition of content when creating a label from the File Plan in RM. Do you need to trigger retention or deletion based on an event, such as the end of a fiscal year or employment end date or the end of a contract? When creating a label from the File Plan in RM you can choose one of the built-in event types or choose to create your own. If you need to manage content as formal records or have even stricter requirements for immutability, look at the information about declaring records with retention labels . Develop a solid test plan that defines what your scenarios and successful test outcomes will be. We recommend testing in a lower environment first to validate outcomes with shorter time periods for both the basic and more advanced configurations. Determine how long it will take to test all your scenarios and what approvals are needed and the timing of those to work backwards to set a deployment timeline and what your milestones will be. Such as deploying a simple retention policy to all of Exchange or having your file plan ready for import into Records Management. Now that we have touched on the preparation for deployment, below we outline the deployment and configurations when creating retention policies, creating and publishing retention labels, as well as creating labels through the file plan in records management to require stricter controls and reviews.","title":"Best Practices"},{"location":"dag/mig-rm/#retention-policies","text":"Retention policies are best suited when targeting a location or container of information. Those locations can be one of the following in the list below, however Teams and Yammer locations need their own policies and cannot be combined with the other locations. Exchange email SharePoint site OneDrive accounts Microsoft 365 groups Skype for Business Exchange public folders Teams channel messages Teams chats Yammer community messages Yammer private messages Creation and management of policies will require that you log into the compliance center with an account that has the necessary Retention Management permissions which we discussed in the considerations section earlier. It is a good idea to start with the basic scenarios before moving on to the more advanced ones to gain a comfort level with the process and ensure you get the desired outcomes. In each example there are 3 consistent steps of the policy creation outlined below. With the common steps established we will focus how each example differs during the creation of the policy. You will need to give your policy a name and description that is meaningful for your organization. Note this name cannot be changed. You will need to choose if you want to retain content, delete it, or both and whether that should be based on created or modified date. The last step is to review your settings and create the policy. Once your policy is created after service completes the mechanisms policy engine in the various environments (Exchange Online, SharePoint Online, OneDrive, Yammer, Teams, etc..) it will take affect without any additional steps. Our experience is this completes in 7 days or sooner.","title":"Retention Policies"},{"location":"dag/mig-rm/#start-simple","text":"Deployment of a basic policy that sets the same retention settings to apply to the entire location(s). This approach is very straightforward. After the steps to name your policy and set retention settings above, you will choose the locations you want this policy to apply to. A basic policy will usually target an entire location and does not have inclusions or exclusions set. You will ensure that the location is toggle On and set to All. Remember that Teams and Yammer cannot be combined with the other locations.","title":"Start Simple"},{"location":"dag/mig-rm/#next-steps","text":"Next, we cover deploying a policy that has inclusions or exclusions based on a need to apply different retention periods to content in the same location types such as different mailbox users, or SharePoint sites as an example. Choose the locations you want this policy to apply to. In this scenario you will ensure the status of the location is toggled On and then use the links to select specific recipients, sites, etc. to include or exclude in this policy. You will be required to know and enter the full path for SharePoint or OneDrive locations. Refer to the considerations section for policy limitations in this scenario.","title":"Next Steps"},{"location":"dag/mig-rm/#advanced","text":"An advanced retention policy configuration is more suited for those that have a need to apply it based on what is in the content to target specific documents, such as sensitive information. Choose to Use Advanced Retention Settings. You can now either apply to content based on sensitive information present in the item using one of the built-in or custom sensitive information types (SITs), or you can apply to content that contains specific words or phrases. The choice to use the advanced settings above is going to limit the locations that you have as options to Exchange, SharePoint, and OneDrive. It will also default the Exchange location to include All. This cannot be changed.","title":"Advanced"},{"location":"dag/mig-rm/#retention-record-and-regulatory-labels-and-policies","text":"When you have a need to retain and delete content at the item level, use a retention label. Retention labels also provide some other capabilities that retention policies do not. Retention labels travel with the content as it moves within your tenant. They allow you to start the retention based on when the item is labeled. You can start the retention based on when an event occurs. An item can be automatically labeled based on a trainable classifier. An item can be labeled automatically if it matches a keyword query you create. You can set a default label on SharePoint lists and libraries. A disposition review can be required before something is permanently deleted. Labels allow you to mark content as a record or regulatory record. As you can see retention labels provide greater flexibility for when the retention period starts, what happens when the retention period ends, how that label is applied, and what can be done with the content once it has been labeled. These options allow for both a basic deployment strategy and a more advanced one. Many of the more advanced options also require the use of the File Plan feature in RM to create the labels. We will start with the label and policy creation from within the MIG solution, and then move to those that require using RM and the File Plan feature to create the more advanced labels and policies.","title":"Retention, Record, and Regulatory labels and policies"},{"location":"dag/mig-rm/#information-governance","text":"Creating labels and policies in Information Governance will require that you log into the compliance center with an account that has the necessary Retention Management permissions which we discussed in the considerations section earlier. In each example below we will be referring to the same steps to create a label that applies the retention period based on when an item is labeled. Label creation steps: * You will give your label a name based on your taxonomy and enter descriptions for both admins and your users that is meaningful for your organization. Remember this name cannot be changed. Toggle the Retention on and then choose whether you want to retain content, delete it, or both. In this example unique to labels, we will choose to take those actions based on When The Content Is Labeled. You are free to choose when created or modified as well. Review your settings and create the label. The label will now need a policy to publish the label to be manually applied by users, or to automatically apply it to content. When creating a policy to publish or apply the label, you should start with a simple approach and then add complexity. All policy creation has common steps to name the policy and review your settings. Each example will differ based on the locations we publish the label to or how that label is applied to content. Policy name and review steps: Give the policy a name and description that is meaningful. Remember, this name cannot be changed. Review your settings and either click publish labels or auto-apply to save your settings depending on the scenario. It can take up to 1 day for labels to appear and only for those mailboxes that have 10MB of data or more as noted above in the considerations.","title":"Information Governance"},{"location":"dag/mig-rm/#start-simple_1","text":"In the basic example we will be publishing our label to all users and locations for them to apply manually. This publishing policy is very straightforward. Simply choose the default to publish this policy to all locations in the Choose Locations page within the Publish to users and groups step.","title":"Start Simple"},{"location":"dag/mig-rm/#next-steps_1","text":"You may also have a need to create a label that needs to be published to a specific set of users or locations due to a department\u2019s unique requirements. When we create the policy to publish the label, we will be specifying inclusions or exclusions. In this scenario instead of all in the Choose Locations page, you will choose specific locations by ensuring the Status of the location is toggled On and then use the links to select specific recipients, sites, etc. to include or exclude in the policy. Refer to the considerations section for policy limitations in this scenario. During preparation you identify that you have a need to proactively address content that may have sensitive information in it. To avoid relying on your users to consistently label this content with a publish policy, you can choose to Auto-apply A Label instead based on SITs which are contained in the same list of templates as when you create a data loss prevention (DLP) policy. Make sure Apply Label To Content That Contains Sensitive Info is selected and pick one of the built-in templates or choose custom to either specify individual (SITs) or your own custom SIT. The SITs will have default instance count and match accuracy settings. If you would like to view them to confirm or modify, you will need to use the Edit button. You can also choose whether you want this policy to apply to All locations or specific locations. Using specific inclusions or exclusions here will also have the same policy limitation considerations mentioned above.","title":"Next Steps"},{"location":"dag/mig-rm/#advanced_1","text":"If your organization has a mature information architecture in SharePoint online, you may want to leverage that data to use the condition Apply Label To Content That Contains Specific Words Or Phrases, Or Properties. The query-based auto-apply policies use the same search index as eDiscovery content search which means you can use any of the pre-defined SharePoint online managed properties as your criteria which are documented in the helpful resources section. You may want to start with out of the box properties first such as filetype or modifiedby before targeting your custom properties that have been mapped to a managed property. Once you have your criteria take care to enter it into the Keyword Query Editor correctly as it will not tell you if your query has bad syntax or is invalid. We also recommend always including the (AND, OR) operators to ensure that your query is interpreted correctly if you are combing more than one condition. During your planning for deployment of not only the MIG or RM solutions, but also Microsoft Information Protection (MIP) and Communications Compliance (CC), you may have decided that our trainable classifiers capability adds a lot of value based on your data estate. If that is the case, then you can create a policy with the condition Apply Label To Content That Matches A Trainable Classifier. You can find more information on trainable classifiers in the creating one compliance story section. Even if you have not built your own custom trainable classifier you can choose a built-in one from the list such as Source Code or Resumes. Trainable classifiers can label new and modified items and existing items from the last six months.","title":"Advanced"},{"location":"dag/mig-rm/#records-management","text":"Some may consider the concept of records management intimidating. The thought of having to categorize all your data and get agreement from the business on how long each category of information needs to be retained or how soon it needs to go can be daunting. We believe that both those already well down the path of the records management journey and those just getting started can take advantage of the features we offer in our solution. Unlike the information governance examples above where the progression of basic to advanced configurations usually involve how the label is applied, in records management the real power is in the information the label can have and what happens when the label is applied. This next section will touch on those configuration examples by starting with using File plan tool and the options we have when creating a label. When following the guidance below make sure that you log into the compliance center with an account that has the necessary Records Management permissions which we discussed in the considerations section earlier.","title":"Records Management"},{"location":"dag/mig-rm/#start-simple-file-plan","text":"During planning you should determine if you have an existing retention schedule. Even if you do not have an existing retention schedule or a file plan, you can start to build one by creating your labels from within File Plan. The creation of the label using File Plan is similar to the steps from Information Governance. However, using File Plan provides the ability to add descriptors to your label. Start by adding your descriptors to provide additional information about each label, such as the business department the label is for, or the provision or citation that drives the configuration settings of the label. As you build your labels out you will be able to export this list to a .csv file which will contain the settings as well as those descriptors. You can pick from a list of values or create your own. If you create your own make sure the spelling and format is correct as you will not be able to modify or remove it once you save your changes.","title":"Start Simple (File Plan)"},{"location":"dag/mig-rm/#next-steps-file-plan","text":"You can also use the File Plan import option or the Export mentioned above to create your labels from the .csv file. This could be an empty template before any labels are created, or after some initial labels have been created to provide examples. This file can be used for planning and execution. We find this is extremely helpful for customers who prefer to fill the template out and then create their labels in bulk to save time. This method can also be used to bulk-modify existing labels.","title":"Next Steps (File Plan)"},{"location":"dag/mig-rm/#advanced-file-plan","text":"Your organization may already have retention schedule in place which includes a formal file plan. If so, the File Plan import can be used to download a blank template to import that plan and create your labels. You will need to map your current file plan to the fields available in the template. Each field can only have 64 characters. There is a validation during the import and if there are errors it will provide the line and row numbers that are causing issues. Keep in mind this import will create the labels only and those labels will have no impact until you create a policy to publish or automatically apply those labels. When creating your labels from File Plan you will notice there are some differences in the experiences as you step through each of the screens. While the retention settings are the same as in Information governance, the way they are presented may differ. All the examples below drive what settings are chosen from the Define Retention Settings screen. For label creation instructions please follow the steps here .","title":"Advanced (File Plan)"},{"location":"dag/mig-rm/#start-simple-label-deployment","text":"We mentioned above with records management, the power is in the label, one example of that is the option to require disposition when creating your label. You may identify certain information that may have a similar duration of retention as other material, but you need someone to formally review those items before they are removed. This is where disposition comes into play. We are covering this under records management because that solution contains the Disposition tab where the reviewers will go to evaluate the content that has reached its retention end date. Disposition can be required by selecting Trigger A Disposition Review under the At The End Of The Retention Period section. When choosing this option, you will need to select the users that you want to perform the review of the content. We recommend selecting more than one user. Mail-enabled security groups are supported. Microsoft 365 groups are not. Specifying a user here will not add them to the Disposition Management role, which is the minimum permissions needed. Content in Exchange, SharePoint, OneDrive, and Microsoft 365 groups is only deleted after a reviewer chooses to permanently delete the content. There is no undo button in the disposition workflow once that selection is made. Disposition for Exchange content requires that the target mailbox has at least 10MB of data. A reviewer can only use the link in the location column to view the content if they have permissions to that location and the content. If you have a need for the owners of the content to participate in the disposition process you can export the list of items needing review to a .csv file.","title":"Start Simple (Label Deployment)"},{"location":"dag/mig-rm/#next-steps-label-deployment","text":"Disposition of content is a common requirement when declaring an item as a record. If your organization has identified certain types of information that are considered a record, you can apply the additional protections by choosing Mark Items As A Record during label creation. When this option is selected and the label is applied to emails, users will not be able to edit or delete those emails. Versioning is still possible by unlocking a record. The previous version is still considered a record and cannot be modified or deleted. When content labeled as a record in a SharePoint site or OneDrive is unlocked, a special Records folder is created in the Preservation Hold Library (PHL). Site Collection Administrators can still remove a record label from an item. Take that into consideration when evaluating who has those rights on your SharePoint site collections. The removal of a label as well as the lock and unlocking of a record are all activities that you can search for and view in the Audit solution. If an item was marked as a record and required disposition you will be able to provide a proof of records deletion.","title":"Next Steps (Label Deployment)"},{"location":"dag/mig-rm/#advanced-label-deployment","text":"A common scenario we see is that organizations have a need to consider certain artifacts a record, but only after a certain event occurs such as the end of a customer engagement. Other organizations do not necessarily have the record requirement but have a need to keep certain information for a specific amount of time only after an event, like when an employee leaves the company. This can be accomplished by selecting one of the built-in event types or creating your own under the Start The Retention Period Based On option. Using this approach does take some planning. It requires that the items that have this label applied have the AssetID (SharePoint and OneDrive) populated by the user when they apply the label, or in the case of Exchange, have a consistent set of Keywords present in the email. Your organization may have other unique properties that you already apply to the documents related to your event type. For example, you may have an engagement number or contract number required for these documents. This can be used in place of the ComplianceAssetID property as long as it is entered in property:value pair format in the AssetID area when you create an event. Content search can be used to find the content that meets these criteria to validate which items will have their retention triggered. Because the labels are associated with event types, and the events you create are what trigger the retention, it is important to understand that the keywords and Asset ID values specified are what uniquely identify which set of labeled items the system should trigger the retention period on. It is important to understand that if you do not specify an asset ID or keywords for an event, all content with a retention label of that event type will have its retention period triggered by the event. If you plan to use labels that will trigger based on events, we highly recommend you consider automating this process. For more information on event types and how to automate this process please read Start retention when an event occurs . There are certain regulations that require strict immutability when it come to the content. While our existing Record capabilities satisfy most of our customer\u2019s needs, we did heard feedback from our highly regulated customers that we need to provide even stricter controls. In response, we have recently introduced a new option under Define Retention Settings when creating a label in Records Management to Mark Items As A Regulatory Record. The restrictions put in place once applied block any modification to the content. Careful thought and consideration need to go into determining if this is truly needed. Once applied the only actions that are allowed are read, copy, and move within container. Reference this table for a full breakdown. Once a regulatory record is applied to content, not even a global administrator, can remove the label. Because of these restrictions and irreversible actions, the option to Mark Items as a regulatory record is not available by default. You will first have to run the commands outline in Declare records by using retention labels . Once available you will also receive a warning when selecting this option. A label that marks content as a regulatory record cannot be applied automatically to content. We also recommend a strong education campaign for those users you publish these labels to. While if you implement all the recommendations above you are set for a successful deployment of MIG and RM, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption initially. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Now that we have covered the different basic to advanced deployment scenarios and best practices, take a minute to make sure you read the rest of this guide to understand how retention and records management integrate with the other compliance solutions and how they complement each other. We also provide you with some important considerations to keep in mind when it comes to your environment and how they may affect your deployment. There are some helpful resources as well thatwill point you to other articles, blog posts, or videos that provide important context or supplement the documentation for MIG and RM.","title":"Advanced (Label Deployment)"},{"location":"dag/mig-rm/#considerations","text":"To manage retention policies and labels, you will need to be added to the Compliance Administrator role group or for more targeted permissions, a new or existing role group can be assigned the Retention Management role. You can also grant read-only rights through the View-Only Retention Management role which can be added to a new or existing role group. Those responsible for records management in the organization should be added to the Records Management role group or for a read-only role, add the View-Only Record Management role to a new or existing role group. Important, when creating retention policies and labels, ensure that you are confident in your naming taxonomy. Once you create a policy or label it cannot be renamed. Only one retention label can be applied to content at any given time. If an item already has a label applied, automated labeling policies will not replace the existing label on the item. When creating a retention label or policy, be aware there is not a test mode or simulation mode as there is when creating a new MIP sensitivity label. Retention labels will only be available for users in Outlook client and Outlook web if their mailboxes have at least 10MB of data in them. Retention policies do not support list items, if you have a need to apply retention to items within lists you must use retention labels. Retention policies with specific inclusions or exclusions are subject to limits which you should be aware of. If you configure a retention policy with specific includes and then remove the last one, the configuration reverts to All for the location. Make sure this is the configuration that you intend before you save the policy. When considering applying retention or deletion policies to Teams channel messages, it is important to remember that private channel conversations are not included. Reactions to Teams messages are also not included. To retain content associated with a Team created from a Microsoft 365 group that is stored in the respective SharePoint site, a separate policy must also be applied to the related Microsoft 365 Group location. To retain email messages for Yammer you will also need a retention policy that applies to the Microsoft 365 groups location. You will also need a policy that targets the related SharePoint site or users OneDrive locations to retain the files shared in Yammer messages. When using retention policies for SharePoint sites, the settings do not apply to organization structures, system lists, or other items used to manage the system. Yammer items are retained and deleted for community messages and private messages but not reaction emoticons. Data Connectors can allow for the archival of third-party data which is stored in a users\u2019 Exchange Online mailbox and can have retention and records management applied to that data. (more here)","title":"Considerations"},{"location":"dag/mig-rm/#helpful-resources","text":"This list of retention policy and retention label capabilities can help you determine whether to use a retention policy or retention label to meet your requirements. It is important to understand the content that can be stored in an Exchange Online mailbox and the impact a retention policy applied to a mailbox may have on that data. It is also important to note that not all data will be preserved when a policy is applied at the mailbox level, such as Teams or Skype data. Those require their own policy specific to that workload. When content in an Exchange Online (EXO) mailbox is modified in some way and there is a retention policy targeting that mailbox or a label applied to the email, the original item is stored in a special location called the Recoverable Items folder for the mailbox. Where it is goes depends on the action taken and that is why we encourage you to have a good understanding of how the Recoverable items folder in Exchange Online works. This list of Third-party data connectors provides a table which indicates which third-party data can have retention and records management applied to it. SharePoint Online also has a special location to store items subject to retention called the Preservation Hold Library. There are also a 1st stage and 2nd stage recycle bin that come into play. To learn more about what happens to an item that someone deletes or reaches the end of its retention or deletion period, read Lifecycle of an item in SharePoint: Where does it go ? In the scenario where more than one retention policy and label may be applied to content, it is important to understand the principles of retention to gain insight into the outcome. Read U se retention labels to manage document lifecycles to understand how to leverage SharePoint information architecture to automatically apply retention labels to content. When targeting SharePoint locations for auto-apply labels, only the pre-defined managed properties are supported in the KQL query. See the list of crawled and managed properties in SharePoint server . Now that you can Use OneDrive for Business and SharePoint for Teams meeting recordings we have added support for you to use our automatic labeling capabilities to apply retention periods or immutability to those files. Read our online documentation for instructions regarding those recordings. You can use the steps for import retention labels into your file plan to guide you on how to map your existing retention schedule to the template to import into our Records Management solution. For a deeper understanding of the new Regulatory Record label for records management you can check out this video . While this guide focuses on the administrator activities for deployment, it is important to also train your end users to drive adoption. Use End User Training for Retention Labels in M365 as a good starting point.","title":"Helpful Resources"},{"location":"dag/mip-dlp/","text":"Last updated: 05/10/2021 With information protection and sensitivity labels, you can intelligently classify and help protect your sensitive content, while making sure that your organization's productivity and ability to collaborate is not hindered. Combined with data loss prevention you can help prevent the accidental oversharing of the sensitive information in your organization. With this in mind, let\u2019s get started with understanding the capabilities which are available as part of Microsoft Information Protection (MIP) , how you discover sensitive information and protect it using the various provided tools provided by MIP and Data Loss Prevention (DLP) Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Microsoft Information Protection (MIP) Data Loss Prevention (DLP) Microsoft Cloud App Security (MCAS) Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while protecting your intellectual property, stopping fraud or insider trading, plugging the sensitive data leaks, along with making the workplace safe. Microsoft Information Protection \u2693\ufe0e Implement Microsoft Information Protection (MIP) to help you discover, classify, and protect sensitive information wherever it lives or travels. Contrary to popular opinion, MIP is not a single product but rather a suite of technologies supported by many aspects of the Microsoft 365 ecosystem. MIP capabilities are included with Microsoft 365 Compliance and give you the tools to know your data, protect your data, and prevent data loss. The main capabilities associated with MIP are as follows: Sensitive information types (SITs) Trainable Classifiers Data Classification Sensitivity Labels Azure Information Protection (AIP) unified labeling client Azure Information Protection (AIP) unified labeling Scanner Azure Purview Double Key Encryption (DKE) Office 365 Message Encryption (OME) Service encryption with Customer Key SharePoint Information Rights Management (IRM) Rights Management connector Microsoft Cloud App Security (MCAS) Microsoft Information Protection (MIP) SDK Data Loss Prevention (DLP) Learn more about MIP basics here . With MIP and a Sensitivity labels policy you can: Deploy your classification taxonomy to the company end user employees and give them the ability to apply these labels to documents and emails. Labels can also be applied automatically or in a recommended way based on sensitive information stored in the document or email. Leverage the applied sensitivity labels as a condition for data loss prevention use cases. Mark the document or email sensitivity with a header, footer and/or watermark. This will make the data sensitivity visible to anyone who consumes the document, within an app, via the web or as a hard copy. Apply sensitivity labels for SharePoint online, Teams sites and groups, providing another layer of control on the container level access within managed or un-managed devices, if it should be set for Public or Private access and/or external access. With encryption you can control who can consume content (for example: only company employees + approved partners) and what permissions he or she has (for example: Read but Do Not Print or Edit). Best Practices \u2693\ufe0e Defining the right label taxonomy and protection policies is the most critical step in a Microsoft Information Protection deployment. Labels will be the interface for users to understand content sensitivity, how it matches company policies, and will be the primary input for users to flag content that needs to be protected. A good label taxonomy needs to meet business and/or regulatory needs, be intuitively understandable by users, provide good policy tips and be easy to use. It should not prevent users from doing their jobs, while at the same time help prevent instances of data leakage or misuse and address compliance requirements. With these requirements in mind, the following best practices have proven to make deployment of information protection policies in many organizations easier, faster, and more successful. Prior to Deployment Plan \u2693\ufe0e Discover your sensitive information in your existing repositories. This is the first step we recommend as part of our best practice approach to detect the data you own and be ready to configure it as part of your sensitivity label configurations as well as data loss prevention policies later in this guide. Microsoft 365 cloud: Use Content Explorer in Microsoft 365 compliance center to discover data stored in Microsoft 365 (SharePoint, OneDrive), read more about it here . Non-Microsoft cloud repositories: Use Microsoft Cloud App Security to connect non-Microsoft applications and discover sensitive information beyond the Microsoft 365 services. Read more about it here . On-premises repositories: Use Azure Information Protection Scanner to discover data stored in your on-premises file shares, read more about it here . Azure resources: Use Azure Purview to identify sensitive information stored in Azure Repositories, read more about it here . Consider the methods in which users will interact with MIP labels and how you intend to implement this: Interactively within Microsoft 365 Apps via the Sensitivity Button. Read more about it in the \u201cMIP Client Consideration\u201d section. Natively for macOS, iOS and Android Native labeling vs AIP Client Container labeling for SharePoint Sites, Teams and Office 365 Groups Public vs Private access Unmanaged device access Sharing levels PowerBI Dashboards and PBIX assets Use label names for your labels that intuitively resonate with your users. Using company jargon that is well ingrained in the employee\u2019s culture is a valid approach, though care must be taken to ensure the labels are also meaningful to new employees. For example, using acronyms in label names is not ideal due to the opacity to new employees and the difficulty of visually recognizing them. Using short, meaningful words such as \u201cConfidential\u201d or \u201cSecret\u201d generally works best. Consider label order. Labels are sorted from lowest sensitivity to highest sensitivity, which means higher sensitivity labels represent an \u201cupgrade\u201d in the confidentiality of the information and usually have stronger protection measures. This order can be enforced by preventing users from downgrading sensitivity of a document unless they have the right privileges, and there are multiple scenarios in which it is important that the order of the labels is clear. It is important that the names you use reflect this order, ad you should avoid using terms that have no clear hierarchy. For example, not all users might agree on whether \u201cConfidential\u201d or \u201cSecret\u201d is the most sensitive label, so using something like \u201cConfidential\u201d vs. \u201cHighly confidential\u201d may be preferable. Use sublabels with intent. Labels are generally used to represent the actual sensitivity of the content that is labeled, while sublabels are typically used to represent variations in the protection or the scope of the content. For example, you might have a label taxonomy that includes \u201cGeneral Business\u201d, \u201cConfidential\u201d and \u201cHighly Confidential\u201d as top-level labels. Sublabels such as \u201cInternal\u201d or \u201cExternal\u201d designate specific types of data in some of those top-level categories that need to be controlled in specific ways. You might also have project/team specific sublabels or sublabels to address special requirements such as excluding the application of content markings for content that should not be modified. Keep it simple with no more than five top level labels and five sublabels. User experience research shows that with five or fewer labels, users can target the desired label directly in a single movement, whereas if there are more elements in the list the user will typically have to read through them each time, making mistakes more likely. The 5x5 approach is proven to keep things simple and help users choose the right labels, but if you can keep labels below those numbers, even better. Define labels that will last a long time. Since labels often become part of a company\u2019s culture and language, it is critical that they are not frequently altered, especially when it comes to the names and meanings of the top-level labels. The approach mentioned in the previous point makes this easy: using top-level labels to represent the sensitivity of the document means they will not change often. Sublabels, on the other hand, can be more dynamic, and while it is preferable to frame them in a way that follows a clear pattern that rarely changes, adding or changing sublabels as additional requirements such as new projects or divisions come up is usually not a problem if you follow a consistent pattern. Do not put sensitive information in a label\u2019s name or description. This might sound obvious, but it is common that IT departments are asked to create a label to protect information for a merger or acquisition or a label for a secret project that is not known to the general population in the company. Putting the name of the company or a word that reveals more about the project than what is public in the name of the label can reveal such data to all users, even if the label is scoped to a small team. While scoped labels are not made available to all users, metadata about the existence of such labels is carried within the policies all users get, so it is important that codenames or other non-disclosing keywords are used in such labels instead. Plan your auto-labeling strategy, MIP provide both Service and Client based auto-labeling for different use cases: Service-side auto labeling policies should be used for data at rest in SharePoint Online and OneDrive for Business and data in transit for Exchange Online when specific SITs need to be detected and labels applied automatically. This can be especially helpful when the data source is not controlled and might be that data is stored or sent without being labeled by the client solution. Also, it\u2019s a great option to label data that is already stored in SharePoint Online and OneDrive for Business. Client-side labeling when users edit documents or compose (also reply or forward) emails: Use a label that is configured for auto-labeling for files and emails (includes Word, Excel, PowerPoint, and Outlook). This method supports recommending a label to a user, as well as automatically applying a label. But in both cases, the user decides whether to accept or reject the label, to help ensure the correct labeling of content. This client-side labeling has minimal delay for documents because the label can be applied even before the document is saved. However, not all client apps support auto-labeling. This capability is supported by the Azure Information Protection unified labeling client, and some versions of Office. If your organization operates in multiple languages, work with your localization teams to ensure the names chosen for the labels can be easily localized and are meaningful in all the required languages. Consider words that have a clear meaning in one language might be harder to localize or be ambiguous when translated. Examples of such words are \u201cPublic\u201d which can have nuanced meanings in some languages, and \u201cPersonal\u201d which can be easily confused in meaning to refer to private information. Consider the impact on usability. Forcing users to select labels too frequently can lead to users doing it reflexively without thinking about the label they should apply. Using a predefined default label is good practice in scenarios where manually labeling everything could be a burden - and where there is some \u201csafe\u201d sensitivity level that applies to most content. One such case is email, where for most users in most organizations labeling emails as \u201cInternal\u201d by default should be a safe option and reduce user effort considerably. Users can label emails as \u201cexternal\u201d, \u201cpublic\u201d or \u201cconfidential\u201d as needed. At the same time, most users do not create dozens of new documents per day, so asking them to individually label each document without providing a default is an acceptable requirement in most cases. MIP allows you to do this by using a different default label for emails and documents using the advanced option named \u201cOutlookDefaultLabel\u201d that specifies a default label for Outlook independently from what is set for documents. Compartmentalize data sparingly. Compartmentalization of data is essential in many businesses and using scoped sublabels that are shown and give rights to people in specific departments is a good practice, but you should use this capability in moderation. If you have a dozen critical projects that need to contain their data from being accessed by the general population of employees, creating sublabels specifically for them is beneficial. But if you have a thousand projects that demand the same treatment, the administrative burden imposed by such label taxonomy would be large and you will likely end up hitting a practical limit. The best practice is to define a clear rule for which kinds of teams, projects, divisions, or groups get their own sublabels which ensures only a small number of sublabels need to be created (a few dozen) - and stick with it. Consider what threats you are trying to prevent \u2013 not what users will be doing with the content. When defining protection policies some organizations start by thinking about what users need to do with their content, and define rights based on that. That often leads to frustration, since IT will rarely know everything every employee needs to do with the content. It can also lead to more protection than is necessary, and since there is a small overhead (for the computers and the humans) involved whenever accessing something is protected via encryption and rights enforcement, that is undesirable. Start instead with what threats you are trying to prevent: you might want to prevent your competitors from accessing your confidential plans, or from users accidentally putting sensitive data where unauthorized people can view it. Based on those requirements, define the minimal controls that must be there to ensure those scenarios do not happen and implement them. With time, as you gain more confidence on understanding what users need to do, you can adjust settings to implement tighter restrictions as needed. Involve different teams in the review of your proposed label taxonomy, including compliance, legal, public relations, end user education, etc. Defining labels is not an IT security task alone, and their early feedback will help you define a label taxonomy that will work for a long time and not need to be revised after deployment when those teams observe the labels you defined do not meet their needs or address their scenarios. Deployment Test Plan \u2693\ufe0e For the labeling client experience, consider your deployment methodology for Windows: Native labeling use Monthly Enterprise Channel or Monthly Channel for updates to Office 365 ProPlus. This will ensure you gain access to all MIP features immediately upon release. Semi-Annual Channel is strongly discouraged. AIP client should not be the default consideration and should only be used when needing specific functionality not yet available in the native client, or when you are using Office perpetual installation. For MAC we support the Native labeling in the office client. More details can be found here . For a comparison of update channels for M365, use this link . In some instances, a hybrid deployment of Native Labeling and AIP client may be appropriate. A good example is when File Explorer extension functionality is needed whilst wanting to keep the native experience as pristine as possible. In this case, the AIP client can be deployed along with an ADMX template to disable the Office Add-In components. Validate labels before deploying to users. Conduct a practical validation to see how accurate your users are at using these labels. One option is to create an email with fake sensitive information in the form of documents attached and send it to a subset of users asking them to open each document in turn and label it. They do not even need to report the results, since you will be able to see how they labeled each document in the Activity Explorer in the compliance center. You can alternatively do an offline activity, by setting baskets in the office\u2019s entrance, printing copies of a mix of pretend sensitive documents, and putting them in a pile at the entrance with a sign that says, \u201ctake one and put it in the corresponding basket\u201d. Users usually do this exercise consciously and it allows you to get a very representative idea of how well your users understand policies and labeling taxonomy. After you have done an exercise, you can validate the accuracy of user\u2019s actions and tune your labels and training materials accordingly. Socialize labels so they become part of the organization\u2019s natural language. While experience indicates the sensitivity label UI is simple enough that users do not need to be trained in its use, it is important to perform an awareness campaign in which the meaning of the different labels and the important of their use is highlighted (i.e., awareness emails, physical posters, etc.). The objective of such a campaign is that users incorporate the organization\u2019s labels as part of their natural language and that can intuitively assign documents to their corresponding label. The MIP CxE team has published several sample documents that can be used in this regard, referenced in the helpful links section above. Schedule multiple workshops with stakeholders during the testing phase to validate the label taxonomy is working effectively and catch any changes needed before wholesale deployment to production has occurred avoiding the need to reclassify large amounts of data in the future. Although we mention above that this validation should be done before deployment to users, it is inevitable that some changes will likely occur, and this should be expected by the project team. Ensure you have a well-documented test plan with clear tasks, testing scenarios and clear outcomes. Establish end user training and education. Measure their understanding of the organization information protection policies. Use \u201cknowledge measure questions\u201d if you can. Production Deployment \u2693\ufe0e Leverage the existing formal feedback mechanism from your end user-base to ensure that your label taxonomy remains effective and relevant to the organization. Making sure that established clear timelines for formal review and revision if necessary are followed. Monitor the classification activities. Using the \u201cActivity Explorer\u201d capability in the compliance center allows you to gain insights on how your users utilizing sensitivity labels (among other things). This will enable you to monitor how actively your users are following the organization policies and doing their due diligence when it comes to information labelling. Update the configuration, as necessary. Ensure all business units\u2019 requirements have been clearly addressed and document acceptance before rolling out to a wider end user base. While if you implement all the recommendations above you are set for a successful deployment of MIP, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption initially such as manual labels without protection, adding basic protection elements in a later stage (e.g. DLP controls to prevent highly confidential items from being accidentally sent outside, or encryption with very broad rights applied), and finally adding more restrictive permissions and tighter controls once you are confident in the use of the technology. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Considerations \u2693\ufe0e Let us start with classifying and protecting our unstructured data assets in documents and emails. Using the guidance above we can start with a classification taxonomy that makes sense to the business. This will allow us to take strides in protecting our data in place. Leveraging the work, we have completed in defining our tenant specific Sensitive Information Types (SITs) will allow us to marry these SITs against different classification categories to ensure protection gets baked into these assets at creation time, thus providing an additional layer of defense over and above that already afforded to us through our efforts up until now. This classification taxonomy can also be applied to data containers in our organization to ensure control over access and management of these areas. For more details on container labels please review the document here . When you create a sensitivity label, you can automatically assign that label to files and emails when it matches conditions that you specify. This ability to apply sensitivity labels to content automatically is important because: You don't need to train your users when to use each of your classifications. You don't need to rely on users to classify all content correctly. Users no longer need to know about your policies\u2014they can instead focus on their work. There are two different methods for automatically applying a sensitivity label to content in Microsoft 365: Client-side labeling when users edit documents or compose (also reply or forward) emails: Use a label that's configured for auto-labeling for files and emails (includes Word, Excel, PowerPoint, and Outlook). Supports recommending a label to users or automatically applying a label. User decides whether to accept or reject the label, to help ensure the correct labeling of content. Minimal delay for documents because the label can be applied even before the document is saved. Not all client apps support auto-labeling. This capability is supported by the Azure Information Protection unified labeling client, and some versions of Office . For configuration instructions, see How to configure auto-labeling for Office apps on this page. Service-side auto labeling policies are a powerful way of applying labels to data at rest and in transit across several M365 workloads, however, it is important to be aware of the limitations imposed by these: Specific to auto-labelling for SharePoint Online and OneDrive for Business: Office files for Word, PowerPoint, and Excel are supported. - These files can be auto-labelled when they are not part of an active session and whether they have been created, uploaded, or changed since you created auto-labelling policies, or they are existing files that have not been changed since auto-labelling policies have been created. Maximum of 25,000 automatically labelled files in your tenant per day. Maximum of 10 auto-labelling policies per tenant, each targeting up to 10 sites (SharePoint Online or OneDrive for Business). Existing values for \u201cmodified\u201d, \u201cmodified by\u201d, and the \u201cdate\u201d are not changed because of auto-labelling policies\u2014for both simulation mode and when labels are applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the account that last modified the file. Specific to auto-labelling for Exchange Online: Unlike manual labelling or auto-labelling with Office apps, Office attachments (Word, Excel, and PowerPoint files) and PDF attachments are also scanned for the conditions you specify in your auto-labelling policy. When there is a match, the email is labelled but not the attachment. For more details on this including what file types are supported please review the information here . If you have Exchange transport rules (ETRs) or data loss prevention (DLP) policies that apply Information Rights Management (IRM) encryption: When content is identified by these rules or policies and an auto-labelling policy, the label is applied. If that label applies encryption, the Information Rights Management settings from the Exchange transport rules or DLP policies are ignored. However, if that label doesn't apply encryption, the Information Rights Management settings from the transport rules or DLP policies are applied in addition to the label. Email that has Information Rights Management encryption with no label will be replaced by a label with any encryption settings when there is a match by using auto-labelling. Incoming email is labelled when there is a match with your auto-labelling conditions. However, if the label is configured for encryption, that encryption is not applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the person who sends the email. With these limitations in mind, Microsoft Cloud App Security (MCAS) can be used to apply labels for these services and several third-party SaaS applications also. MCAS has its own limitations and considerations which are discussed in this blog post . To protect and label structured data you should consider a solution like Azure Purview which among other things can allow you to Classify data using built-in and custom classifiers and Microsoft Information Protection sensitivity labels which allows you to label sensitive data consistently across SQL Server, Azure, Microsoft 365, and Power BI. To understand more about Azure Purview, check out this link . MIP Client Considerations \u2693\ufe0e When it comes to windows client you have two options, either a built-in client or a unified label client. Strategically, organizations should use the built-in client as it supports cross platform with a consistent experience. The built-in client does not need an add-in to deploy, or the need to be manage or keep up to date while providing a deeper integration with office products which includes performance improvement. While there are some feature gaps using the built-in client compared to the unified label client, we are working diligently to close that gap in the interim you can use the unified label client. To determine which features exist in the built-in client and which in the unified label client use the following table comparison . When it comes to MAC clients you can use the built-in client for office and Edge for viewing PDFs. Helpful Resources \u2693\ufe0e Using Sensitivity Labels in M365 \u2013 How to Protect NDA Data from Leaking End User Training for Sensitivity Labels in M365 \u2013 How to Accelerate Your Adoption Secure external collaboration using sensitivity labels Using Azure PIM for the AIP Super User feature management Data Loss Prevention \u2693\ufe0e To comply with business standards and industry regulations, organizations must protect sensitive information and prevent its inadvertent disclosure. Sensitive information can include financial data or personally identifiable information (PII) such as credit card numbers, social security numbers, or health records. With a data loss prevention (DLP) policy in the M365 SCC, you can identify, monitor, and automatically protect sensitive information across multiple Microsoft 365 workloads. With a DLP policy, you can: Identify sensitive information across many locations, such as Exchange Online, SharePoint Online, OneDrive for Business, Microsoft Teams, Windows 10 Devices, Microsoft Cloud App Security. For example, you can identify any document containing a credit card number that is stored in any OneDrive for Business site, or you can monitor just the OneDrive sites of specific people. Prevent the accidental sharing of sensitive information. For example, you can identify any document or email containing a health record that is shared with people outside your organization, and then automatically block access to that document or block the email from being sent. Monitor and protect sensitive information in the desktop versions of Excel, PowerPoint, and Word applications. Just like in Exchange Online, SharePoint Online, and OneDrive for Business, these Office desktop programs include the same capabilities to identify sensitive information and apply DLP policies. DLP provides continuous monitoring when people share content in these Office programs. Help users learn how to stay compliant without interrupting their workflow. You can educate your users about DLP policies and help them remain compliant without blocking their work. For example, if a user tries to share a document containing sensitive information, a DLP policy can both send them an email notification and show them a policy tip in the context of the document library that allows them to override the policy if they have a business justification. The same policy tips also appear in Outlook on the web (OWA), Outlook, Excel, PowerPoint, and Word Office clients. View DLP alerts and reports showing content that matches your organization\u2019s DLP policies. To view alerts and metadata related to your DLP policies you can use the DLP Alerts Management Dashboard. You can also view policy match reports to assess how your organization is complying with a DLP policy. If a DLP policy allows users to override a policy tip and report a false positive, you can also view what users have reported. You create and manage DLP policies on the Data Loss Prevention page in the Microsoft 365 compliance center. Learn about how DLP policies are structured . Best Practices \u2693\ufe0e Prior to Deployment Plan \u2693\ufe0e Identify the appropriate stakeholders and personas in your organization to collaborate for the design of DLP policies and workloads to be monitored. Some recommended personas to include compliance/privacy, security, human resources, and legal. Identify the types of information you need to protect and where this information is stored. Consider using the Data Classification page in the M365 SCC to help with this identification. Are there any types of information that will require the creation of custom Sensitive Information Types to detect? Where is the information stored in terms of workloads? Use the DLP Playbook to answer these questions and more. Currently, DLP supports the following workloads for protection: Exchange Online SharePoint Online OneDrive for Business Microsoft Teams Devices Microsoft Cloud App Security (acting as a proxy for creation of MCAS policy within the tenant Currently only global full or view only permissions are available for alerts at this time and cannot be further carved into areas of responsibility based on such as departments, locations etc. All designs should take this limitation into account before deployment is undertaken. If this capability is an absolute requirement, consider establishing a feed of all DLP alerts and activities into Azure Sentinel and configuring access rights accordingly within the solution.. Existing Exchange Online mail flow and DLP rules created in the Exchange Admin Center (EAC) will need to be gradually migrated to the M365 SCC, but will continue to function together with new policies created in the M365 SCC as documented here . Consider creating equivalent rules and disabling old rules in EAC while testing your new ones, then deleting the old rules when no longer needed. Using the presence of Sensitivity labels as a condition in your DLP policy should be closely considered as a standard in your organization. A sensitivity label is more likely to represent security sensitive information than a simple pattern match from a SIT, especially if you are using manual or recommended labeling, as the data is likely to have been deliberately classified by and end user as a match for certain sensitive information. Additionally, labels applied automatically via a trainable classifier are far more likely to be accurately classified than from pattern matching. Deployment Test Plan \u2693\ufe0e Always create DLP policies initially in test mode as this gives you an opportunity to determine not only if the policy is alerting correctly via email (nothing will flow through to the DLP reports in audit mode by design) but this will also allow you to determine if the thresholds you have configured for each rule are appropriate. For example, suppose you have configured your rule to trigger when more than 5 credit card numbers have detected. During testing you realize that it would be more appropriate to trigger the rule on 1 credit card number, so you edit the rule to make this change and then enable the policy to allow for the population of alerts in the reports. Use the DLP policy templates initially to see whether they make sense for your organization. These templates are preconfigured with certain Sensitive Information Types to monitor based on the regulatory compliance frameworks you need to monitor broken down by vertical organization type and country. This can drastically reduce the amount of time needed to create and test policies during your deployment test. If your licensing plan allows, consider using alerts based on volume thresholds rather than sending alerts each time a rule is matched. This allows for more targeted alert behavior based on when certain thresholds are exceeded or when the number of activities are above a certain number, which is more likely to be representative of suspicious behavior and leads to fewer alerts being ignored as \u201cnoise\u201d. When creating DLP policies, consider separate policies per workload. For example, you might have a policy named \u201cPCI-DSS-ExchangeOnline\u201d and one named \u201cPCI-DSS-SharePointOnline\u201d. The reason for this is that when combining workloads, the DLP rules interface will only show conditions common to each workload chosen, which can lead to many options missing when incompatibilities occur. Consider a case where a policy is choosing Exchange Online and SharePoint Online as workloads. The below figures show the DLP Rules Wizard conditions when the policy chooses Exchange Online in isolation versus in conjunction with SharePoint Online. When adding files to SharePoint Online and OneDrive for Business, there is an expected lag time between when the file is added and indexing occurs, a necessary process that must complete before DLP policies can be enforced. For more on how this works use this link . This leads to an opportunity for data leakage while waiting for this process to occur. Consider configuring SharePoint sensitive by default functionality to ensure this does not become an issue. Ensure that you have fully documented your policies and their expected outcomes for end users as part of your user acceptance and training procedures. Not all aspects of the user experience are identical across all platforms and this should be considered so as not to generate unnecessary help desk calls. A good example of this is policy tips and their behavior across the various OS platforms. You should expect to see Policy Tips in Office Online and Windows, but not macOS for instance. Ensure you have a well-documented and functional test plan, with clear tasks and outcomes. Production Deployment \u2693\ufe0e DLP reports should be scheduled and emailed to appropriate stakeholders based on the report types (schedules and recipients can be defined directly from the report itself in the Security and Compliance report viewer at https://protection.office.com ). Note currently you cannot schedule the following reports in the new Compliance portal (you can still do this in the older security and compliance center): DLP Policy Matches DLP Incidents Consider allowing users to mark items as false positives or provide an exception with justification. This will allow you to track what is being shared out and not slow business process down. These should be reviewed carefully to see if a policy needs to be adjusted or changed. Define exceptions to your DLP rules that are based on sensitivity labels. MIP labels are highly synergistic with traditional DLP. The biggest challenge with DLP is handling incidents such as false positives and exceptions, which generally disrupt user work and often require reactive actions taken by IT to unblock productivity and labels can help with that. For example, you can define a DLP rule that blocks Personally identifiable information (PII) from being shared outside of the organization, but make an exception for low-count PII (e.g., <2 credit card numbers) if the content is labeled as \u201cNon-business\u201d to allow for employees to share their personal information with family members when needed, and also exempt moderate counts of PII (e.g. <10 credit card numbers) if it is in protected form. You can even create a blanket exception for a label such as \u201cExecutive Sharing Exception\u201d which bypasses all DLP filters, but that is only available to specific people that are trusted to deal with this information, and that they must explicitly choose for the sensitive content they need to share. Use of such labels can be closely monitored and reported. When you are setting up a policy for Teams as a workload you should consider combining this with SharePoint Online and OneDrive for Business to maintain complete coverage. It is important to understand that \u201cTeams\u201d as a DLP workload only covers private chat and channel messages. Files shared in channels and chat are served from SharePoint and OneDrive, respectively. Ideally Onboarding devices to Endpoint DLP should be done automatically within a Mobile Device Management (MDM) when possible, such as Microsoft Intune or System Center Configuration Manager. If Microsoft Defender for Endpoint is already deployed in the organization, there is nothing further to do for this onboarding to occur. Otherwise, you can onboard devices with a script, Group Policy or VDI onboarding scripts. More details can be found here . Considerations \u2693\ufe0e While DLP might be a very important part of your compliance configuration you may want to consider reviewing the assessments that are available in from Compliance Manager, there is a significant chance that some control objectives require you to establish not only data loss prevention strategies, but also procedures to follow if information spillage does occur in the organization. Figure 1 below shows the improvement actions within a given tenant for an example compliance assessment. It is important to take these into consideration not only when planning your DLP strategy, but also updating these improvement actions upon completion of deployment will feed into an overall audit package to be provided to auditors when necessary for these regulatory compliance reporting periods. Consider using the out of the box (OOTB) SITs policy templates first, then start customizing the OOTB as you need if necessary. Sensitive Information Types (SITs) creation is likely to be a large factor of your initial deployment work. When using Regular Expressions (RegEx) for SIT definition, use websites such as regex101.com or regexr.com to help construct the RegEx\u2019s to be used. Be aware that the RegEx engine used in Microsoft DLP is Boost.Regex 5.1.3 so care should be taken to ensure all expressions conform to this standard. Some aspects of RegEx construction can create performance issues in the service, therefore it is also important to be aware of any potential validation issues . When creating a DLP policy in test mode, be aware that while incident emails will be generated, NO alerts will be created in the DLP reports within the Security and Compliance center. This is an expected outcome to avoid polluting the reports with false alerts. When working with Endpoint DLP, be aware that content is evaluated when created or modified. Existing content at rest on the device is not scanned at this time. When considering applying DLP policies to Teams, it is important to remember that the Teams \u201cworkload\u201d as shown in the wizard refers to chat and channel messages only. Files within Teams will be resident in either SharePoint Online or OneDrive for Business, therefore a comprehensive Teams protection strategy should also take these workloads into account when planning your policies. All DLP reports can show data from the most recent four-month period. The most recent data can take up to 24 hours to appear in the reports. Helpful Resources \u2693\ufe0e When testing SITs and Endpoint DLP actions, it can be useful to have a library of links to assist in this testing: https://filebin.net \u2013 excellent for testing HTTP post/upload actions https://dlptest.com \u2013 provides several testing options as well as samples for common restricted items such as credit card numbers, SSN, etc. https://dlptest.com - Provides you with data that can be used to generate SSN, credit card numbers etc. Migrating from Exchange Transport Rules to Unified DLP - The complete playbook","title":"Microsoft Information Protection and Data Loss Prevention"},{"location":"dag/mip-dlp/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Microsoft Information Protection (MIP) Data Loss Prevention (DLP) Microsoft Cloud App Security (MCAS) Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while protecting your intellectual property, stopping fraud or insider trading, plugging the sensitive data leaks, along with making the workplace safe.","title":"Your Deployment Plan"},{"location":"dag/mip-dlp/#microsoft-information-protection","text":"Implement Microsoft Information Protection (MIP) to help you discover, classify, and protect sensitive information wherever it lives or travels. Contrary to popular opinion, MIP is not a single product but rather a suite of technologies supported by many aspects of the Microsoft 365 ecosystem. MIP capabilities are included with Microsoft 365 Compliance and give you the tools to know your data, protect your data, and prevent data loss. The main capabilities associated with MIP are as follows: Sensitive information types (SITs) Trainable Classifiers Data Classification Sensitivity Labels Azure Information Protection (AIP) unified labeling client Azure Information Protection (AIP) unified labeling Scanner Azure Purview Double Key Encryption (DKE) Office 365 Message Encryption (OME) Service encryption with Customer Key SharePoint Information Rights Management (IRM) Rights Management connector Microsoft Cloud App Security (MCAS) Microsoft Information Protection (MIP) SDK Data Loss Prevention (DLP) Learn more about MIP basics here . With MIP and a Sensitivity labels policy you can: Deploy your classification taxonomy to the company end user employees and give them the ability to apply these labels to documents and emails. Labels can also be applied automatically or in a recommended way based on sensitive information stored in the document or email. Leverage the applied sensitivity labels as a condition for data loss prevention use cases. Mark the document or email sensitivity with a header, footer and/or watermark. This will make the data sensitivity visible to anyone who consumes the document, within an app, via the web or as a hard copy. Apply sensitivity labels for SharePoint online, Teams sites and groups, providing another layer of control on the container level access within managed or un-managed devices, if it should be set for Public or Private access and/or external access. With encryption you can control who can consume content (for example: only company employees + approved partners) and what permissions he or she has (for example: Read but Do Not Print or Edit).","title":"Microsoft Information Protection"},{"location":"dag/mip-dlp/#best-practices","text":"Defining the right label taxonomy and protection policies is the most critical step in a Microsoft Information Protection deployment. Labels will be the interface for users to understand content sensitivity, how it matches company policies, and will be the primary input for users to flag content that needs to be protected. A good label taxonomy needs to meet business and/or regulatory needs, be intuitively understandable by users, provide good policy tips and be easy to use. It should not prevent users from doing their jobs, while at the same time help prevent instances of data leakage or misuse and address compliance requirements. With these requirements in mind, the following best practices have proven to make deployment of information protection policies in many organizations easier, faster, and more successful.","title":"Best Practices"},{"location":"dag/mip-dlp/#prior-to-deployment-plan","text":"Discover your sensitive information in your existing repositories. This is the first step we recommend as part of our best practice approach to detect the data you own and be ready to configure it as part of your sensitivity label configurations as well as data loss prevention policies later in this guide. Microsoft 365 cloud: Use Content Explorer in Microsoft 365 compliance center to discover data stored in Microsoft 365 (SharePoint, OneDrive), read more about it here . Non-Microsoft cloud repositories: Use Microsoft Cloud App Security to connect non-Microsoft applications and discover sensitive information beyond the Microsoft 365 services. Read more about it here . On-premises repositories: Use Azure Information Protection Scanner to discover data stored in your on-premises file shares, read more about it here . Azure resources: Use Azure Purview to identify sensitive information stored in Azure Repositories, read more about it here . Consider the methods in which users will interact with MIP labels and how you intend to implement this: Interactively within Microsoft 365 Apps via the Sensitivity Button. Read more about it in the \u201cMIP Client Consideration\u201d section. Natively for macOS, iOS and Android Native labeling vs AIP Client Container labeling for SharePoint Sites, Teams and Office 365 Groups Public vs Private access Unmanaged device access Sharing levels PowerBI Dashboards and PBIX assets Use label names for your labels that intuitively resonate with your users. Using company jargon that is well ingrained in the employee\u2019s culture is a valid approach, though care must be taken to ensure the labels are also meaningful to new employees. For example, using acronyms in label names is not ideal due to the opacity to new employees and the difficulty of visually recognizing them. Using short, meaningful words such as \u201cConfidential\u201d or \u201cSecret\u201d generally works best. Consider label order. Labels are sorted from lowest sensitivity to highest sensitivity, which means higher sensitivity labels represent an \u201cupgrade\u201d in the confidentiality of the information and usually have stronger protection measures. This order can be enforced by preventing users from downgrading sensitivity of a document unless they have the right privileges, and there are multiple scenarios in which it is important that the order of the labels is clear. It is important that the names you use reflect this order, ad you should avoid using terms that have no clear hierarchy. For example, not all users might agree on whether \u201cConfidential\u201d or \u201cSecret\u201d is the most sensitive label, so using something like \u201cConfidential\u201d vs. \u201cHighly confidential\u201d may be preferable. Use sublabels with intent. Labels are generally used to represent the actual sensitivity of the content that is labeled, while sublabels are typically used to represent variations in the protection or the scope of the content. For example, you might have a label taxonomy that includes \u201cGeneral Business\u201d, \u201cConfidential\u201d and \u201cHighly Confidential\u201d as top-level labels. Sublabels such as \u201cInternal\u201d or \u201cExternal\u201d designate specific types of data in some of those top-level categories that need to be controlled in specific ways. You might also have project/team specific sublabels or sublabels to address special requirements such as excluding the application of content markings for content that should not be modified. Keep it simple with no more than five top level labels and five sublabels. User experience research shows that with five or fewer labels, users can target the desired label directly in a single movement, whereas if there are more elements in the list the user will typically have to read through them each time, making mistakes more likely. The 5x5 approach is proven to keep things simple and help users choose the right labels, but if you can keep labels below those numbers, even better. Define labels that will last a long time. Since labels often become part of a company\u2019s culture and language, it is critical that they are not frequently altered, especially when it comes to the names and meanings of the top-level labels. The approach mentioned in the previous point makes this easy: using top-level labels to represent the sensitivity of the document means they will not change often. Sublabels, on the other hand, can be more dynamic, and while it is preferable to frame them in a way that follows a clear pattern that rarely changes, adding or changing sublabels as additional requirements such as new projects or divisions come up is usually not a problem if you follow a consistent pattern. Do not put sensitive information in a label\u2019s name or description. This might sound obvious, but it is common that IT departments are asked to create a label to protect information for a merger or acquisition or a label for a secret project that is not known to the general population in the company. Putting the name of the company or a word that reveals more about the project than what is public in the name of the label can reveal such data to all users, even if the label is scoped to a small team. While scoped labels are not made available to all users, metadata about the existence of such labels is carried within the policies all users get, so it is important that codenames or other non-disclosing keywords are used in such labels instead. Plan your auto-labeling strategy, MIP provide both Service and Client based auto-labeling for different use cases: Service-side auto labeling policies should be used for data at rest in SharePoint Online and OneDrive for Business and data in transit for Exchange Online when specific SITs need to be detected and labels applied automatically. This can be especially helpful when the data source is not controlled and might be that data is stored or sent without being labeled by the client solution. Also, it\u2019s a great option to label data that is already stored in SharePoint Online and OneDrive for Business. Client-side labeling when users edit documents or compose (also reply or forward) emails: Use a label that is configured for auto-labeling for files and emails (includes Word, Excel, PowerPoint, and Outlook). This method supports recommending a label to a user, as well as automatically applying a label. But in both cases, the user decides whether to accept or reject the label, to help ensure the correct labeling of content. This client-side labeling has minimal delay for documents because the label can be applied even before the document is saved. However, not all client apps support auto-labeling. This capability is supported by the Azure Information Protection unified labeling client, and some versions of Office. If your organization operates in multiple languages, work with your localization teams to ensure the names chosen for the labels can be easily localized and are meaningful in all the required languages. Consider words that have a clear meaning in one language might be harder to localize or be ambiguous when translated. Examples of such words are \u201cPublic\u201d which can have nuanced meanings in some languages, and \u201cPersonal\u201d which can be easily confused in meaning to refer to private information. Consider the impact on usability. Forcing users to select labels too frequently can lead to users doing it reflexively without thinking about the label they should apply. Using a predefined default label is good practice in scenarios where manually labeling everything could be a burden - and where there is some \u201csafe\u201d sensitivity level that applies to most content. One such case is email, where for most users in most organizations labeling emails as \u201cInternal\u201d by default should be a safe option and reduce user effort considerably. Users can label emails as \u201cexternal\u201d, \u201cpublic\u201d or \u201cconfidential\u201d as needed. At the same time, most users do not create dozens of new documents per day, so asking them to individually label each document without providing a default is an acceptable requirement in most cases. MIP allows you to do this by using a different default label for emails and documents using the advanced option named \u201cOutlookDefaultLabel\u201d that specifies a default label for Outlook independently from what is set for documents. Compartmentalize data sparingly. Compartmentalization of data is essential in many businesses and using scoped sublabels that are shown and give rights to people in specific departments is a good practice, but you should use this capability in moderation. If you have a dozen critical projects that need to contain their data from being accessed by the general population of employees, creating sublabels specifically for them is beneficial. But if you have a thousand projects that demand the same treatment, the administrative burden imposed by such label taxonomy would be large and you will likely end up hitting a practical limit. The best practice is to define a clear rule for which kinds of teams, projects, divisions, or groups get their own sublabels which ensures only a small number of sublabels need to be created (a few dozen) - and stick with it. Consider what threats you are trying to prevent \u2013 not what users will be doing with the content. When defining protection policies some organizations start by thinking about what users need to do with their content, and define rights based on that. That often leads to frustration, since IT will rarely know everything every employee needs to do with the content. It can also lead to more protection than is necessary, and since there is a small overhead (for the computers and the humans) involved whenever accessing something is protected via encryption and rights enforcement, that is undesirable. Start instead with what threats you are trying to prevent: you might want to prevent your competitors from accessing your confidential plans, or from users accidentally putting sensitive data where unauthorized people can view it. Based on those requirements, define the minimal controls that must be there to ensure those scenarios do not happen and implement them. With time, as you gain more confidence on understanding what users need to do, you can adjust settings to implement tighter restrictions as needed. Involve different teams in the review of your proposed label taxonomy, including compliance, legal, public relations, end user education, etc. Defining labels is not an IT security task alone, and their early feedback will help you define a label taxonomy that will work for a long time and not need to be revised after deployment when those teams observe the labels you defined do not meet their needs or address their scenarios.","title":"Prior to Deployment Plan"},{"location":"dag/mip-dlp/#deployment-test-plan","text":"For the labeling client experience, consider your deployment methodology for Windows: Native labeling use Monthly Enterprise Channel or Monthly Channel for updates to Office 365 ProPlus. This will ensure you gain access to all MIP features immediately upon release. Semi-Annual Channel is strongly discouraged. AIP client should not be the default consideration and should only be used when needing specific functionality not yet available in the native client, or when you are using Office perpetual installation. For MAC we support the Native labeling in the office client. More details can be found here . For a comparison of update channels for M365, use this link . In some instances, a hybrid deployment of Native Labeling and AIP client may be appropriate. A good example is when File Explorer extension functionality is needed whilst wanting to keep the native experience as pristine as possible. In this case, the AIP client can be deployed along with an ADMX template to disable the Office Add-In components. Validate labels before deploying to users. Conduct a practical validation to see how accurate your users are at using these labels. One option is to create an email with fake sensitive information in the form of documents attached and send it to a subset of users asking them to open each document in turn and label it. They do not even need to report the results, since you will be able to see how they labeled each document in the Activity Explorer in the compliance center. You can alternatively do an offline activity, by setting baskets in the office\u2019s entrance, printing copies of a mix of pretend sensitive documents, and putting them in a pile at the entrance with a sign that says, \u201ctake one and put it in the corresponding basket\u201d. Users usually do this exercise consciously and it allows you to get a very representative idea of how well your users understand policies and labeling taxonomy. After you have done an exercise, you can validate the accuracy of user\u2019s actions and tune your labels and training materials accordingly. Socialize labels so they become part of the organization\u2019s natural language. While experience indicates the sensitivity label UI is simple enough that users do not need to be trained in its use, it is important to perform an awareness campaign in which the meaning of the different labels and the important of their use is highlighted (i.e., awareness emails, physical posters, etc.). The objective of such a campaign is that users incorporate the organization\u2019s labels as part of their natural language and that can intuitively assign documents to their corresponding label. The MIP CxE team has published several sample documents that can be used in this regard, referenced in the helpful links section above. Schedule multiple workshops with stakeholders during the testing phase to validate the label taxonomy is working effectively and catch any changes needed before wholesale deployment to production has occurred avoiding the need to reclassify large amounts of data in the future. Although we mention above that this validation should be done before deployment to users, it is inevitable that some changes will likely occur, and this should be expected by the project team. Ensure you have a well-documented test plan with clear tasks, testing scenarios and clear outcomes. Establish end user training and education. Measure their understanding of the organization information protection policies. Use \u201cknowledge measure questions\u201d if you can.","title":"Deployment Test Plan"},{"location":"dag/mip-dlp/#production-deployment","text":"Leverage the existing formal feedback mechanism from your end user-base to ensure that your label taxonomy remains effective and relevant to the organization. Making sure that established clear timelines for formal review and revision if necessary are followed. Monitor the classification activities. Using the \u201cActivity Explorer\u201d capability in the compliance center allows you to gain insights on how your users utilizing sensitivity labels (among other things). This will enable you to monitor how actively your users are following the organization policies and doing their due diligence when it comes to information labelling. Update the configuration, as necessary. Ensure all business units\u2019 requirements have been clearly addressed and document acceptance before rolling out to a wider end user base. While if you implement all the recommendations above you are set for a successful deployment of MIP, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption initially such as manual labels without protection, adding basic protection elements in a later stage (e.g. DLP controls to prevent highly confidential items from being accidentally sent outside, or encryption with very broad rights applied), and finally adding more restrictive permissions and tighter controls once you are confident in the use of the technology. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact.","title":"Production Deployment"},{"location":"dag/mip-dlp/#considerations","text":"Let us start with classifying and protecting our unstructured data assets in documents and emails. Using the guidance above we can start with a classification taxonomy that makes sense to the business. This will allow us to take strides in protecting our data in place. Leveraging the work, we have completed in defining our tenant specific Sensitive Information Types (SITs) will allow us to marry these SITs against different classification categories to ensure protection gets baked into these assets at creation time, thus providing an additional layer of defense over and above that already afforded to us through our efforts up until now. This classification taxonomy can also be applied to data containers in our organization to ensure control over access and management of these areas. For more details on container labels please review the document here . When you create a sensitivity label, you can automatically assign that label to files and emails when it matches conditions that you specify. This ability to apply sensitivity labels to content automatically is important because: You don't need to train your users when to use each of your classifications. You don't need to rely on users to classify all content correctly. Users no longer need to know about your policies\u2014they can instead focus on their work. There are two different methods for automatically applying a sensitivity label to content in Microsoft 365: Client-side labeling when users edit documents or compose (also reply or forward) emails: Use a label that's configured for auto-labeling for files and emails (includes Word, Excel, PowerPoint, and Outlook). Supports recommending a label to users or automatically applying a label. User decides whether to accept or reject the label, to help ensure the correct labeling of content. Minimal delay for documents because the label can be applied even before the document is saved. Not all client apps support auto-labeling. This capability is supported by the Azure Information Protection unified labeling client, and some versions of Office . For configuration instructions, see How to configure auto-labeling for Office apps on this page. Service-side auto labeling policies are a powerful way of applying labels to data at rest and in transit across several M365 workloads, however, it is important to be aware of the limitations imposed by these: Specific to auto-labelling for SharePoint Online and OneDrive for Business: Office files for Word, PowerPoint, and Excel are supported. - These files can be auto-labelled when they are not part of an active session and whether they have been created, uploaded, or changed since you created auto-labelling policies, or they are existing files that have not been changed since auto-labelling policies have been created. Maximum of 25,000 automatically labelled files in your tenant per day. Maximum of 10 auto-labelling policies per tenant, each targeting up to 10 sites (SharePoint Online or OneDrive for Business). Existing values for \u201cmodified\u201d, \u201cmodified by\u201d, and the \u201cdate\u201d are not changed because of auto-labelling policies\u2014for both simulation mode and when labels are applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the account that last modified the file. Specific to auto-labelling for Exchange Online: Unlike manual labelling or auto-labelling with Office apps, Office attachments (Word, Excel, and PowerPoint files) and PDF attachments are also scanned for the conditions you specify in your auto-labelling policy. When there is a match, the email is labelled but not the attachment. For more details on this including what file types are supported please review the information here . If you have Exchange transport rules (ETRs) or data loss prevention (DLP) policies that apply Information Rights Management (IRM) encryption: When content is identified by these rules or policies and an auto-labelling policy, the label is applied. If that label applies encryption, the Information Rights Management settings from the Exchange transport rules or DLP policies are ignored. However, if that label doesn't apply encryption, the Information Rights Management settings from the transport rules or DLP policies are applied in addition to the label. Email that has Information Rights Management encryption with no label will be replaced by a label with any encryption settings when there is a match by using auto-labelling. Incoming email is labelled when there is a match with your auto-labelling conditions. However, if the label is configured for encryption, that encryption is not applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the person who sends the email. With these limitations in mind, Microsoft Cloud App Security (MCAS) can be used to apply labels for these services and several third-party SaaS applications also. MCAS has its own limitations and considerations which are discussed in this blog post . To protect and label structured data you should consider a solution like Azure Purview which among other things can allow you to Classify data using built-in and custom classifiers and Microsoft Information Protection sensitivity labels which allows you to label sensitive data consistently across SQL Server, Azure, Microsoft 365, and Power BI. To understand more about Azure Purview, check out this link .","title":"Considerations"},{"location":"dag/mip-dlp/#mip-client-considerations","text":"When it comes to windows client you have two options, either a built-in client or a unified label client. Strategically, organizations should use the built-in client as it supports cross platform with a consistent experience. The built-in client does not need an add-in to deploy, or the need to be manage or keep up to date while providing a deeper integration with office products which includes performance improvement. While there are some feature gaps using the built-in client compared to the unified label client, we are working diligently to close that gap in the interim you can use the unified label client. To determine which features exist in the built-in client and which in the unified label client use the following table comparison . When it comes to MAC clients you can use the built-in client for office and Edge for viewing PDFs.","title":"MIP Client Considerations"},{"location":"dag/mip-dlp/#helpful-resources","text":"Using Sensitivity Labels in M365 \u2013 How to Protect NDA Data from Leaking End User Training for Sensitivity Labels in M365 \u2013 How to Accelerate Your Adoption Secure external collaboration using sensitivity labels Using Azure PIM for the AIP Super User feature management","title":"Helpful Resources"},{"location":"dag/mip-dlp/#data-loss-prevention","text":"To comply with business standards and industry regulations, organizations must protect sensitive information and prevent its inadvertent disclosure. Sensitive information can include financial data or personally identifiable information (PII) such as credit card numbers, social security numbers, or health records. With a data loss prevention (DLP) policy in the M365 SCC, you can identify, monitor, and automatically protect sensitive information across multiple Microsoft 365 workloads. With a DLP policy, you can: Identify sensitive information across many locations, such as Exchange Online, SharePoint Online, OneDrive for Business, Microsoft Teams, Windows 10 Devices, Microsoft Cloud App Security. For example, you can identify any document containing a credit card number that is stored in any OneDrive for Business site, or you can monitor just the OneDrive sites of specific people. Prevent the accidental sharing of sensitive information. For example, you can identify any document or email containing a health record that is shared with people outside your organization, and then automatically block access to that document or block the email from being sent. Monitor and protect sensitive information in the desktop versions of Excel, PowerPoint, and Word applications. Just like in Exchange Online, SharePoint Online, and OneDrive for Business, these Office desktop programs include the same capabilities to identify sensitive information and apply DLP policies. DLP provides continuous monitoring when people share content in these Office programs. Help users learn how to stay compliant without interrupting their workflow. You can educate your users about DLP policies and help them remain compliant without blocking their work. For example, if a user tries to share a document containing sensitive information, a DLP policy can both send them an email notification and show them a policy tip in the context of the document library that allows them to override the policy if they have a business justification. The same policy tips also appear in Outlook on the web (OWA), Outlook, Excel, PowerPoint, and Word Office clients. View DLP alerts and reports showing content that matches your organization\u2019s DLP policies. To view alerts and metadata related to your DLP policies you can use the DLP Alerts Management Dashboard. You can also view policy match reports to assess how your organization is complying with a DLP policy. If a DLP policy allows users to override a policy tip and report a false positive, you can also view what users have reported. You create and manage DLP policies on the Data Loss Prevention page in the Microsoft 365 compliance center. Learn about how DLP policies are structured .","title":"Data Loss Prevention"},{"location":"dag/mip-dlp/#best-practices_1","text":"","title":"Best Practices"},{"location":"dag/mip-dlp/#prior-to-deployment-plan_1","text":"Identify the appropriate stakeholders and personas in your organization to collaborate for the design of DLP policies and workloads to be monitored. Some recommended personas to include compliance/privacy, security, human resources, and legal. Identify the types of information you need to protect and where this information is stored. Consider using the Data Classification page in the M365 SCC to help with this identification. Are there any types of information that will require the creation of custom Sensitive Information Types to detect? Where is the information stored in terms of workloads? Use the DLP Playbook to answer these questions and more. Currently, DLP supports the following workloads for protection: Exchange Online SharePoint Online OneDrive for Business Microsoft Teams Devices Microsoft Cloud App Security (acting as a proxy for creation of MCAS policy within the tenant Currently only global full or view only permissions are available for alerts at this time and cannot be further carved into areas of responsibility based on such as departments, locations etc. All designs should take this limitation into account before deployment is undertaken. If this capability is an absolute requirement, consider establishing a feed of all DLP alerts and activities into Azure Sentinel and configuring access rights accordingly within the solution.. Existing Exchange Online mail flow and DLP rules created in the Exchange Admin Center (EAC) will need to be gradually migrated to the M365 SCC, but will continue to function together with new policies created in the M365 SCC as documented here . Consider creating equivalent rules and disabling old rules in EAC while testing your new ones, then deleting the old rules when no longer needed. Using the presence of Sensitivity labels as a condition in your DLP policy should be closely considered as a standard in your organization. A sensitivity label is more likely to represent security sensitive information than a simple pattern match from a SIT, especially if you are using manual or recommended labeling, as the data is likely to have been deliberately classified by and end user as a match for certain sensitive information. Additionally, labels applied automatically via a trainable classifier are far more likely to be accurately classified than from pattern matching.","title":"Prior to Deployment Plan"},{"location":"dag/mip-dlp/#deployment-test-plan_1","text":"Always create DLP policies initially in test mode as this gives you an opportunity to determine not only if the policy is alerting correctly via email (nothing will flow through to the DLP reports in audit mode by design) but this will also allow you to determine if the thresholds you have configured for each rule are appropriate. For example, suppose you have configured your rule to trigger when more than 5 credit card numbers have detected. During testing you realize that it would be more appropriate to trigger the rule on 1 credit card number, so you edit the rule to make this change and then enable the policy to allow for the population of alerts in the reports. Use the DLP policy templates initially to see whether they make sense for your organization. These templates are preconfigured with certain Sensitive Information Types to monitor based on the regulatory compliance frameworks you need to monitor broken down by vertical organization type and country. This can drastically reduce the amount of time needed to create and test policies during your deployment test. If your licensing plan allows, consider using alerts based on volume thresholds rather than sending alerts each time a rule is matched. This allows for more targeted alert behavior based on when certain thresholds are exceeded or when the number of activities are above a certain number, which is more likely to be representative of suspicious behavior and leads to fewer alerts being ignored as \u201cnoise\u201d. When creating DLP policies, consider separate policies per workload. For example, you might have a policy named \u201cPCI-DSS-ExchangeOnline\u201d and one named \u201cPCI-DSS-SharePointOnline\u201d. The reason for this is that when combining workloads, the DLP rules interface will only show conditions common to each workload chosen, which can lead to many options missing when incompatibilities occur. Consider a case where a policy is choosing Exchange Online and SharePoint Online as workloads. The below figures show the DLP Rules Wizard conditions when the policy chooses Exchange Online in isolation versus in conjunction with SharePoint Online. When adding files to SharePoint Online and OneDrive for Business, there is an expected lag time between when the file is added and indexing occurs, a necessary process that must complete before DLP policies can be enforced. For more on how this works use this link . This leads to an opportunity for data leakage while waiting for this process to occur. Consider configuring SharePoint sensitive by default functionality to ensure this does not become an issue. Ensure that you have fully documented your policies and their expected outcomes for end users as part of your user acceptance and training procedures. Not all aspects of the user experience are identical across all platforms and this should be considered so as not to generate unnecessary help desk calls. A good example of this is policy tips and their behavior across the various OS platforms. You should expect to see Policy Tips in Office Online and Windows, but not macOS for instance. Ensure you have a well-documented and functional test plan, with clear tasks and outcomes.","title":"Deployment Test Plan"},{"location":"dag/mip-dlp/#production-deployment_1","text":"DLP reports should be scheduled and emailed to appropriate stakeholders based on the report types (schedules and recipients can be defined directly from the report itself in the Security and Compliance report viewer at https://protection.office.com ). Note currently you cannot schedule the following reports in the new Compliance portal (you can still do this in the older security and compliance center): DLP Policy Matches DLP Incidents Consider allowing users to mark items as false positives or provide an exception with justification. This will allow you to track what is being shared out and not slow business process down. These should be reviewed carefully to see if a policy needs to be adjusted or changed. Define exceptions to your DLP rules that are based on sensitivity labels. MIP labels are highly synergistic with traditional DLP. The biggest challenge with DLP is handling incidents such as false positives and exceptions, which generally disrupt user work and often require reactive actions taken by IT to unblock productivity and labels can help with that. For example, you can define a DLP rule that blocks Personally identifiable information (PII) from being shared outside of the organization, but make an exception for low-count PII (e.g., <2 credit card numbers) if the content is labeled as \u201cNon-business\u201d to allow for employees to share their personal information with family members when needed, and also exempt moderate counts of PII (e.g. <10 credit card numbers) if it is in protected form. You can even create a blanket exception for a label such as \u201cExecutive Sharing Exception\u201d which bypasses all DLP filters, but that is only available to specific people that are trusted to deal with this information, and that they must explicitly choose for the sensitive content they need to share. Use of such labels can be closely monitored and reported. When you are setting up a policy for Teams as a workload you should consider combining this with SharePoint Online and OneDrive for Business to maintain complete coverage. It is important to understand that \u201cTeams\u201d as a DLP workload only covers private chat and channel messages. Files shared in channels and chat are served from SharePoint and OneDrive, respectively. Ideally Onboarding devices to Endpoint DLP should be done automatically within a Mobile Device Management (MDM) when possible, such as Microsoft Intune or System Center Configuration Manager. If Microsoft Defender for Endpoint is already deployed in the organization, there is nothing further to do for this onboarding to occur. Otherwise, you can onboard devices with a script, Group Policy or VDI onboarding scripts. More details can be found here .","title":"Production Deployment"},{"location":"dag/mip-dlp/#considerations_1","text":"While DLP might be a very important part of your compliance configuration you may want to consider reviewing the assessments that are available in from Compliance Manager, there is a significant chance that some control objectives require you to establish not only data loss prevention strategies, but also procedures to follow if information spillage does occur in the organization. Figure 1 below shows the improvement actions within a given tenant for an example compliance assessment. It is important to take these into consideration not only when planning your DLP strategy, but also updating these improvement actions upon completion of deployment will feed into an overall audit package to be provided to auditors when necessary for these regulatory compliance reporting periods. Consider using the out of the box (OOTB) SITs policy templates first, then start customizing the OOTB as you need if necessary. Sensitive Information Types (SITs) creation is likely to be a large factor of your initial deployment work. When using Regular Expressions (RegEx) for SIT definition, use websites such as regex101.com or regexr.com to help construct the RegEx\u2019s to be used. Be aware that the RegEx engine used in Microsoft DLP is Boost.Regex 5.1.3 so care should be taken to ensure all expressions conform to this standard. Some aspects of RegEx construction can create performance issues in the service, therefore it is also important to be aware of any potential validation issues . When creating a DLP policy in test mode, be aware that while incident emails will be generated, NO alerts will be created in the DLP reports within the Security and Compliance center. This is an expected outcome to avoid polluting the reports with false alerts. When working with Endpoint DLP, be aware that content is evaluated when created or modified. Existing content at rest on the device is not scanned at this time. When considering applying DLP policies to Teams, it is important to remember that the Teams \u201cworkload\u201d as shown in the wizard refers to chat and channel messages only. Files within Teams will be resident in either SharePoint Online or OneDrive for Business, therefore a comprehensive Teams protection strategy should also take these workloads into account when planning your policies. All DLP reports can show data from the most recent four-month period. The most recent data can take up to 24 hours to appear in the reports.","title":"Considerations"},{"location":"dag/mip-dlp/#helpful-resources_1","text":"When testing SITs and Endpoint DLP actions, it can be useful to have a library of links to assist in this testing: https://filebin.net \u2013 excellent for testing HTTP post/upload actions https://dlptest.com \u2013 provides several testing options as well as samples for common restricted items such as credit card numbers, SSN, etc. https://dlptest.com - Provides you with data that can be used to generate SSN, credit card numbers etc. Migrating from Exchange Transport Rules to Unified DLP - The complete playbook","title":"Helpful Resources"},{"location":"enduser/retention/","text":"Coming soon! In the mean time, please download the Retention Labeling End User Training documentation from here","title":"Retention Labels"},{"location":"enduser/sensitivity/","text":"Coming soon! In the mean time, please download the Sensitivity Labeling End User Training documentation from here","title":"Sensitivity Labels"},{"location":"playbooks/etr2dlp/","text":"Coming soon! In the mean time, please download the Exchange ETR to DLP Playbook from here","title":"Exchange ETR to DLP Playbook"},{"location":"playbooks/teamsdlp/","text":"Coming soon! In the mean time, please download the Teams DLP Playbook from here","title":"Teams DLP Playbook"},{"location":"resources/aed/","text":"We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Technical Sessions Playbooks and Guides \u2693\ufe0e Deployment Acceleration Guide Webinars \u2693\ufe0e Discovery & Response (D&R) Webinars Blogs \u2693\ufe0e Lifecycle of an item in SharePoint: Where does it go?","title":"Advanced eDiscovery"},{"location":"resources/aed/#videos","text":"Technical Sessions","title":"Videos"},{"location":"resources/aed/#playbooks-and-guides","text":"Deployment Acceleration Guide","title":"Playbooks and Guides"},{"location":"resources/aed/#webinars","text":"Discovery & Response (D&R) Webinars","title":"Webinars"},{"location":"resources/aed/#blogs","text":"Lifecycle of an item in SharePoint: Where does it go?","title":"Blogs"},{"location":"resources/cm/","text":"We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Introduction to Compliance Manager Simplify Compliance and Reduce Risk with our 150+ Assessment templates or bring your own assessment Create assessments and monitor your progress with Compliance Manager - Microsoft Tech Community Extend and customize assessments to suit your needs in Compliance Manager Playbooks and Guides \u2693\ufe0e Deployment Acceleration Guide Microsoft Compliance Manager Webinars \u2693\ufe0e Compliance Manager (CM) Webinars Learning Path \u2693\ufe0e Reduce risk with Microsoft Compliance Manager","title":"Compliance Manager (CM)"},{"location":"resources/cm/#videos","text":"Introduction to Compliance Manager Simplify Compliance and Reduce Risk with our 150+ Assessment templates or bring your own assessment Create assessments and monitor your progress with Compliance Manager - Microsoft Tech Community Extend and customize assessments to suit your needs in Compliance Manager","title":"Videos"},{"location":"resources/cm/#playbooks-and-guides","text":"Deployment Acceleration Guide Microsoft Compliance Manager","title":"Playbooks and Guides"},{"location":"resources/cm/#webinars","text":"Compliance Manager (CM) Webinars","title":"Webinars"},{"location":"resources/cm/#learning-path","text":"Reduce risk with Microsoft Compliance Manager","title":"Learning Path"},{"location":"resources/dlp/","text":"We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Vblog - Learn how to apply DLP policy to non-Microsoft cloud apps How to configure a DLP policy Playbooks and Guides \u2693\ufe0e Deployment Acceleration Guide Endpoint DLP interactive guide Teams DLP interactive guide Migrating from Exchange ETR to DLP playbook Teams DLP Playbook Join Endpoint DLP preview ring Webinars \u2693\ufe0e Data Loss Prevention (DLP) Webinars","title":"Data Loss Prevention (DLP)"},{"location":"resources/dlp/#videos","text":"Vblog - Learn how to apply DLP policy to non-Microsoft cloud apps How to configure a DLP policy","title":"Videos"},{"location":"resources/dlp/#playbooks-and-guides","text":"Deployment Acceleration Guide Endpoint DLP interactive guide Teams DLP interactive guide Migrating from Exchange ETR to DLP playbook Teams DLP Playbook Join Endpoint DLP preview ring","title":"Playbooks and Guides"},{"location":"resources/dlp/#webinars","text":"Data Loss Prevention (DLP) Webinars","title":"Webinars"},{"location":"resources/ir/","text":"We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Insider Risk Management Overview Insider Risk Management Analytics Insider Risk Management Policy Configuration Insider Risk Management Alerts Triage Experience Insider Risk Management Investigation and Escalation Playbooks and Guides \u2693\ufe0e Deployment Acceleration Guide Insider Risk interactive guide Implement policies for Insider Risk Management and Communication Compliance Webinars \u2693\ufe0e Insider Risk Management and Communication Compliance (IRCC) Webinars Learning Path \u2693\ufe0e Insider Risk Management learning path","title":"Insider Risk Management (IR)"},{"location":"resources/ir/#videos","text":"Insider Risk Management Overview Insider Risk Management Analytics Insider Risk Management Policy Configuration Insider Risk Management Alerts Triage Experience Insider Risk Management Investigation and Escalation","title":"Videos"},{"location":"resources/ir/#playbooks-and-guides","text":"Deployment Acceleration Guide Insider Risk interactive guide Implement policies for Insider Risk Management and Communication Compliance","title":"Playbooks and Guides"},{"location":"resources/ir/#webinars","text":"Insider Risk Management and Communication Compliance (IRCC) Webinars","title":"Webinars"},{"location":"resources/ir/#learning-path","text":"Insider Risk Management learning path","title":"Learning Path"},{"location":"resources/mig/","text":"We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e How to Auto-apply Retention Labels using Compliance Center Playbooks and Guides \u2693\ufe0e Deployment Acceleration Guide End User Training for Retention labels Webinars \u2693\ufe0e Microsoft Information Governance (MIG) Webinars Blogs \u2693\ufe0e Lifecycle of an item in SharePoint: Where does it go?","title":"Microsoft Information Governance (MIG)"},{"location":"resources/mig/#videos","text":"How to Auto-apply Retention Labels using Compliance Center","title":"Videos"},{"location":"resources/mig/#playbooks-and-guides","text":"Deployment Acceleration Guide End User Training for Retention labels","title":"Playbooks and Guides"},{"location":"resources/mig/#webinars","text":"Microsoft Information Governance (MIG) Webinars","title":"Webinars"},{"location":"resources/mig/#blogs","text":"Lifecycle of an item in SharePoint: Where does it go?","title":"Blogs"},{"location":"resources/mip/","text":"We built this page to help you easily find all relevant content and resources relating to the compliance solutions in Microsoft 365. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Vblog series: setting up a secure collaboration environment Vblog series \u2013 end user point of view Vblog series - Admin point of view Using Sensitivity Labels in M365 \u2013 How to Protect NDA Data from Leaking Playbooks and Guides \u2693\ufe0e Deployment Acceleration Guide Data Classification White Paper End User Training for Sensitivity labels How to re-label documents classified with a deprecated sensitivity label Webinars \u2693\ufe0e Microsoft Information Protection (MIP) Webinars","title":"Microsoft Information Protection (MIP)"},{"location":"resources/mip/#videos","text":"Vblog series: setting up a secure collaboration environment Vblog series \u2013 end user point of view Vblog series - Admin point of view Using Sensitivity Labels in M365 \u2013 How to Protect NDA Data from Leaking","title":"Videos"},{"location":"resources/mip/#playbooks-and-guides","text":"Deployment Acceleration Guide Data Classification White Paper End User Training for Sensitivity labels How to re-label documents classified with a deprecated sensitivity label","title":"Playbooks and Guides"},{"location":"resources/mip/#webinars","text":"Microsoft Information Protection (MIP) Webinars","title":"Webinars"}]}